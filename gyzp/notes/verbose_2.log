Renderer: Tesla V100-DGXS-32GB/PCIe/SSE2 by NVIDIA Corporation
OpenGL version: 4.6.0 NVIDIA 525.105.17
Using optional features:
    GL_ARB_vertex_array_object
    GL_ARB_separate_shader_objects
    GL_ARB_robustness
    GL_ARB_texture_storage
    GL_ARB_texture_view
    GL_ARB_framebuffer_no_attachments
    GL_ARB_invalidate_subdata
    GL_ARB_texture_storage_multisample
    GL_ARB_multi_bind
    GL_ARB_direct_state_access
    GL_ARB_get_texture_sub_image
    GL_ARB_texture_filter_anisotropic
    GL_KHR_debug
    GL_KHR_parallel_shader_compile
    GL_NV_depth_buffer_float
Using driver workarounds:
    no-forward-compatible-core-context
    nv-egl-incorrect-gl11-function-pointers
    no-layout-qualifiers-on-old-glsl
    nv-zero-context-profile-mask
    nv-implementation-color-read-format-dsa-broken
    nv-cubemap-inconsistent-compressed-image-size
    nv-cubemap-broken-full-compressed-image-query
    nv-compressed-block-size-in-bits
Exploration Agent created
Renderer: Tesla V100-DGXS-32GB/PCIe/SSE2 by NVIDIA Corporation
OpenGL version: 4.6.0 NVIDIA 525.105.17
Using optional features:
    GL_ARB_vertex_array_object
    GL_ARB_separate_shader_objects
    GL_ARB_robustness
    GL_ARB_texture_storage
    GL_ARB_texture_view
    GL_ARB_framebuffer_no_attachments
    GL_ARB_invalidate_subdata
    GL_ARB_texture_storage_multisample
    GL_ARB_multi_bind
    GL_ARB_direct_state_access
    GL_ARB_get_texture_sub_image
    GL_ARB_texture_filter_anisotropic
    GL_KHR_debug
    GL_KHR_parallel_shader_compile
    GL_NV_depth_buffer_float
Using driver workarounds:
    nv-egl-incorrect-gl11-function-pointers
    no-layout-qualifiers-on-old-glsl
    nv-zero-context-profile-mask
    nv-implementation-color-read-format-dsa-broken
    nv-cubemap-inconsistent-compressed-image-size
    nv-cubemap-broken-full-compressed-image-query
    nv-compressed-block-size-in-bits
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']


======= labels_counter:  0
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']


======= labels_counter:  1
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']


======= labels_counter:  2
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']


======= labels_counter:  3
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']


======= labels_counter:  4
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']


======= labels_counter:  5
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']


======= labels_counter:  6
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']


======= labels_counter:  7
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']


======= labels_counter:  8
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']


======= labels_counter:  9
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -59.47591952082388
Distance to goal 26.419689627245813
Distance in cm: 132.09844813622905 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 0.0
angle final goal = -59.47591952082388
0.0 0.2 rel ang = 59.999969482421875
-----------------


======= labels_counter:  10
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -89.47591952082388
Distance to goal 26.419689627245813
Distance in cm: 132.09844813622905 > 50.0
continuous actions for exploring
agent angle = 29.999969482421875
angle stg goal = 0.0
angle final goal = -89.47591952082388
0.0 0.2 rel ang = 29.999969482421875
-----------------


======= labels_counter:  11
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -119.47591952082388
Distance to goal 26.419689627245813
Distance in cm: 132.09844813622905 > 50.0
continuous actions for exploring
agent angle = -3.0517578125e-05
angle stg goal = 0.0
angle final goal = -119.47591952082388
0.0 0.2 rel ang = -3.0517578125e-05
-----------------


======= labels_counter:  12
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 240)
  - delta = 4 0
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 23.749463975288634
Distance to goal 27.313000567495326
Distance in cm: 136.56500283747664 > 50.0
continuous actions for exploring
agent angle = -3.0517578125e-05
angle stg goal = 90.0
angle final goal = 23.749463975288634
0.2 0.0 rel ang = -90.00003051757812
-----------------


======= labels_counter:  13
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 240)
  - delta = 4 0
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 53.7494792340777
Distance to goal 27.313000567495326
Distance in cm: 136.56500283747664 > 50.0
continuous actions for exploring
agent angle = 29.999984741210938
angle stg goal = 90.0
angle final goal = 53.7494792340777
0.2 0.0 rel ang = -60.00001525878906
-----------------


======= labels_counter:  14
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 240)
  - delta = 4 0
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 83.74946397528863
Distance to goal 27.313000567495326
Distance in cm: 136.56500283747664 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 90.0
angle final goal = 83.74946397528863
0.2 0.0 rel ang = -30.000030517578125
-----------------


======= labels_counter:  15
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 113.74949449286676
Distance to goal 27.313000567495326
Distance in cm: 136.56500283747664 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = 113.74949449286676
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  16
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 113.74949449286676
Distance to goal 27.313000567495326
Distance in cm: 136.56500283747664 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = 113.74949449286676
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  17
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 242)
  - delta = 3 2
Distance (m): 0.18027756377319945
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 113.74949449286676
Distance to goal 27.313000567495326
Distance in cm: 136.56500283747664 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 56.309932474020215
angle final goal = 113.74949449286676
0.15000000000000002 0.1 rel ang = 33.690067525979785
-----------------


======= labels_counter:  18
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move screwdriver from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 242)
  - delta = 3 2
Distance (m): 0.18027756377319945
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 83.74949449286676
Distance to goal 27.313000567495326
Distance in cm: 136.56500283747664 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 56.309932474020215
angle final goal = 83.74949449286676
0.15000000000000002 0.1 rel ang = 3.690067525979785
-----------------


======= labels_counter:  19
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']


======= labels_counter:  20
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']


======= labels_counter:  21
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']


======= labels_counter:  22
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']


======= labels_counter:  23
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']


======= labels_counter:  24
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']


======= labels_counter:  25
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']


======= labels_counter:  26
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']


======= labels_counter:  27
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']


======= labels_counter:  28
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']


======= labels_counter:  29
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -164.99996948242188
Distance to goal 49.49747468305833
Distance in cm: 247.48737341529164 > 50.0
continuous actions for exploring
agent angle = 60.000030517578125
angle stg goal = 45.0
angle final goal = -164.99996948242188
0.15000000000000002 0.15000000000000002 rel ang = 15.000030517578125
-----------------


======= labels_counter:  30
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 165.00003051757812
Distance to goal 49.49747468305833
Distance in cm: 247.48737341529164 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = 168.6900675259798
angle final goal = 165.00003051757812
0.05 -0.25 rel ang = -138.69003700840167
-----------------


======= labels_counter:  31
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -164.99996948242188
Distance to goal 49.49747468305833
Distance in cm: 247.48737341529164 > 50.0
continuous actions for exploring
agent angle = 60.000030517578125
angle stg goal = 168.6900675259798
angle final goal = -164.99996948242188
0.05 -0.25 rel ang = -108.69003700840167
-----------------


======= labels_counter:  32
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -134.99996948242188
Distance to goal 49.49747468305833
Distance in cm: 247.48737341529164 > 50.0
continuous actions for exploring
agent angle = 90.00003051757812
angle stg goal = 168.6900675259798
angle final goal = -134.99996948242188
0.05 -0.25 rel ang = -78.69003700840165
-----------------


======= labels_counter:  33
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -104.99996948242188
Distance to goal 49.49747468305833
Distance in cm: 247.48737341529164 > 50.0
continuous actions for exploring
agent angle = 120.00003051757812
angle stg goal = 168.6900675259798
angle final goal = -104.99996948242188
0.05 -0.25 rel ang = -48.690037008401646
-----------------


======= labels_counter:  34
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -74.99996948242188
Distance to goal 49.49747468305833
Distance in cm: 247.48737341529164 > 50.0
continuous actions for exploring
agent angle = 150.00003051757812
angle stg goal = 168.6900675259798
angle final goal = -74.99996948242188
0.05 -0.25 rel ang = -18.690037008401646
-----------------


======= labels_counter:  35
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -44.99993896484375
Distance to goal 49.49747468305833
Distance in cm: 247.48737341529164 > 50.0
continuous actions for exploring
agent angle = -179.99993896484375
angle stg goal = 168.6900675259798
angle final goal = -44.99993896484375
0.05 -0.25 rel ang = 11.30999350917648
-----------------


======= labels_counter:  36
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -45.881342961425844
Distance to goal 45.967379738244816
Distance in cm: 229.83689869122406 > 50.0
continuous actions for exploring
agent angle = -179.99993896484375
angle stg goal = 168.6900675259798
angle final goal = -45.881342961425844
0.05 -0.25 rel ang = 11.30999350917648
-----------------


======= labels_counter:  37
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -44.99993896484375
Distance to goal 42.42640687119285
Distance in cm: 212.13203435596427 > 50.0
continuous actions for exploring
agent angle = -179.99993896484375
angle stg goal = 143.13010235415598
angle final goal = -44.99993896484375
0.15000000000000002 -0.2 rel ang = 36.8699586810003
-----------------


======= labels_counter:  38
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move lamp from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -74.99993896484375
Distance to goal 42.42640687119285
Distance in cm: 212.13203435596427 > 50.0
continuous actions for exploring
agent angle = 150.00006103515625
angle stg goal = 143.13010235415598
angle final goal = -74.99993896484375
0.15000000000000002 -0.2 rel ang = 6.86995868100027
-----------------


======= labels_counter:  39
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']


======= labels_counter:  40
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']


======= labels_counter:  41
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']


======= labels_counter:  42
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']


======= labels_counter:  43
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']


======= labels_counter:  44
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']


======= labels_counter:  45
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']


======= labels_counter:  46
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']


======= labels_counter:  47
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']


======= labels_counter:  48
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']


======= labels_counter:  49
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 52.23477294641842
Distance to goal 22.20360331117452
Distance in cm: 111.01801655587259 > 50.0
continuous actions for exploring
agent angle = 59.99993896484375
angle stg goal = -135.0
angle final goal = 52.23477294641842
-0.2 -0.2 rel ang = -165.00006103515625
-----------------


======= labels_counter:  50
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 82.23477294641842
Distance to goal 22.20360331117452
Distance in cm: 111.01801655587259 > 50.0
continuous actions for exploring
agent angle = 89.99993896484375
angle stg goal = -135.0
angle final goal = 82.23477294641842
-0.2 -0.2 rel ang = -135.00006103515625
-----------------


======= labels_counter:  51
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 112.23480346399654
Distance to goal 22.20360331117452
Distance in cm: 111.01801655587259 > 50.0
continuous actions for exploring
agent angle = 119.99996948242188
angle stg goal = -135.0
angle final goal = 112.23480346399654
-0.2 -0.2 rel ang = -105.00003051757812
-----------------


======= labels_counter:  52
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 142.23480346399654
Distance to goal 22.20360331117452
Distance in cm: 111.01801655587259 > 50.0
continuous actions for exploring
agent angle = 149.99996948242188
angle stg goal = -135.0
angle final goal = 142.23480346399654
-0.2 -0.2 rel ang = -75.00003051757812
-----------------


======= labels_counter:  53
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 172.23480346399654
Distance to goal 22.20360331117452
Distance in cm: 111.01801655587259 > 50.0
continuous actions for exploring
agent angle = 179.99996948242188
angle stg goal = -135.0
angle final goal = 172.23480346399654
-0.2 -0.2 rel ang = -45.000030517578125
-----------------


======= labels_counter:  54
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -157.76516601842533
Distance to goal 22.20360331117452
Distance in cm: 111.01801655587259 > 50.0
continuous actions for exploring
agent angle = -150.0
angle stg goal = -135.0
angle final goal = -157.76516601842533
-0.2 -0.2 rel ang = -15.0
-----------------


======= labels_counter:  55
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 30.0
Distance to goal 24.0
Distance in cm: 120.0 > 50.0
continuous actions for exploring
agent angle = -150.0
angle stg goal = -111.80140948635182
angle final goal = 30.0
-0.25 -0.1 rel ang = -38.198590513648185
-----------------


======= labels_counter:  56
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 62.38594403038883
Distance to goal 24.020824298928627
Distance in cm: 120.10412149464314 > 50.0
continuous actions for exploring
agent angle = -120.0
angle stg goal = -111.80140948635182
angle final goal = 62.38594403038883
-0.25 -0.1 rel ang = -8.198590513648185
-----------------


======= labels_counter:  57
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 72.80426606528675
Distance to goal 22.561028345356956
Distance in cm: 112.80514172678478 > 50.0
continuous actions for exploring
agent angle = -120.0
angle stg goal = -135.0
angle final goal = 72.80426606528675
-0.2 -0.2 rel ang = 15.0
-----------------


======= labels_counter:  58
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move cup from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (237, 236)
  - delta = -3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 87.75854060106002
Distance to goal 21.470910553583888
Distance in cm: 107.35455276791944 > 50.0
continuous actions for exploring
agent angle = -120.0
angle stg goal = -143.13010235415598
angle final goal = 87.75854060106002
-0.15000000000000002 -0.2 rel ang = 23.13010235415598
-----------------


======= labels_counter:  59
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']


======= labels_counter:  60
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']


======= labels_counter:  61
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']


======= labels_counter:  62
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']


======= labels_counter:  63
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']


======= labels_counter:  64
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']


======= labels_counter:  65
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']


======= labels_counter:  66
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']


======= labels_counter:  67
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']


======= labels_counter:  68
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']


======= labels_counter:  69
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 119.65675111576043
Distance to goal 47.50789408087881
Distance in cm: 237.53947040439408 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = -135.0
angle final goal = 119.65675111576043
-0.2 -0.2 rel ang = -165.0
-----------------


======= labels_counter:  70
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 149.65675111576041
Distance to goal 47.50789408087881
Distance in cm: 237.53947040439408 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = -135.0
angle final goal = 149.65675111576041
-0.2 -0.2 rel ang = -135.0
-----------------


======= labels_counter:  71
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 179.65675111576041
Distance to goal 47.50789408087881
Distance in cm: 237.53947040439408 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = -135.0
angle final goal = 179.65675111576041
-0.2 -0.2 rel ang = -105.0
-----------------


======= labels_counter:  72
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -150.34324888423959
Distance to goal 47.50789408087881
Distance in cm: 237.53947040439408 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = -135.0
angle final goal = -150.34324888423959
-0.2 -0.2 rel ang = -75.0
-----------------


======= labels_counter:  73
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -120.34324888423959
Distance to goal 47.50789408087881
Distance in cm: 237.53947040439408 > 50.0
continuous actions for exploring
agent angle = 180.0
angle stg goal = -135.0
angle final goal = -120.34324888423959
-0.2 -0.2 rel ang = -45.0
-----------------


======= labels_counter:  74
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -90.34324888423959
Distance to goal 47.50789408087881
Distance in cm: 237.53947040439408 > 50.0
continuous actions for exploring
agent angle = -150.0
angle stg goal = -135.0
angle final goal = -90.34324888423959
-0.2 -0.2 rel ang = -15.0
-----------------


======= labels_counter:  75
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 240)
  - delta = -5 0
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -97.34934904464058
Distance to goal 47.80167361086848
Distance in cm: 239.00836805434238 > 50.0
continuous actions for exploring
agent angle = -150.0
angle stg goal = -90.0
angle final goal = -97.34934904464058
-0.25 0.0 rel ang = -60.0
-----------------


======= labels_counter:  76
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 240)
  - delta = -5 0
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -67.34934904464058
Distance to goal 47.80167361086848
Distance in cm: 239.00836805434238 > 50.0
continuous actions for exploring
agent angle = -120.0
angle stg goal = -90.0
angle final goal = -67.34934904464058
-0.25 0.0 rel ang = -30.0
-----------------


======= labels_counter:  77
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 24.30454926593673
Distance to goal 68.0294054067798
Distance in cm: 340.147027033899 > 50.0
continuous actions for exploring
agent angle = -90.0
angle stg goal = -135.0
angle final goal = 24.30454926593673
-0.2 -0.2 rel ang = 45.0
-----------------


======= labels_counter:  78
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move toy_food from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -5.695450734063286
Distance to goal 68.0294054067798
Distance in cm: 340.147027033899 > 50.0
continuous actions for exploring
agent angle = -120.0
angle stg goal = -135.0
angle final goal = -5.695450734063286
-0.2 -0.2 rel ang = 15.0
-----------------


======= labels_counter:  79
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']


======= labels_counter:  80
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']


======= labels_counter:  81
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']


======= labels_counter:  82
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']


======= labels_counter:  83
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']


======= labels_counter:  84
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']


======= labels_counter:  85
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']


======= labels_counter:  86
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']


======= labels_counter:  87
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']


======= labels_counter:  88
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']


======= labels_counter:  89
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 72.38081796396342
Distance to goal 41.97618372363071
Distance in cm: 209.88091861815354 > 50.0
continuous actions for exploring
agent angle = 60.00006103515625
angle stg goal = 168.6900675259798
angle final goal = 72.38081796396342
0.05 -0.25 rel ang = -108.69000649082355
-----------------


======= labels_counter:  90
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 102.38081796396342
Distance to goal 41.97618372363071
Distance in cm: 209.88091861815354 > 50.0
continuous actions for exploring
agent angle = 90.00006103515625
angle stg goal = 168.6900675259798
angle final goal = 102.38081796396342
0.05 -0.25 rel ang = -78.69000649082352
-----------------


======= labels_counter:  91
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 132.38081796396344
Distance to goal 41.97618372363071
Distance in cm: 209.88091861815354 > 50.0
continuous actions for exploring
agent angle = 120.00006103515625
angle stg goal = 168.6900675259798
angle final goal = 132.38081796396344
0.05 -0.25 rel ang = -48.69000649082352
-----------------


======= labels_counter:  92
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 162.38081796396344
Distance to goal 41.97618372363071
Distance in cm: 209.88091861815354 > 50.0
continuous actions for exploring
agent angle = 150.00006103515625
angle stg goal = 168.6900675259798
angle final goal = 162.38081796396344
0.05 -0.25 rel ang = -18.69000649082352
-----------------


======= labels_counter:  93
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -167.61918203603656
Distance to goal 41.97618372363071
Distance in cm: 209.88091861815354 > 50.0
continuous actions for exploring
agent angle = -179.99993896484375
angle stg goal = 168.6900675259798
angle final goal = -167.61918203603656
0.05 -0.25 rel ang = 11.30999350917648
-----------------


======= labels_counter:  94
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -168.92973638690438
Distance to goal 46.87216658103186
Distance in cm: 234.36083290515933 > 50.0
continuous actions for exploring
agent angle = -179.99993896484375
angle stg goal = 143.13010235415598
angle final goal = -168.92973638690438
0.15000000000000002 -0.2 rel ang = 36.8699586810003
-----------------


======= labels_counter:  95
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 161.07026361309562
Distance to goal 46.87216658103186
Distance in cm: 234.36083290515933 > 50.0
continuous actions for exploring
agent angle = 150.00006103515625
angle stg goal = 168.6900675259798
angle final goal = 161.07026361309562
0.05 -0.25 rel ang = -18.69000649082352
-----------------


======= labels_counter:  96
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -168.92973638690438
Distance to goal 46.87216658103186
Distance in cm: 234.36083290515933 > 50.0
continuous actions for exploring
agent angle = -179.99993896484375
angle stg goal = 168.6900675259798
angle final goal = -168.92973638690438
0.05 -0.25 rel ang = 11.30999350917648
-----------------


======= labels_counter:  97
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -169.9919591634024
Distance to goal 51.78802950489621
Distance in cm: 258.94014752448106 > 50.0
continuous actions for exploring
agent angle = -179.99993896484375
angle stg goal = 168.6900675259798
angle final goal = -169.9919591634024
0.05 -0.25 rel ang = 11.30999350917648
-----------------


======= labels_counter:  98
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move gaming_console from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -28.61039863080896
Distance to goal 50.11985634456667
Distance in cm: 250.59928172283335 > 50.0
continuous actions for exploring
agent angle = -179.99993896484375
angle stg goal = 168.6900675259798
angle final goal = -28.61039863080896
0.05 -0.25 rel ang = 11.30999350917648
-----------------


======= labels_counter:  99
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']


======= labels_counter:  100
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']


======= labels_counter:  101
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']


======= labels_counter:  102
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']


======= labels_counter:  103
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']


======= labels_counter:  104
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']


======= labels_counter:  105
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']


======= labels_counter:  106
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']


======= labels_counter:  107
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']


======= labels_counter:  108
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']


======= labels_counter:  109
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 170.85445803957833
Distance to goal 22.47220505424423
Distance in cm: 112.36102527122115 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 143.13010235415598
angle final goal = 170.85445803957833
0.15000000000000002 -0.2 rel ang = -83.13010235415595
-----------------


======= labels_counter:  110
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -159.14554196042167
Distance to goal 22.47220505424423
Distance in cm: 112.36102527122115 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 143.13010235415598
angle final goal = -159.14554196042167
0.15000000000000002 -0.2 rel ang = -53.13010235415595
-----------------


======= labels_counter:  111
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -129.14554196042167
Distance to goal 22.47220505424423
Distance in cm: 112.36102527122115 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = 143.13010235415598
angle final goal = -129.14554196042167
0.15000000000000002 -0.2 rel ang = -23.13010235415595
-----------------


======= labels_counter:  112
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -99.14554196042167
Distance to goal 22.47220505424423
Distance in cm: 112.36102527122115 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 143.13010235415598
angle final goal = -99.14554196042167
0.15000000000000002 -0.2 rel ang = 6.86989764584402
-----------------


======= labels_counter:  113
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -102.34987578006985
Distance to goal 23.08679276123039
Distance in cm: 115.43396380615195 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 116.56505117707799
angle final goal = -102.34987578006985
0.2 -0.1 rel ang = 33.43494882292201
-----------------


======= labels_counter:  114
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -132.34987578006985
Distance to goal 23.08679276123039
Distance in cm: 115.43396380615195 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = 116.56505117707799
angle final goal = -132.34987578006985
0.2 -0.1 rel ang = 3.43494882292201
-----------------


======= labels_counter:  115
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -139.11447294534128
Distance to goal 26.476404589747453
Distance in cm: 132.38202294873727 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = 116.56505117707799
angle final goal = -139.11447294534128
0.2 -0.1 rel ang = 3.43494882292201
-----------------


======= labels_counter:  116
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 240)
  - delta = 4 0
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 76.6365770416167
Distance to goal 24.758836806279895
Distance in cm: 123.79418403139948 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = 90.0
angle final goal = 76.6365770416167
0.2 0.0 rel ang = 30.0
-----------------


======= labels_counter:  117
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 239)
  - delta = 4 -1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 52.69605172201657
Distance to goal 26.40075756488817
Distance in cm: 132.00378782444085 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 104.03624346792648
angle final goal = 52.69605172201657
0.2 -0.05 rel ang = -14.03624346792651
-----------------


======= labels_counter:  118
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candle_holder from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 239)
  - delta = 4 -1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 62.35402463626132
Distance to goal 23.706539182259394
Distance in cm: 118.53269591129697 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 104.03624346792648
angle final goal = 62.35402463626132
0.2 -0.05 rel ang = -14.03624346792651
-----------------


======= labels_counter:  119
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']


======= labels_counter:  120
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']


======= labels_counter:  121
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']


======= labels_counter:  122
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']


======= labels_counter:  123
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']


======= labels_counter:  124
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']


======= labels_counter:  125
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']


======= labels_counter:  126
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']


======= labels_counter:  127
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']


======= labels_counter:  128
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']


======= labels_counter:  129
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 61.39718102729638
Distance to goal 41.012193308819754
Distance in cm: 205.06096654409876 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 45.0
angle final goal = 61.39718102729638
0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  130
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 61.46880071438582
Distance to goal 39.01281840626232
Distance in cm: 195.0640920313116 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 45.0
angle final goal = 61.46880071438582
0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  131
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 51.86989764584402
Distance to goal 35.35533905932738
Distance in cm: 176.7766952966369 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 45.0
angle final goal = 51.86989764584402
0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  132
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 58.264295411071615
Distance to goal 33.015148038438355
Distance in cm: 165.07574019219177 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 45.0
angle final goal = 58.264295411071615
0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  133
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (242, 243)
  - delta = 2 3
Distance (m): 0.18027756377319945
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 58.264295411071615
Distance to goal 33.015148038438355
Distance in cm: 165.07574019219177 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 33.690067525979785
angle final goal = 58.264295411071615
0.1 0.15000000000000002 rel ang = 26.309932474020215
-----------------


======= labels_counter:  134
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (242, 243)
  - delta = 2 3
Distance (m): 0.18027756377319945
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 33.3664606634298
Distance to goal 34.058772731852805
Distance in cm: 170.29386365926402 > 50.0
continuous actions for exploring
agent angle = 30.0
angle stg goal = 33.690067525979785
angle final goal = 33.3664606634298
0.1 0.15000000000000002 rel ang = -3.690067525979771
-----------------


======= labels_counter:  135
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 240)
  - delta = 4 0
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 33.3664606634298
Distance to goal 34.058772731852805
Distance in cm: 170.29386365926402 > 50.0
continuous actions for exploring
agent angle = 30.0
angle stg goal = 90.0
angle final goal = 33.3664606634298
0.2 0.0 rel ang = -60.0
-----------------


======= labels_counter:  136
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 240)
  - delta = 4 0
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 63.3664606634298
Distance to goal 34.058772731852805
Distance in cm: 170.29386365926402 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 90.0
angle final goal = 63.3664606634298
0.2 0.0 rel ang = -30.0
-----------------


======= labels_counter:  137
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 240)
  - delta = 4 0
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 93.3664606634298
Distance to goal 34.058772731852805
Distance in cm: 170.29386365926402 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 90.0
angle final goal = 93.3664606634298
0.2 0.0 rel ang = 0.0
-----------------


======= labels_counter:  138
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move scissors from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 101.63363399894044
Distance to goal 34.713109915419565
Distance in cm: 173.56554957709784 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 14.036243467926479
angle final goal = 101.63363399894044
0.05 0.2 rel ang = 75.96375653207352
-----------------


======= labels_counter:  139
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']


======= labels_counter:  140
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']


======= labels_counter:  141
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']


======= labels_counter:  142
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']


======= labels_counter:  143
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']


======= labels_counter:  144
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']


======= labels_counter:  145
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']


======= labels_counter:  146
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']


======= labels_counter:  147
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']


======= labels_counter:  148
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']


======= labels_counter:  149
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 235)
  - delta = -1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 74.93144769571568
Distance to goal 31.04834939252005
Distance in cm: 155.24174696260025 > 50.0
continuous actions for exploring
agent angle = 60.000030517578125
angle stg goal = -168.6900675259798
angle final goal = 74.93144769571568
-0.05 -0.25 rel ang = -131.30990195644208
-----------------


======= labels_counter:  150
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 235)
  - delta = -1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 104.93141717813755
Distance to goal 31.04834939252005
Distance in cm: 155.24174696260025 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = -168.6900675259798
angle final goal = 104.93141717813755
-0.05 -0.25 rel ang = -101.30993247402023
-----------------


======= labels_counter:  151
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 235)
  - delta = -1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 134.93138666055944
Distance to goal 31.04834939252005
Distance in cm: 155.24174696260025 > 50.0
continuous actions for exploring
agent angle = 119.99996948242188
angle stg goal = -168.6900675259798
angle final goal = 134.93138666055944
-0.05 -0.25 rel ang = -71.30996299159835
-----------------


======= labels_counter:  152
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 235)
  - delta = -1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 164.93138666055944
Distance to goal 31.04834939252005
Distance in cm: 155.24174696260025 > 50.0
continuous actions for exploring
agent angle = 149.99996948242188
angle stg goal = -168.6900675259798
angle final goal = 164.93138666055944
-0.05 -0.25 rel ang = -41.309962991598354
-----------------


======= labels_counter:  153
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 235)
  - delta = -1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -165.06858282186244
Distance to goal 31.04834939252005
Distance in cm: 155.24174696260025 > 50.0
continuous actions for exploring
agent angle = 180.0
angle stg goal = -168.6900675259798
angle final goal = -165.06858282186244
-0.05 -0.25 rel ang = -11.30993247402023
-----------------


======= labels_counter:  154
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -167.12499844038751
Distance to goal 35.90264614203248
Distance in cm: 179.51323071016242 > 50.0
continuous actions for exploring
agent angle = 180.0
angle stg goal = 168.6900675259798
angle final goal = -167.12499844038751
0.05 -0.25 rel ang = 11.3099324740202
-----------------


======= labels_counter:  155
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -168.6900675259798
Distance to goal 40.792156108742276
Distance in cm: 203.9607805437114 > 50.0
continuous actions for exploring
agent angle = 180.0
angle stg goal = 168.6900675259798
angle final goal = -168.6900675259798
0.05 -0.25 rel ang = 11.3099324740202
-----------------


======= labels_counter:  156
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -169.91940201245768
Distance to goal 45.70557952810576
Distance in cm: 228.5278976405288 > 50.0
continuous actions for exploring
agent angle = 180.0
angle stg goal = 168.6900675259798
angle final goal = -169.91940201245768
0.05 -0.25 rel ang = 11.3099324740202
-----------------


======= labels_counter:  157
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -170.90972307917767
Distance to goal 50.635955604688654
Distance in cm: 253.17977802344328 > 50.0
continuous actions for exploring
agent angle = 180.0
angle stg goal = 168.6900675259798
angle final goal = -170.90972307917767
0.05 -0.25 rel ang = 11.3099324740202
-----------------


======= labels_counter:  158
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 19
[ObjectNav] Goal name:  ['Move screwdriver from chest_of_drawers to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -45.0
Distance to goal 53.74011537017761
Distance in cm: 268.70057685088807 > 50.0
continuous actions for exploring
agent angle = 180.0
angle stg goal = 168.6900675259798
angle final goal = -45.0
0.05 -0.25 rel ang = 11.3099324740202
-----------------


======= labels_counter:  159
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']


======= labels_counter:  160
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']


======= labels_counter:  161
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']


======= labels_counter:  162
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']


======= labels_counter:  163
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']


======= labels_counter:  164
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']


======= labels_counter:  165
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']


======= labels_counter:  166
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']


======= labels_counter:  167
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']


======= labels_counter:  168
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']


======= labels_counter:  169
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 92.47122280842662
Distance to goal 39.11521443121589
Distance in cm: 195.57607215607945 > 50.0
continuous actions for exploring
agent angle = 60.000030517578125
angle stg goal = -78.69006752597979
angle final goal = 92.47122280842662
-0.25 0.05 rel ang = 138.6900980435579
-----------------


======= labels_counter:  170
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 62.47122280842662
Distance to goal 39.11521443121589
Distance in cm: 195.57607215607945 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = -78.69006752597979
angle final goal = 62.47122280842662
-0.25 0.05 rel ang = 108.69009804355791
-----------------


======= labels_counter:  171
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 32.47122280842662
Distance to goal 39.11521443121589
Distance in cm: 195.57607215607945 > 50.0
continuous actions for exploring
agent angle = 3.0517578125e-05
angle stg goal = -78.69006752597979
angle final goal = 32.47122280842662
-0.25 0.05 rel ang = 78.69009804355791
-----------------


======= labels_counter:  172
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 2.4712533260047422
Distance to goal 39.11521443121589
Distance in cm: 195.57607215607945 > 50.0
continuous actions for exploring
agent angle = -29.99993896484375
angle stg goal = -78.69006752597979
angle final goal = 2.4712533260047422
-0.25 0.05 rel ang = 48.690128561136035
-----------------


======= labels_counter:  173
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -27.52873141520621
Distance to goal 39.11521443121589
Distance in cm: 195.57607215607945 > 50.0
continuous actions for exploring
agent angle = -59.99992370605469
angle stg goal = -78.69006752597979
angle final goal = -27.52873141520621
-0.25 0.05 rel ang = 18.690143819925098
-----------------


======= labels_counter:  174
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -57.52874667399527
Distance to goal 39.11521443121589
Distance in cm: 195.57607215607945 > 50.0
continuous actions for exploring
agent angle = -89.99993896484375
angle stg goal = -78.69006752597979
angle final goal = -57.52874667399527
-0.25 0.05 rel ang = -11.30987143886398
-----------------


======= labels_counter:  175
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 43.91913684849558
Distance to goal 37.48332962798263
Distance in cm: 187.41664813991315 > 50.0
continuous actions for exploring
agent angle = -89.99993896484375
angle stg goal = -53.13010235415598
angle final goal = 43.91913684849558
-0.2 0.15000000000000002 rel ang = -36.8698366106878
-----------------


======= labels_counter:  176
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 73.91913684849558
Distance to goal 37.48332962798263
Distance in cm: 187.41664813991315 > 50.0
continuous actions for exploring
agent angle = -59.99993896484375
angle stg goal = -53.13010235415598
angle final goal = 73.91913684849558
-0.2 0.15000000000000002 rel ang = -6.869836610687798
-----------------


======= labels_counter:  177
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 79.5739822950571
Distance to goal 35.4682957019364
Distance in cm: 177.341478509682 > 50.0
continuous actions for exploring
agent angle = -59.99993896484375
angle stg goal = -53.13010235415598
angle final goal = 79.5739822950571
-0.2 0.15000000000000002 rel ang = -6.869836610687798
-----------------


======= labels_counter:  178
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -52.4052955962523
Distance to goal 30.265491900843113
Distance in cm: 151.32745950421557 > 50.0
continuous actions for exploring
agent angle = -59.99993896484375
angle stg goal = -78.69006752597979
angle final goal = -52.4052955962523
-0.25 0.05 rel ang = 18.690128561136035
-----------------


======= labels_counter:  179
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']


======= labels_counter:  180
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']


======= labels_counter:  181
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']


======= labels_counter:  182
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']


======= labels_counter:  183
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']


======= labels_counter:  184
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']


======= labels_counter:  185
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']


======= labels_counter:  186
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']


======= labels_counter:  187
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']


======= labels_counter:  188
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']


======= labels_counter:  189
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -137.44720368207126
Distance to goal 36.68787265568828
Distance in cm: 183.43936327844142 > 50.0
continuous actions for exploring
agent angle = 59.99998474121094
angle stg goal = 45.0
angle final goal = -137.44720368207126
0.15000000000000002 0.15000000000000002 rel ang = 14.999984741210938
-----------------


======= labels_counter:  190
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -131.5921906690801
Distance to goal 39.81205847478876
Distance in cm: 199.0602923739438 > 50.0
continuous actions for exploring
agent angle = 59.99998474121094
angle stg goal = 14.036243467926479
angle final goal = -131.5921906690801
0.05 0.2 rel ang = 45.963741273284455
-----------------


======= labels_counter:  191
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -161.5921906690801
Distance to goal 39.81205847478876
Distance in cm: 199.0602923739438 > 50.0
continuous actions for exploring
agent angle = 29.999984741210938
angle stg goal = -26.56505117707799
angle final goal = -161.5921906690801
-0.1 0.2 rel ang = 56.56503591828893
-----------------


======= labels_counter:  192
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 168.4078093309199
Distance to goal 39.81205847478876
Distance in cm: 199.0602923739438 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = -26.56505117707799
angle final goal = 168.4078093309199
-0.1 0.2 rel ang = 26.565035918288928
-----------------


======= labels_counter:  193
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 138.4078093309199
Distance to goal 39.81205847478876
Distance in cm: 199.0602923739438 > 50.0
continuous actions for exploring
agent angle = -30.000015258789062
angle stg goal = -26.56505117707799
angle final goal = 138.4078093309199
-0.1 0.2 rel ang = -3.4349640817110867
-----------------


======= labels_counter:  194
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 90.96374127328446
Distance to goal 40.8166632639171
Distance in cm: 204.0833163195855 > 50.0
continuous actions for exploring
agent angle = -30.000015258789062
angle stg goal = -26.56505117707799
angle final goal = 90.96374127328446
-0.1 0.2 rel ang = -3.4349640817110867
-----------------


======= labels_counter:  195
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 98.23380991865787
Distance to goal 42.01190307520001
Distance in cm: 210.05951537600004 > 50.0
continuous actions for exploring
agent angle = -30.000015258789062
angle stg goal = 0.0
angle final goal = 98.23380991865787
0.0 0.2 rel ang = -30.000015258789062
-----------------


======= labels_counter:  196
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 128.23380991865787
Distance to goal 42.01190307520001
Distance in cm: 210.05951537600004 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = 0.0
angle final goal = 128.23380991865787
0.0 0.2 rel ang = -1.52587890625e-05
-----------------


======= labels_counter:  197
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 80.31119818084414
Distance to goal 41.593268686170845
Distance in cm: 207.96634343085424 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = 0.0
angle final goal = 80.31119818084414
0.0 0.2 rel ang = -1.52587890625e-05
-----------------


======= labels_counter:  198
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move spectacles from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 77.00536794929444
Distance to goal 40.024992192379
Distance in cm: 200.124960961895 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = 0.0
angle final goal = 77.00536794929444
0.0 0.2 rel ang = -1.52587890625e-05
-----------------


======= labels_counter:  199
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']


======= labels_counter:  200
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']


======= labels_counter:  201
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']


======= labels_counter:  202
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']


======= labels_counter:  203
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']


======= labels_counter:  204
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']


======= labels_counter:  205
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']


======= labels_counter:  206
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']


======= labels_counter:  207
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']


======= labels_counter:  208
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']


======= labels_counter:  209
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 25.124702172975944
Distance to goal 40.22437072223753
Distance in cm: 201.12185361118765 > 50.0
continuous actions for exploring
agent angle = 60.000030517578125
angle stg goal = -53.13010235415598
angle final goal = 25.124702172975944
-0.2 0.15000000000000002 rel ang = 113.1301328717341
-----------------


======= labels_counter:  210
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -4.875297827024042
Distance to goal 40.22437072223753
Distance in cm: 201.12185361118765 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = -53.13010235415598
angle final goal = -4.875297827024042
-0.2 0.15000000000000002 rel ang = 83.1301328717341
-----------------


======= labels_counter:  211
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -34.87529782702404
Distance to goal 40.22437072223753
Distance in cm: 201.12185361118765 > 50.0
continuous actions for exploring
agent angle = 3.0517578125e-05
angle stg goal = -53.13010235415598
angle final goal = -34.87529782702404
-0.2 0.15000000000000002 rel ang = 53.130132871734105
-----------------


======= labels_counter:  212
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -64.87529782702404
Distance to goal 40.22437072223753
Distance in cm: 201.12185361118765 > 50.0
continuous actions for exploring
agent angle = -29.999969482421875
angle stg goal = -53.13010235415598
angle final goal = -64.87529782702404
-0.2 0.15000000000000002 rel ang = 23.130132871734105
-----------------


======= labels_counter:  213
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -94.87529782702404
Distance to goal 40.22437072223753
Distance in cm: 201.12185361118765 > 50.0
continuous actions for exploring
agent angle = -59.999969482421875
angle stg goal = -53.13010235415598
angle final goal = -94.87529782702404
-0.2 0.15000000000000002 rel ang = -6.869867128265923
-----------------


======= labels_counter:  214
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -102.08913165625415
Distance to goal 41.773197148410844
Distance in cm: 208.86598574205422 > 50.0
continuous actions for exploring
agent angle = -59.999969482421875
angle stg goal = -53.13010235415598
angle final goal = -102.08913165625415
-0.2 0.15000000000000002 rel ang = -6.869867128265923
-----------------


======= labels_counter:  215
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -95.2175624506146
Distance to goal 41.617304093369626
Distance in cm: 208.08652046684813 > 50.0
continuous actions for exploring
agent angle = -59.999969482421875
angle stg goal = -26.56505117707799
angle final goal = -95.2175624506146
-0.1 0.2 rel ang = -33.4349183053439
-----------------


======= labels_counter:  216
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -65.21757770940366
Distance to goal 41.617304093369626
Distance in cm: 208.08652046684813 > 50.0
continuous actions for exploring
agent angle = -29.999984741210938
angle stg goal = -26.56505117707799
angle final goal = -65.21757770940366
-0.1 0.2 rel ang = -3.4349335641329617
-----------------


======= labels_counter:  217
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -61.701414410716666
Distance to goal 39.96248240537617
Distance in cm: 199.81241202688085 > 50.0
continuous actions for exploring
agent angle = -29.999984741210938
angle stg goal = -53.13010235415598
angle final goal = -61.701414410716666
-0.2 0.15000000000000002 rel ang = 23.130117612945043
-----------------


======= labels_counter:  218
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -91.70142966950573
Distance to goal 39.96248240537617
Distance in cm: 199.81241202688085 > 50.0
continuous actions for exploring
agent angle = -60.0
angle stg goal = -53.13010235415598
angle final goal = -91.70142966950573
-0.2 0.15000000000000002 rel ang = -6.869897645844048
-----------------


======= labels_counter:  219
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']


======= labels_counter:  220
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']


======= labels_counter:  221
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']


======= labels_counter:  222
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']


======= labels_counter:  223
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']


======= labels_counter:  224
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']


======= labels_counter:  225
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']


======= labels_counter:  226
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']


======= labels_counter:  227
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']


======= labels_counter:  228
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']


======= labels_counter:  229
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: True
reduced obs dilation to 2
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -104.47585848566763
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 60.000030517578125
angle stg goal = -135.0
angle final goal = -104.47585848566763
-0.2 -0.2 rel ang = -164.99996948242188
-----------------


======= labels_counter:  230
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -74.47588900324575
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 45.0
angle final goal = -74.47588900324575
0.15000000000000002 0.15000000000000002 rel ang = 45.0
-----------------


======= labels_counter:  231
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -104.47591952082388
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 45.0
angle final goal = -104.47591952082388
0.15000000000000002 0.15000000000000002 rel ang = 14.999969482421875
-----------------


======= labels_counter:  232
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -117.13762529146638
Distance to goal 20.024984394500787
Distance in cm: 100.12492197250394 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 143.13010235415598
angle final goal = -117.13762529146638
0.15000000000000002 -0.2 rel ang = -83.13013287173408
-----------------


======= labels_counter:  233
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -87.1376252914664
Distance to goal 20.024984394500787
Distance in cm: 100.12492197250394 > 50.0
continuous actions for exploring
agent angle = 89.99996948242188
angle stg goal = 143.13010235415598
angle final goal = -87.1376252914664
0.15000000000000002 -0.2 rel ang = -53.13013287173408
-----------------


======= labels_counter:  234
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -62.72634151148441
Distance to goal 21.02379604162864
Distance in cm: 105.1189802081432 > 50.0
continuous actions for exploring
agent angle = 119.99996948242188
angle stg goal = 143.13010235415598
angle final goal = -62.72634151148441
0.15000000000000002 -0.2 rel ang = -23.130132871734077
-----------------


======= labels_counter:  235
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -32.72634151148441
Distance to goal 21.02379604162864
Distance in cm: 105.1189802081432 > 50.0
continuous actions for exploring
agent angle = 149.99996948242188
angle stg goal = 143.13010235415598
angle final goal = -32.72634151148441
0.15000000000000002 -0.2 rel ang = 6.869867128265895
-----------------


======= labels_counter:  236
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -32.72634151148441
Distance to goal 21.02379604162864
Distance in cm: 105.1189802081432 > 50.0
continuous actions for exploring
agent angle = 149.99996948242188
angle stg goal = 116.56505117707799
angle final goal = -32.72634151148441
0.2 -0.1 rel ang = 33.434918305343885
-----------------


======= labels_counter:  237
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -62.72634151148441
Distance to goal 21.02379604162864
Distance in cm: 105.1189802081432 > 50.0
continuous actions for exploring
agent angle = 119.99996948242188
angle stg goal = 116.56505117707799
angle final goal = -62.72634151148441
0.2 -0.1 rel ang = 3.434918305343885
-----------------


======= labels_counter:  238
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move picture_frame from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -62.72634151148441
Distance to goal 21.02379604162864
Distance in cm: 105.1189802081432 > 50.0
continuous actions for exploring
agent angle = 119.99996948242188
angle stg goal = 75.96375653207353
angle final goal = -62.72634151148441
0.2 0.05 rel ang = 44.03621295034834
-----------------


======= labels_counter:  239
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  240
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  241
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  242
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  243
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  244
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  245
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  246
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  247
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  248
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  249
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -103.14160123226173
Distance to goal 34.48187929913333
Distance in cm: 172.40939649566667 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 75.96375653207353
angle final goal = -103.14160123226173
0.2 0.05 rel ang = -15.963756532073546
-----------------


======= labels_counter:  250
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -73.14160123226173
Distance to goal 34.48187929913333
Distance in cm: 172.40939649566667 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = -73.14160123226173
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  251
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -68.19859051364818
Distance to goal 32.31098884280702
Distance in cm: 161.55494421403512 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 45.0
angle final goal = -68.19859051364818
0.15000000000000002 0.15000000000000002 rel ang = 45.0
-----------------


======= labels_counter:  252
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -98.19859051364818
Distance to goal 32.31098884280702
Distance in cm: 161.55494421403512 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 45.0
angle final goal = -98.19859051364818
0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  253
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -105.96375653207352
Distance to goal 32.984845004941285
Distance in cm: 164.92422502470643 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 0.0
angle final goal = -105.96375653207352
0.0 0.2 rel ang = 60.0
-----------------


======= labels_counter:  254
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -135.96375653207352
Distance to goal 32.984845004941285
Distance in cm: 164.92422502470643 > 50.0
continuous actions for exploring
agent angle = 30.0
angle stg goal = 0.0
angle final goal = -135.96375653207352
0.0 0.2 rel ang = 30.0
-----------------


======= labels_counter:  255
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -165.96377179086258
Distance to goal 32.984845004941285
Distance in cm: 164.92422502470643 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = -111.80140948635182
angle final goal = -165.96377179086258
-0.25 -0.1 rel ang = 111.80139422756275
-----------------


======= labels_counter:  256
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 164.03622820913742
Distance to goal 32.984845004941285
Distance in cm: 164.92422502470643 > 50.0
continuous actions for exploring
agent angle = -30.000015258789062
angle stg goal = -111.80140948635182
angle final goal = 164.03622820913742
-0.25 -0.1 rel ang = 81.80139422756275
-----------------


======= labels_counter:  257
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 134.03624346792648
Distance to goal 32.984845004941285
Distance in cm: 164.92422502470643 > 50.0
continuous actions for exploring
agent angle = -60.0
angle stg goal = -111.80140948635182
angle final goal = 134.03624346792648
-0.25 -0.1 rel ang = 51.801409486351815
-----------------


======= labels_counter:  258
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 104.03624346792648
Distance to goal 32.984845004941285
Distance in cm: 164.92422502470643 > 50.0
continuous actions for exploring
agent angle = -90.0
angle stg goal = -111.80140948635182
angle final goal = 104.03624346792648
-0.25 -0.1 rel ang = 21.801409486351815
-----------------


======= labels_counter:  259
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']


======= labels_counter:  260
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']


======= labels_counter:  261
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']


======= labels_counter:  262
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']


======= labels_counter:  263
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']


======= labels_counter:  264
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']


======= labels_counter:  265
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']


======= labels_counter:  266
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']


======= labels_counter:  267
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']


======= labels_counter:  268
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']


======= labels_counter:  269
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -160.60129464500446
Distance to goal 36.87817782917155
Distance in cm: 184.39088914585773 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = -111.80140948635182
angle final goal = -160.60129464500446
-0.25 -0.1 rel ang = 171.80140948635182
-----------------


======= labels_counter:  270
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 169.39870535499554
Distance to goal 36.87817782917155
Distance in cm: 184.39088914585773 > 50.0
continuous actions for exploring
agent angle = 30.0
angle stg goal = -111.80140948635182
angle final goal = 169.39870535499554
-0.25 -0.1 rel ang = 141.80140948635182
-----------------


======= labels_counter:  271
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 139.39867483741742
Distance to goal 36.87817782917155
Distance in cm: 184.39088914585773 > 50.0
continuous actions for exploring
agent angle = -3.0517578125e-05
angle stg goal = -111.80140948635182
angle final goal = 139.39867483741742
-0.25 -0.1 rel ang = 111.80137896877369
-----------------


======= labels_counter:  272
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 109.39867483741742
Distance to goal 36.87817782917155
Distance in cm: 184.39088914585773 > 50.0
continuous actions for exploring
agent angle = -30.000030517578125
angle stg goal = -111.80140948635182
angle final goal = 109.39867483741742
-0.25 -0.1 rel ang = 81.80137896877369
-----------------


======= labels_counter:  273
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 79.39867483741742
Distance to goal 36.87817782917155
Distance in cm: 184.39088914585773 > 50.0
continuous actions for exploring
agent angle = -60.000030517578125
angle stg goal = -111.80140948635182
angle final goal = 79.39867483741742
-0.25 -0.1 rel ang = 51.80137896877369
-----------------


======= labels_counter:  274
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 49.39870535499554
Distance to goal 36.87817782917155
Distance in cm: 184.39088914585773 > 50.0
continuous actions for exploring
agent angle = -90.0
angle stg goal = -111.80140948635182
angle final goal = 49.39870535499554
-0.25 -0.1 rel ang = 21.801409486351815
-----------------


======= labels_counter:  275
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 19.398705354995542
Distance to goal 36.87817782917155
Distance in cm: 184.39088914585773 > 50.0
continuous actions for exploring
agent angle = -120.0
angle stg goal = -111.80140948635182
angle final goal = 19.398705354995542
-0.25 -0.1 rel ang = -8.198590513648185
-----------------


======= labels_counter:  276
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 22.765166018425333
Distance to goal 31.400636936215164
Distance in cm: 157.00318468107582 > 50.0
continuous actions for exploring
agent angle = -120.0
angle stg goal = -111.80140948635182
angle final goal = 22.765166018425333
-0.25 -0.1 rel ang = -8.198590513648185
-----------------


======= labels_counter:  277
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 26.888658039627984
Distance to goal 27.459060435491963
Distance in cm: 137.2953021774598 > 50.0
continuous actions for exploring
agent angle = -120.0
angle stg goal = -111.80140948635182
angle final goal = 26.888658039627984
-0.25 -0.1 rel ang = -8.198590513648185
-----------------


======= labels_counter:  278
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move fork from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 31.18920625702694
Distance to goal 22.825424421026653
Distance in cm: 114.12712210513327 > 50.0
continuous actions for exploring
agent angle = -120.0
angle stg goal = -78.69006752597979
angle final goal = 31.18920625702694
-0.25 0.05 rel ang = -41.30993247402023
-----------------


======= labels_counter:  279
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']


======= labels_counter:  280
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']


======= labels_counter:  281
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']


======= labels_counter:  282
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']


======= labels_counter:  283
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']


======= labels_counter:  284
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']


======= labels_counter:  285
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']


======= labels_counter:  286
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']


======= labels_counter:  287
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']


======= labels_counter:  288
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']


======= labels_counter:  289
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -32.29070159537292
Distance to goal 25.019992006393608
Distance in cm: 125.09996003196804 > 50.0
continuous actions for exploring
agent angle = 59.999908447265625
angle stg goal = -26.56505117707799
angle final goal = -32.29070159537292
-0.1 0.2 rel ang = 86.56495962434362
-----------------


======= labels_counter:  290
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -62.29068633658386
Distance to goal 25.019992006393608
Distance in cm: 125.09996003196804 > 50.0
continuous actions for exploring
agent angle = 29.999923706054688
angle stg goal = -26.56505117707799
angle final goal = -62.29068633658386
-0.1 0.2 rel ang = 56.56497488313268
-----------------


======= labels_counter:  291
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -92.29068633658386
Distance to goal 25.019992006393608
Distance in cm: 125.09996003196804 > 50.0
continuous actions for exploring
agent angle = -7.62939453125e-05
angle stg goal = -26.56505117707799
angle final goal = -92.29068633658386
-0.1 0.2 rel ang = 26.564974883132678
-----------------


======= labels_counter:  292
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -122.29070159537292
Distance to goal 25.019992006393608
Distance in cm: 125.09996003196804 > 50.0
continuous actions for exploring
agent angle = -30.000091552734375
angle stg goal = -26.56505117707799
angle final goal = -122.29070159537292
-0.1 0.2 rel ang = -3.435040375656399
-----------------


======= labels_counter:  293
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -113.65989980682446
Distance to goal 27.16615541441225
Distance in cm: 135.83077707206124 > 50.0
continuous actions for exploring
agent angle = -30.000091552734375
angle stg goal = 0.0
angle final goal = -113.65989980682446
0.0 0.2 rel ang = -30.000091552734375
-----------------


======= labels_counter:  294
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -83.65989980682446
Distance to goal 27.16615541441225
Distance in cm: 135.83077707206124 > 50.0
continuous actions for exploring
agent angle = -9.1552734375e-05
angle stg goal = 0.0
angle final goal = -83.65989980682446
0.0 0.2 rel ang = -9.1552734375e-05
-----------------


======= labels_counter:  295
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -92.12118794939585
Distance to goal 27.018512172212592
Distance in cm: 135.09256086106296 > 50.0
continuous actions for exploring
agent angle = -9.1552734375e-05
angle stg goal = 14.036243467926479
angle final goal = -92.12118794939585
0.05 0.2 rel ang = -14.036335020660829
-----------------


======= labels_counter:  296
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -100.49156856506596
Distance to goal 27.459060435491963
Distance in cm: 137.2953021774598 > 50.0
continuous actions for exploring
agent angle = -9.1552734375e-05
angle stg goal = 45.0
angle final goal = -100.49156856506596
0.15000000000000002 0.15000000000000002 rel ang = -45.000091552734375
-----------------


======= labels_counter:  297
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -70.4915533062769
Distance to goal 27.459060435491963
Distance in cm: 137.2953021774598 > 50.0
continuous actions for exploring
agent angle = 29.999923706054688
angle stg goal = 45.0
angle final goal = -70.4915533062769
0.15000000000000002 0.15000000000000002 rel ang = -15.000076293945312
-----------------


======= labels_counter:  298
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move keychain from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -40.4915533062769
Distance to goal 27.459060435491963
Distance in cm: 137.2953021774598 > 50.0
continuous actions for exploring
agent angle = 59.99992370605469
angle stg goal = 14.036243467926479
angle final goal = -40.4915533062769
0.05 0.2 rel ang = 45.963680238128205
-----------------


======= labels_counter:  299
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']


======= labels_counter:  300
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']


======= labels_counter:  301
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']


======= labels_counter:  302
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']


======= labels_counter:  303
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']


======= labels_counter:  304
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']


======= labels_counter:  305
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']


======= labels_counter:  306
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']


======= labels_counter:  307
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']


======= labels_counter:  308
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']


======= labels_counter:  309
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -100.01690873688909
Distance to goal 23.40939982143925
Distance in cm: 117.04699910719626 > 50.0
continuous actions for exploring
agent angle = 59.99998474121094
angle stg goal = -26.56505117707799
angle final goal = -100.01690873688909
-0.1 0.2 rel ang = 86.56503591828893
-----------------


======= labels_counter:  310
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -130.0169087368891
Distance to goal 23.40939982143925
Distance in cm: 117.04699910719626 > 50.0
continuous actions for exploring
agent angle = 29.999984741210938
angle stg goal = -26.56505117707799
angle final goal = -130.0169087368891
-0.1 0.2 rel ang = 56.56503591828893
-----------------


======= labels_counter:  311
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -160.0169087368891
Distance to goal 23.40939982143925
Distance in cm: 117.04699910719626 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = -26.56505117707799
angle final goal = -160.0169087368891
-0.1 0.2 rel ang = 26.565035918288928
-----------------


======= labels_counter:  312
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 169.9830912631109
Distance to goal 23.40939982143925
Distance in cm: 117.04699910719626 > 50.0
continuous actions for exploring
agent angle = -30.000015258789062
angle stg goal = -26.56505117707799
angle final goal = 169.9830912631109
-0.1 0.2 rel ang = -3.4349640817110867
-----------------


======= labels_counter:  313
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 160.12465639660874
Distance to goal 28.442925306655784
Distance in cm: 142.21462653327893 > 50.0
continuous actions for exploring
agent angle = -30.000015258789062
angle stg goal = -26.56505117707799
angle final goal = 160.12465639660874
-0.1 0.2 rel ang = -3.4349640817110867
-----------------


======= labels_counter:  314
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 162.33907201953713
Distance to goal 32.7566787083184
Distance in cm: 163.78339354159198 > 50.0
continuous actions for exploring
agent angle = -30.000015258789062
angle stg goal = 0.0
angle final goal = 162.33907201953713
0.0 0.2 rel ang = -30.000015258789062
-----------------


======= labels_counter:  315
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -167.6609127216738
Distance to goal 32.7566787083184
Distance in cm: 163.78339354159198 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = 0.0
angle final goal = -167.6609127216738
0.0 0.2 rel ang = 0.0
-----------------


======= labels_counter:  316
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -48.50353164478446
Distance to goal 34.713109915419565
Distance in cm: 173.56554957709784 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = 0.0
angle final goal = -48.50353164478446
0.0 0.2 rel ang = 0.0
-----------------


======= labels_counter:  317
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -55.304846468766016
Distance to goal 31.622776601683793
Distance in cm: 158.11388300841895 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = 14.036243467926479
angle final goal = -55.304846468766016
0.05 0.2 rel ang = -14.036243467926454
-----------------


======= labels_counter:  318
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move box from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -55.304846468766016
Distance to goal 31.622776601683793
Distance in cm: 158.11388300841895 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = -26.56505117707799
angle final goal = -55.304846468766016
-0.1 0.2 rel ang = 26.56505117707799
-----------------


======= labels_counter:  319
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']


======= labels_counter:  320
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']


======= labels_counter:  321
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']


======= labels_counter:  322
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']


======= labels_counter:  323
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']


======= labels_counter:  324
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']


======= labels_counter:  325
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']


======= labels_counter:  326
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']


======= labels_counter:  327
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']


======= labels_counter:  328
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']


======= labels_counter:  329
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 127.16631530450432
Distance to goal 20.615528128088304
Distance in cm: 103.07764064044152 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 45.0
angle final goal = 127.16631530450432
0.15000000000000002 0.15000000000000002 rel ang = 14.999969482421875
-----------------


======= labels_counter:  330
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 135.3790954937902
Distance to goal 23.769728648009426
Distance in cm: 118.84864324004712 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 45.0
angle final goal = 135.3790954937902
0.15000000000000002 0.15000000000000002 rel ang = 14.999969482421875
-----------------


======= labels_counter:  331
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 143.65977773651196
Distance to goal 27.16615541441225
Distance in cm: 135.83077707206124 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 45.0
angle final goal = 143.65977773651196
0.15000000000000002 0.15000000000000002 rel ang = 14.999969482421875
-----------------


======= labels_counter:  332
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 148.15235921642727
Distance to goal 31.016124838541646
Distance in cm: 155.08062419270823 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 45.0
angle final goal = 148.15235921642727
0.15000000000000002 0.15000000000000002 rel ang = 14.999969482421875
-----------------


======= labels_counter:  333
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 67.8532827844001
Distance to goal 29.274562336608895
Distance in cm: 146.37281168304446 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 14.036243467926479
angle final goal = 67.8532827844001
0.05 0.2 rel ang = 45.96372601449539
-----------------


======= labels_counter:  334
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 41.68933865786107
Distance to goal 29.614185789921695
Distance in cm: 148.0709289496085 > 50.0
continuous actions for exploring
agent angle = 29.999969482421875
angle stg goal = 45.0
angle final goal = 41.68933865786107
0.15000000000000002 0.15000000000000002 rel ang = -15.000030517578125
-----------------


======= labels_counter:  335
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 71.68933865786107
Distance to goal 29.614185789921695
Distance in cm: 148.0709289496085 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 45.0
angle final goal = 71.68933865786107
0.15000000000000002 0.15000000000000002 rel ang = 14.999969482421875
-----------------


======= labels_counter:  336
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 80.32310631208482
Distance to goal 28.792360097775937
Distance in cm: 143.96180048887967 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 14.036243467926479
angle final goal = 80.32310631208482
0.05 0.2 rel ang = 45.96372601449539
-----------------


======= labels_counter:  337
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 51.44770580952722
Distance to goal 30.083217912982647
Distance in cm: 150.41608956491325 > 50.0
continuous actions for exploring
agent angle = 29.999969482421875
angle stg goal = 14.036243467926479
angle final goal = 51.44770580952722
0.05 0.2 rel ang = 15.963726014495396
-----------------


======= labels_counter:  338
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bread from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 21.447705809527225
Distance to goal 30.083217912982647
Distance in cm: 150.41608956491325 > 50.0
continuous actions for exploring
agent angle = -3.0517578125e-05
angle stg goal = 45.0
angle final goal = 21.447705809527225
0.15000000000000002 0.15000000000000002 rel ang = -45.000030517578125
-----------------


======= labels_counter:  339
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']


======= labels_counter:  340
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']


======= labels_counter:  341
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']


======= labels_counter:  342
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']


======= labels_counter:  343
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']


======= labels_counter:  344
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']


======= labels_counter:  345
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']


======= labels_counter:  346
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']


======= labels_counter:  347
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']


======= labels_counter:  348
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']


======= labels_counter:  349
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -120.00006103515625
Distance to goal 34.0
Distance in cm: 170.0 > 50.0
continuous actions for exploring
agent angle = 59.99993896484375
angle stg goal = 45.0
angle final goal = -120.00006103515625
0.15000000000000002 0.15000000000000002 rel ang = 14.99993896484375
-----------------


======= labels_counter:  350
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -123.1798911550205
Distance to goal 36.05551275463989
Distance in cm: 180.27756377319946 > 50.0
continuous actions for exploring
agent angle = 59.99993896484375
angle stg goal = 14.036243467926479
angle final goal = -123.1798911550205
0.05 0.2 rel ang = 45.96369549691727
-----------------


======= labels_counter:  351
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -153.1798911550205
Distance to goal 36.05551275463989
Distance in cm: 180.27756377319946 > 50.0
continuous actions for exploring
agent angle = 29.99993896484375
angle stg goal = -26.56505117707799
angle final goal = -153.1798911550205
-0.1 0.2 rel ang = 56.56499014192174
-----------------


======= labels_counter:  352
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 176.8201088449795
Distance to goal 36.05551275463989
Distance in cm: 180.27756377319946 > 50.0
continuous actions for exploring
agent angle = -6.103515625e-05
angle stg goal = -26.56505117707799
angle final goal = 176.8201088449795
-0.1 0.2 rel ang = 26.56499014192174
-----------------


======= labels_counter:  353
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 146.8201088449795
Distance to goal 36.05551275463989
Distance in cm: 180.27756377319946 > 50.0
continuous actions for exploring
agent angle = -30.00006103515625
angle stg goal = -26.56505117707799
angle final goal = 146.8201088449795
-0.1 0.2 rel ang = -3.435009858078274
-----------------


======= labels_counter:  354
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 77.44712738812596
Distance to goal 36.68787265568828
Distance in cm: 183.43936327844142 > 50.0
continuous actions for exploring
agent angle = -30.00006103515625
angle stg goal = -26.56505117707799
angle final goal = 77.44712738812596
-0.1 0.2 rel ang = -3.435009858078274
-----------------


======= labels_counter:  355
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 72.87494052445624
Distance to goal 35.90264614203248
Distance in cm: 179.51323071016242 > 50.0
continuous actions for exploring
agent angle = -30.00006103515625
angle stg goal = -26.56505117707799
angle final goal = 72.87494052445624
-0.1 0.2 rel ang = -3.435009858078274
-----------------


======= labels_counter:  356
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 70.30478543360978
Distance to goal 33.54101966249684
Distance in cm: 167.7050983124842 > 50.0
continuous actions for exploring
agent angle = -30.00006103515625
angle stg goal = -26.56505117707799
angle final goal = 70.30478543360978
-0.1 0.2 rel ang = -3.435009858078274
-----------------


======= labels_counter:  357
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 77.87863556068508
Distance to goal 32.57299494980466
Distance in cm: 162.8649747490233 > 50.0
continuous actions for exploring
agent angle = -30.00006103515625
angle stg goal = -26.56505117707799
angle final goal = 77.87863556068508
-0.1 0.2 rel ang = -3.435009858078274
-----------------


======= labels_counter:  358
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move pen from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 88.17852907480292
Distance to goal 31.76476034853718
Distance in cm: 158.8238017426859 > 50.0
continuous actions for exploring
agent angle = -30.00006103515625
angle stg goal = -26.56505117707799
angle final goal = 88.17852907480292
-0.1 0.2 rel ang = -3.435009858078274
-----------------


======= labels_counter:  359
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']


======= labels_counter:  360
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']


======= labels_counter:  361
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']


======= labels_counter:  362
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']


======= labels_counter:  363
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']


======= labels_counter:  364
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']


======= labels_counter:  365
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']


======= labels_counter:  366
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']


======= labels_counter:  367
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']


======= labels_counter:  368
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']


======= labels_counter:  369
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 165.52401944401987
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 59.999908447265625
angle stg goal = 14.036243467926479
angle final goal = 165.52401944401987
0.05 0.2 rel ang = 45.96366497933914
-----------------


======= labels_counter:  370
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 135.52401944401987
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 29.999908447265625
angle stg goal = 14.036243467926479
angle final goal = 135.52401944401987
0.05 0.2 rel ang = 15.963664979339146
-----------------


======= labels_counter:  371
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 105.52401944401988
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = -9.1552734375e-05
angle stg goal = 14.036243467926479
angle final goal = 105.52401944401988
0.05 0.2 rel ang = -14.036335020660829
-----------------


======= labels_counter:  372
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 105.52401944401988
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = -9.1552734375e-05
angle stg goal = 14.036243467926479
angle final goal = 105.52401944401988
0.05 0.2 rel ang = -14.036335020660829
-----------------


======= labels_counter:  373
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (242, 243)
  - delta = 2 3
Distance (m): 0.18027756377319945
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 105.52401944401988
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = -9.1552734375e-05
angle stg goal = 33.690067525979785
angle final goal = 105.52401944401988
0.1 0.15000000000000002 rel ang = -33.690159078714146
-----------------


======= labels_counter:  374
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (242, 243)
  - delta = 2 3
Distance (m): 0.18027756377319945
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 135.52401944401987
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 29.999908447265625
angle stg goal = 33.690067525979785
angle final goal = 135.52401944401987
0.1 0.15000000000000002 rel ang = -3.690159078714146
-----------------


======= labels_counter:  375
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 117.13750322115388
Distance to goal 20.024984394500787
Distance in cm: 100.12492197250394 > 50.0
continuous actions for exploring
agent angle = 29.999908447265625
angle stg goal = -53.13010235415598
angle final goal = 117.13750322115388
-0.2 0.15000000000000002 rel ang = 83.1300108014216
-----------------


======= labels_counter:  376
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 87.13750322115388
Distance to goal 20.024984394500787
Distance in cm: 100.12492197250394 > 50.0
continuous actions for exploring
agent angle = -9.1552734375e-05
angle stg goal = -53.13010235415598
angle final goal = 87.13750322115388
-0.2 0.15000000000000002 rel ang = 53.130010801421605
-----------------


======= labels_counter:  377
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 65.44024047827114
Distance to goal 21.095023109728988
Distance in cm: 105.47511554864494 > 50.0
continuous actions for exploring
agent angle = -30.000091552734375
angle stg goal = -53.13010235415598
angle final goal = 65.44024047827114
-0.2 0.15000000000000002 rel ang = 23.130010801421605
-----------------


======= labels_counter:  378
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move kettle from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 242)
  - delta = 3 2
Distance (m): 0.18027756377319945
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 35.440240478271136
Distance to goal 21.095023109728988
Distance in cm: 105.47511554864494 > 50.0
continuous actions for exploring
agent angle = -60.000091552734375
angle stg goal = 56.309932474020215
angle final goal = 35.440240478271136
0.15000000000000002 0.1 rel ang = -116.3100240267546
-----------------


======= labels_counter:  379
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']


======= labels_counter:  380
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']


======= labels_counter:  381
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']


======= labels_counter:  382
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']


======= labels_counter:  383
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']


======= labels_counter:  384
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']


======= labels_counter:  385
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']


======= labels_counter:  386
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']


======= labels_counter:  387
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']


======= labels_counter:  388
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']


======= labels_counter:  389
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 87.89728628973668
Distance to goal 19.235384061671343
Distance in cm: 96.17692030835671 > 50.0
continuous actions for exploring
agent angle = 60.00001525878906
angle stg goal = 45.0
angle final goal = 87.89728628973668
0.15000000000000002 0.15000000000000002 rel ang = 15.000015258789062
-----------------


======= labels_counter:  390
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 64.50853824645746
Distance to goal 19.4164878389476
Distance in cm: 97.082439194738 > 50.0
continuous actions for exploring
agent angle = 30.000015258789062
angle stg goal = 143.13010235415598
angle final goal = 64.50853824645746
0.15000000000000002 -0.2 rel ang = -113.13008709536692
-----------------


======= labels_counter:  391
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 94.50856876403559
Distance to goal 19.4164878389476
Distance in cm: 97.082439194738 > 50.0
continuous actions for exploring
agent angle = 60.00004577636719
angle stg goal = 143.13010235415598
angle final goal = 94.50856876403559
0.15000000000000002 -0.2 rel ang = -83.13005657778876
-----------------


======= labels_counter:  392
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 124.50855350524652
Distance to goal 19.4164878389476
Distance in cm: 97.082439194738 > 50.0
continuous actions for exploring
agent angle = 90.00003051757812
angle stg goal = 143.13010235415598
angle final goal = 124.50855350524652
0.15000000000000002 -0.2 rel ang = -53.13007183657783
-----------------


======= labels_counter:  393
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 154.50855350524654
Distance to goal 19.4164878389476
Distance in cm: 97.082439194738 > 50.0
continuous actions for exploring
agent angle = 120.00003051757812
angle stg goal = 143.13010235415598
angle final goal = 154.50855350524654
0.15000000000000002 -0.2 rel ang = -23.130071836577827
-----------------


======= labels_counter:  394
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -175.49144649475346
Distance to goal 19.4164878389476
Distance in cm: 97.082439194738 > 50.0
continuous actions for exploring
agent angle = 150.00003051757812
angle stg goal = 143.13010235415598
angle final goal = -175.49144649475346
0.15000000000000002 -0.2 rel ang = 6.869928163422145
-----------------


======= labels_counter:  395
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -178.24048939760908
Distance to goal 24.698178070456937
Distance in cm: 123.49089035228468 > 50.0
continuous actions for exploring
agent angle = 150.00003051757812
angle stg goal = 143.13010235415598
angle final goal = -178.24048939760908
0.15000000000000002 -0.2 rel ang = 6.869928163422145
-----------------


======= labels_counter:  396
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -177.38072641122903
Distance to goal 29.68164415931166
Distance in cm: 148.40822079655828 > 50.0
continuous actions for exploring
agent angle = 150.00003051757812
angle stg goal = 143.13010235415598
angle final goal = -177.38072641122903
0.15000000000000002 -0.2 rel ang = 6.869928163422145
-----------------


======= labels_counter:  397
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -178.17252290574876
Distance to goal 34.132096331752024
Distance in cm: 170.66048165876012 > 50.0
continuous actions for exploring
agent angle = 150.00003051757812
angle stg goal = 143.13010235415598
angle final goal = -178.17252290574876
0.15000000000000002 -0.2 rel ang = 6.869928163422145
-----------------


======= labels_counter:  398
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 9
[ObjectNav] Goal name:  ['Move credit_card from table to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -93.4349183053439
Distance to goal 40.24922359499622
Distance in cm: 201.24611797498108 > 50.0
continuous actions for exploring
agent angle = 150.00003051757812
angle stg goal = 143.13010235415598
angle final goal = -93.4349183053439
0.15000000000000002 -0.2 rel ang = 6.869928163422145
-----------------


======= labels_counter:  399
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']


======= labels_counter:  400
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']


======= labels_counter:  401
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']


======= labels_counter:  402
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']


======= labels_counter:  403
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']


======= labels_counter:  404
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']


======= labels_counter:  405
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']


======= labels_counter:  406
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']


======= labels_counter:  407
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']


======= labels_counter:  408
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']


======= labels_counter:  409
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 2.3474129818639113
Distance to goal 35.510561809129406
Distance in cm: 177.55280904564702 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 143.13010235415598
angle final goal = 2.3474129818639113
0.15000000000000002 -0.2 rel ang = -83.13013287173408
-----------------


======= labels_counter:  410
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 32.34741298186391
Distance to goal 35.510561809129406
Distance in cm: 177.55280904564702 > 50.0
continuous actions for exploring
agent angle = 89.99996948242188
angle stg goal = 143.13010235415598
angle final goal = 32.34741298186391
0.15000000000000002 -0.2 rel ang = -53.13013287173408
-----------------


======= labels_counter:  411
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 62.34741298186391
Distance to goal 35.510561809129406
Distance in cm: 177.55280904564702 > 50.0
continuous actions for exploring
agent angle = 119.99996948242188
angle stg goal = 143.13010235415598
angle final goal = 62.34741298186391
0.15000000000000002 -0.2 rel ang = -23.130132871734077
-----------------


======= labels_counter:  412
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 92.34744349944204
Distance to goal 35.510561809129406
Distance in cm: 177.55280904564702 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 143.13010235415598
angle final goal = 92.34744349944204
0.15000000000000002 -0.2 rel ang = 6.86989764584402
-----------------


======= labels_counter:  413
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 87.97947438848016
Distance to goal 36.235341863986875
Distance in cm: 181.1767093199344 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 143.13010235415598
angle final goal = 87.97947438848016
0.15000000000000002 -0.2 rel ang = 6.86989764584402
-----------------


======= labels_counter:  414
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 86.56505117707799
Distance to goal 35.77708763999664
Distance in cm: 178.88543819998318 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 116.56505117707799
angle final goal = 86.56505117707799
0.2 -0.1 rel ang = 33.43494882292201
-----------------


======= labels_counter:  415
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 56.56505117707799
Distance to goal 35.77708763999664
Distance in cm: 178.88543819998318 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = 143.13010235415598
angle final goal = 56.56505117707799
0.15000000000000002 -0.2 rel ang = -23.13010235415595
-----------------


======= labels_counter:  416
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 86.56505117707799
Distance to goal 35.77708763999664
Distance in cm: 178.88543819998318 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 143.13010235415598
angle final goal = 86.56505117707799
0.15000000000000002 -0.2 rel ang = 6.86989764584402
-----------------


======= labels_counter:  417
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 90.14138555207535
Distance to goal 35.84689665786984
Distance in cm: 179.2344832893492 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 116.56505117707799
angle final goal = 90.14138555207535
0.2 -0.1 rel ang = 33.43494882292201
-----------------


======= labels_counter:  418
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move candy_bar from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 60.14138555207534
Distance to goal 35.84689665786984
Distance in cm: 179.2344832893492 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = 116.56505117707799
angle final goal = 60.14138555207534
0.2 -0.1 rel ang = 3.43494882292201
-----------------


======= labels_counter:  419
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']


======= labels_counter:  420
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']


======= labels_counter:  421
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']


======= labels_counter:  422
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']


======= labels_counter:  423
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']


======= labels_counter:  424
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']


======= labels_counter:  425
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']


======= labels_counter:  426
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']


======= labels_counter:  427
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']


======= labels_counter:  428
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']


======= labels_counter:  429
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -33.01275698660521
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = 60.000030517578125
angle stg goal = -78.69006752597979
angle final goal = -33.01275698660521
-0.25 0.05 rel ang = 138.6900980435579
-----------------


======= labels_counter:  430
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -63.01275698660521
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = -78.69006752597979
angle final goal = -63.01275698660521
-0.25 0.05 rel ang = 108.69009804355791
-----------------


======= labels_counter:  431
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -93.01275698660521
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = 3.0517578125e-05
angle stg goal = -78.69006752597979
angle final goal = -93.01275698660521
-0.25 0.05 rel ang = 78.69009804355791
-----------------


======= labels_counter:  432
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -123.01275698660521
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = -29.999969482421875
angle stg goal = -78.69006752597979
angle final goal = -123.01275698660521
-0.25 0.05 rel ang = 48.69009804355791
-----------------


======= labels_counter:  433
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -153.0127569866052
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = -59.999969482421875
angle stg goal = -78.69006752597979
angle final goal = -153.0127569866052
-0.25 0.05 rel ang = 18.69009804355791
-----------------


======= labels_counter:  434
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 176.98721249581666
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = -90.0
angle stg goal = -78.69006752597979
angle final goal = 176.98721249581666
-0.25 0.05 rel ang = -11.30993247402023
-----------------


======= labels_counter:  435
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 163.07245641827484
Distance to goal 24.041630560342615
Distance in cm: 120.20815280171307 > 50.0
continuous actions for exploring
agent angle = -90.00003051757812
angle stg goal = -53.13010235415598
angle final goal = 163.07245641827484
-0.2 0.15000000000000002 rel ang = -36.86992816342217
-----------------


======= labels_counter:  436
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -166.92757409930329
Distance to goal 24.041630560342615
Distance in cm: 120.20815280171307 > 50.0
continuous actions for exploring
agent angle = -60.00006103515625
angle stg goal = -53.13010235415598
angle final goal = -166.92757409930329
-0.2 0.15000000000000002 rel ang = -6.869958681000298
-----------------


======= labels_counter:  437
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -151.9750103048273
Distance to goal 29.017236257093817
Distance in cm: 145.08618128546908 > 50.0
continuous actions for exploring
agent angle = -60.00007629394531
angle stg goal = -53.13010235415598
angle final goal = -151.9750103048273
-0.2 0.15000000000000002 rel ang = -6.869973939789361
-----------------


======= labels_counter:  438
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move hammer from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -144.6442512510901
Distance to goal 32.14031735997639
Distance in cm: 160.70158679988197 > 50.0
continuous actions for exploring
agent angle = -60.00007629394531
angle stg goal = -53.13010235415598
angle final goal = -144.6442512510901
-0.2 0.15000000000000002 rel ang = -6.869973939789361
-----------------


======= labels_counter:  439
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']


======= labels_counter:  440
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']


======= labels_counter:  441
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']


======= labels_counter:  442
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']


======= labels_counter:  443
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']


======= labels_counter:  444
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']


======= labels_counter:  445
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']


======= labels_counter:  446
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']


======= labels_counter:  447
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']


======= labels_counter:  448
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']


======= labels_counter:  449
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -87.99455575676029
Distance to goal 47.16990566028302
Distance in cm: 235.8495283014151 > 50.0
continuous actions for exploring
agent angle = 60.00006103515625
angle stg goal = 45.0
angle final goal = -87.99455575676029
0.15000000000000002 0.15000000000000002 rel ang = 15.00006103515625
-----------------


======= labels_counter:  450
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -117.99455575676026
Distance to goal 47.16990566028302
Distance in cm: 235.8495283014151 > 50.0
continuous actions for exploring
agent angle = 30.00006103515625
angle stg goal = 75.96375653207353
angle final goal = -117.99455575676026
0.2 0.05 rel ang = -45.963695496917296
-----------------


======= labels_counter:  451
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -87.99455575676029
Distance to goal 47.16990566028302
Distance in cm: 235.8495283014151 > 50.0
continuous actions for exploring
agent angle = 60.00006103515625
angle stg goal = 75.96375653207353
angle final goal = -87.99455575676029
0.2 0.05 rel ang = -15.963695496917296
-----------------


======= labels_counter:  452
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -57.99455575676029
Distance to goal 47.16990566028302
Distance in cm: 235.8495283014151 > 50.0
continuous actions for exploring
agent angle = 90.00006103515625
angle stg goal = 75.96375653207353
angle final goal = -57.99455575676029
0.2 0.05 rel ang = 14.036304503082718
-----------------


======= labels_counter:  453
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -63.434887787765774
Distance to goal 44.721359549995796
Distance in cm: 223.60679774997897 > 50.0
continuous actions for exploring
agent angle = 90.00006103515625
angle stg goal = 75.96375653207353
angle final goal = -63.434887787765774
0.2 0.05 rel ang = 14.036304503082718
-----------------


======= labels_counter:  454
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -69.44389374526031
Distance to goal 42.720018726587654
Distance in cm: 213.60009363293827 > 50.0
continuous actions for exploring
agent angle = 90.00006103515625
angle stg goal = 75.96375653207353
angle final goal = -69.44389374526031
0.2 0.05 rel ang = 14.036304503082718
-----------------


======= labels_counter:  455
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -63.434887787765774
Distance to goal 40.24922359499622
Distance in cm: 201.24611797498108 > 50.0
continuous actions for exploring
agent angle = 90.00006103515625
angle stg goal = 75.96375653207353
angle final goal = -63.434887787765774
0.2 0.05 rel ang = 14.036304503082718
-----------------


======= labels_counter:  456
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -57.99455575676029
Distance to goal 37.73592452822641
Distance in cm: 188.67962264113206 > 50.0
continuous actions for exploring
agent angle = 90.00006103515625
angle stg goal = 45.0
angle final goal = -57.99455575676029
0.15000000000000002 0.15000000000000002 rel ang = 45.00006103515625
-----------------


======= labels_counter:  457
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -87.99455575676029
Distance to goal 37.73592452822641
Distance in cm: 188.67962264113206 > 50.0
continuous actions for exploring
agent angle = 60.00006103515625
angle stg goal = 45.0
angle final goal = -87.99455575676029
0.15000000000000002 0.15000000000000002 rel ang = 15.00006103515625
-----------------


======= labels_counter:  458
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move fork from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -117.99455575676026
Distance to goal 37.73592452822641
Distance in cm: 188.67962264113206 > 50.0
continuous actions for exploring
agent angle = 30.00006103515625
angle stg goal = 45.0
angle final goal = -117.99455575676026
0.15000000000000002 0.15000000000000002 rel ang = -14.99993896484375
-----------------


======= labels_counter:  459
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']


======= labels_counter:  460
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']


======= labels_counter:  461
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']


======= labels_counter:  462
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']


======= labels_counter:  463
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']


======= labels_counter:  464
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']


======= labels_counter:  465
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']


======= labels_counter:  466
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']


======= labels_counter:  467
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']


======= labels_counter:  468
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']


======= labels_counter:  469
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -73.45184230102205
Distance to goal 26.1725046566048
Distance in cm: 130.86252328302402 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 45.0
angle final goal = -73.45184230102205
0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  470
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -79.89909245378777
Distance to goal 24.839484696748443
Distance in cm: 124.19742348374221 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 14.036243467926479
angle final goal = -79.89909245378777
0.05 0.2 rel ang = 45.96375653207352
-----------------


======= labels_counter:  471
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -109.89909245378777
Distance to goal 24.839484696748443
Distance in cm: 124.19742348374221 > 50.0
continuous actions for exploring
agent angle = 30.0
angle stg goal = -53.13010235415598
angle final goal = -109.89909245378777
-0.2 0.15000000000000002 rel ang = 83.13010235415598
-----------------


======= labels_counter:  472
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -139.89909245378777
Distance to goal 24.839484696748443
Distance in cm: 124.19742348374221 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = -53.13010235415598
angle final goal = -139.89909245378777
-0.2 0.15000000000000002 rel ang = 53.13010235415598
-----------------


======= labels_counter:  473
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -169.89909245378777
Distance to goal 24.839484696748443
Distance in cm: 124.19742348374221 > 50.0
continuous actions for exploring
agent angle = -30.0
angle stg goal = -53.13010235415598
angle final goal = -169.89909245378777
-0.2 0.15000000000000002 rel ang = 23.13010235415598
-----------------


======= labels_counter:  474
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 160.10090754621223
Distance to goal 24.839484696748443
Distance in cm: 124.19742348374221 > 50.0
continuous actions for exploring
agent angle = -60.0
angle stg goal = -53.13010235415598
angle final goal = 160.10090754621223
-0.2 0.15000000000000002 rel ang = -6.869897645844048
-----------------


======= labels_counter:  475
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 162.27368900609375
Distance to goal 29.732137494637012
Distance in cm: 148.66068747318505 > 50.0
continuous actions for exploring
agent angle = -60.0
angle stg goal = -53.13010235415598
angle final goal = 162.27368900609375
-0.2 0.15000000000000002 rel ang = -6.869897645844048
-----------------


======= labels_counter:  476
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 163.83086067209257
Distance to goal 34.655446902326915
Distance in cm: 173.27723451163456 > 50.0
continuous actions for exploring
agent angle = -60.0
angle stg goal = -53.13010235415598
angle final goal = 163.83086067209257
-0.2 0.15000000000000002 rel ang = -6.869897645844048
-----------------


======= labels_counter:  477
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 165.0
Distance to goal 39.59797974644666
Distance in cm: 197.9898987322333 > 50.0
continuous actions for exploring
agent angle = -60.0
angle stg goal = -53.13010235415598
angle final goal = 165.0
-0.2 0.15000000000000002 rel ang = -6.869897645844048
-----------------


======= labels_counter:  478
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 19
[ObjectNav] Goal name:  ['Move lunch_box from counter to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 71.42366562500266
Distance to goal 45.34313619501854
Distance in cm: 226.71568097509268 > 50.0
continuous actions for exploring
agent angle = -60.0
angle stg goal = -78.69006752597979
angle final goal = 71.42366562500266
-0.25 0.05 rel ang = 18.690067525979785
-----------------


======= labels_counter:  479
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']


======= labels_counter:  480
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']


======= labels_counter:  481
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']


======= labels_counter:  482
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']


======= labels_counter:  483
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']


======= labels_counter:  484
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']


======= labels_counter:  485
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']


======= labels_counter:  486
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']


======= labels_counter:  487
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']


======= labels_counter:  488
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']


======= labels_counter:  489
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -165.00003051757812
Distance to goal 32.526911934581186
Distance in cm: 162.63455967290594 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = -53.13010235415598
angle final goal = -165.00003051757812
-0.2 0.15000000000000002 rel ang = 113.13007183657786
-----------------


======= labels_counter:  490
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 164.99996948242188
Distance to goal 32.526911934581186
Distance in cm: 162.63455967290594 > 50.0
continuous actions for exploring
agent angle = 29.999969482421875
angle stg goal = -53.13010235415598
angle final goal = 164.99996948242188
-0.2 0.15000000000000002 rel ang = 83.13007183657786
-----------------


======= labels_counter:  491
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 134.99996948242188
Distance to goal 32.526911934581186
Distance in cm: 162.63455967290594 > 50.0
continuous actions for exploring
agent angle = -3.0517578125e-05
angle stg goal = -53.13010235415598
angle final goal = 134.99996948242188
-0.2 0.15000000000000002 rel ang = 53.130071836577855
-----------------


======= labels_counter:  492
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 104.99996948242188
Distance to goal 32.526911934581186
Distance in cm: 162.63455967290594 > 50.0
continuous actions for exploring
agent angle = -30.000030517578125
angle stg goal = -53.13010235415598
angle final goal = 104.99996948242188
-0.2 0.15000000000000002 rel ang = 23.130071836577855
-----------------


======= labels_counter:  493
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 74.99996948242188
Distance to goal 32.526911934581186
Distance in cm: 162.63455967290594 > 50.0
continuous actions for exploring
agent angle = -60.000030517578125
angle stg goal = -53.13010235415598
angle final goal = 74.99996948242188
-0.2 0.15000000000000002 rel ang = -6.869928163422173
-----------------


======= labels_counter:  494
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 78.99088258085166
Distance to goal 30.479501308256342
Distance in cm: 152.3975065412817 > 50.0
continuous actions for exploring
agent angle = -60.000030517578125
angle stg goal = -53.13010235415598
angle final goal = 78.99088258085166
-0.2 0.15000000000000002 rel ang = -6.869928163422173
-----------------


======= labels_counter:  495
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 70.81505335730347
Distance to goal 29.068883707497267
Distance in cm: 145.34441853748635 > 50.0
continuous actions for exploring
agent angle = -60.000030517578125
angle stg goal = -53.13010235415598
angle final goal = 70.81505335730347
-0.2 0.15000000000000002 rel ang = -6.869928163422173
-----------------


======= labels_counter:  496
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 73.53116876803605
Distance to goal 27.586228448267445
Distance in cm: 137.93114224133723 > 50.0
continuous actions for exploring
agent angle = -60.000030517578125
angle stg goal = -26.56505117707799
angle final goal = 73.53116876803605
-0.1 0.2 rel ang = -33.43497934050015
-----------------


======= labels_counter:  497
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 103.53113825045793
Distance to goal 27.586228448267445
Distance in cm: 137.93114224133723 > 50.0
continuous actions for exploring
agent angle = -30.00006103515625
angle stg goal = -53.13010235415598
angle final goal = 103.53113825045793
-0.2 0.15000000000000002 rel ang = 23.13004131899973
-----------------


======= labels_counter:  498
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move watch from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 73.53115350924699
Distance to goal 27.586228448267445
Distance in cm: 137.93114224133723 > 50.0
continuous actions for exploring
agent angle = -60.00004577636719
angle stg goal = -53.13010235415598
angle final goal = 73.53115350924699
-0.2 0.15000000000000002 rel ang = -6.869943422211236
-----------------


======= labels_counter:  499
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']


======= labels_counter:  500
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']


======= labels_counter:  501
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']


======= labels_counter:  502
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']


======= labels_counter:  503
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']


======= labels_counter:  504
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']


======= labels_counter:  505
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']


======= labels_counter:  506
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']


======= labels_counter:  507
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']


======= labels_counter:  508
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']


======= labels_counter:  509
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 34.35900943448378
Distance to goal 27.730849247724095
Distance in cm: 138.6542462386205 > 50.0
continuous actions for exploring
agent angle = 60.00001525878906
angle stg goal = 116.56505117707799
angle final goal = 34.35900943448378
0.2 -0.1 rel ang = -56.56503591828891
-----------------


======= labels_counter:  510
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 64.35899417569472
Distance to goal 27.730849247724095
Distance in cm: 138.6542462386205 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 116.56505117707799
angle final goal = 64.35899417569472
0.2 -0.1 rel ang = -26.565051177077976
-----------------


======= labels_counter:  511
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 94.35899417569472
Distance to goal 27.730849247724095
Distance in cm: 138.6542462386205 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = 116.56505117707799
angle final goal = 94.35899417569472
0.2 -0.1 rel ang = 3.43494882292201
-----------------


======= labels_counter:  512
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 104.05460409907715
Distance to goal 29.120439557122072
Distance in cm: 145.60219778561037 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = 75.96375653207353
angle final goal = 104.05460409907715
0.2 0.05 rel ang = 44.03624346792647
-----------------


======= labels_counter:  513
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 74.05460409907715
Distance to goal 29.120439557122072
Distance in cm: 145.60219778561037 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = 74.05460409907715
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  514
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 83.88449643371459
Distance to goal 28.160255680657446
Distance in cm: 140.80127840328723 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = 83.88449643371459
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  515
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 92.04540848888723
Distance to goal 28.0178514522438
Distance in cm: 140.089257261219 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = 92.04540848888723
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  516
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 100.12467165539782
Distance to goal 28.442925306655784
Distance in cm: 142.21462653327893 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = 100.12467165539782
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  517
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 109.65382405805332
Distance to goal 29.732137494637012
Distance in cm: 148.66068747318505 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 45.0
angle final goal = 109.65382405805332
0.15000000000000002 0.15000000000000002 rel ang = 45.0
-----------------


======= labels_counter:  518
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move action_figure from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 79.65383931684238
Distance to goal 29.732137494637012
Distance in cm: 148.66068747318505 > 50.0
continuous actions for exploring
agent angle = 60.00001525878906
angle stg goal = 45.0
angle final goal = 79.65383931684238
0.15000000000000002 0.15000000000000002 rel ang = 15.000015258789062
-----------------


======= labels_counter:  519
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']


======= labels_counter:  520
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']


======= labels_counter:  521
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']


======= labels_counter:  522
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']


======= labels_counter:  523
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']


======= labels_counter:  524
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']


======= labels_counter:  525
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']


======= labels_counter:  526
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']


======= labels_counter:  527
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']


======= labels_counter:  528
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']


======= labels_counter:  529
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -123.01278750418334
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 14.036243467926479
angle final goal = -123.01278750418334
0.05 0.2 rel ang = 45.96375653207352
-----------------


======= labels_counter:  530
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -153.01278750418334
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = 30.0
angle stg goal = 0.0
angle final goal = -153.01278750418334
0.0 0.2 rel ang = 30.0
-----------------


======= labels_counter:  531
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 176.9871972370276
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = 0.0
angle final goal = 176.9871972370276
0.0 0.2 rel ang = -1.52587890625e-05
-----------------


======= labels_counter:  532
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -167.73524153089667
Distance to goal 23.53720459187964
Distance in cm: 117.6860229593982 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = 0.0
angle final goal = -167.73524153089667
0.0 0.2 rel ang = -1.52587890625e-05
-----------------


======= labels_counter:  533
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -169.87534360339126
Distance to goal 28.442925306655784
Distance in cm: 142.21462653327893 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = 0.0
angle final goal = -169.87534360339126
0.0 0.2 rel ang = -1.52587890625e-05
-----------------


======= labels_counter:  534
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -171.38436707462495
Distance to goal 33.37663853655727
Distance in cm: 166.88319268278636 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = 0.0
angle final goal = -171.38436707462495
0.0 0.2 rel ang = -1.52587890625e-05
-----------------


======= labels_counter:  535
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -95.19444416652385
Distance to goal 33.13608305156178
Distance in cm: 165.68041525780893 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = 14.036243467926479
angle final goal = -95.19444416652385
0.05 0.2 rel ang = -14.036258726715516
-----------------


======= labels_counter:  536
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -103.62701011868057
Distance to goal 33.95585369269929
Distance in cm: 169.77926846349646 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = 45.0
angle final goal = -103.62701011868057
0.15000000000000002 0.15000000000000002 rel ang = -45.00001525878906
-----------------


======= labels_counter:  537
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -73.62701011868057
Distance to goal 33.95585369269929
Distance in cm: 169.77926846349646 > 50.0
continuous actions for exploring
agent angle = 29.999984741210938
angle stg goal = 45.0
angle final goal = -73.62701011868057
0.15000000000000002 0.15000000000000002 rel ang = -15.000015258789062
-----------------


======= labels_counter:  538
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move jug from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -48.43496408171109
Distance to goal 34.785054261852174
Distance in cm: 173.92527130926086 > 50.0
continuous actions for exploring
agent angle = 59.99998474121094
angle stg goal = 45.0
angle final goal = -48.43496408171109
0.15000000000000002 0.15000000000000002 rel ang = 14.999984741210938
-----------------


======= labels_counter:  539
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']


======= labels_counter:  540
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']


======= labels_counter:  541
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']


======= labels_counter:  542
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']


======= labels_counter:  543
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']


======= labels_counter:  544
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']


======= labels_counter:  545
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']


======= labels_counter:  546
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']


======= labels_counter:  547
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']


======= labels_counter:  548
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']


======= labels_counter:  549
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 244)
  - delta = -1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -166.04159615843184
Distance to goal 38.897300677553446
Distance in cm: 194.48650338776724 > 50.0
continuous actions for exploring
agent angle = 60.000030517578125
angle stg goal = -14.036243467926479
angle final goal = -166.04159615843184
-0.05 0.2 rel ang = 74.03627398550461
-----------------


======= labels_counter:  550
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 244)
  - delta = -1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 163.95840384156816
Distance to goal 38.897300677553446
Distance in cm: 194.48650338776724 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = -14.036243467926479
angle final goal = 163.95840384156816
-0.05 0.2 rel ang = 44.03627398550461
-----------------


======= labels_counter:  551
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 244)
  - delta = -1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 133.95840384156816
Distance to goal 38.897300677553446
Distance in cm: 194.48650338776724 > 50.0
continuous actions for exploring
agent angle = 3.0517578125e-05
angle stg goal = -14.036243467926479
angle final goal = 133.95840384156816
-0.05 0.2 rel ang = 14.036273985504604
-----------------


======= labels_counter:  552
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 133.95840384156816
Distance to goal 38.897300677553446
Distance in cm: 194.48650338776724 > 50.0
continuous actions for exploring
agent angle = 3.0517578125e-05
angle stg goal = 168.6900675259798
angle final goal = 133.95840384156816
0.05 -0.25 rel ang = -168.69003700840167
-----------------


======= labels_counter:  553
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 163.95840384156816
Distance to goal 38.897300677553446
Distance in cm: 194.48650338776724 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = 168.6900675259798
angle final goal = 163.95840384156816
0.05 -0.25 rel ang = -138.69003700840167
-----------------


======= labels_counter:  554
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -166.04159615843184
Distance to goal 38.897300677553446
Distance in cm: 194.48650338776724 > 50.0
continuous actions for exploring
agent angle = 60.000030517578125
angle stg goal = 168.6900675259798
angle final goal = -166.04159615843184
0.05 -0.25 rel ang = -108.69003700840167
-----------------


======= labels_counter:  555
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -136.04159615843184
Distance to goal 38.897300677553446
Distance in cm: 194.48650338776724 > 50.0
continuous actions for exploring
agent angle = 90.00003051757812
angle stg goal = 168.6900675259798
angle final goal = -136.04159615843184
0.05 -0.25 rel ang = -78.69003700840165
-----------------


======= labels_counter:  556
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -106.04162667600997
Distance to goal 38.897300677553446
Distance in cm: 194.48650338776724 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = 168.6900675259798
angle final goal = -106.04162667600997
0.05 -0.25 rel ang = -48.69006752597977
-----------------


======= labels_counter:  557
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -76.04162667600997
Distance to goal 38.897300677553446
Distance in cm: 194.48650338776724 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 168.6900675259798
angle final goal = -76.04162667600997
0.05 -0.25 rel ang = -18.69006752597977
-----------------


======= labels_counter:  558
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -46.04162667600997
Distance to goal 38.897300677553446
Distance in cm: 194.48650338776724 > 50.0
continuous actions for exploring
agent angle = 180.0
angle stg goal = 168.6900675259798
angle final goal = -46.04162667600997
0.05 -0.25 rel ang = 11.3099324740202
-----------------


======= labels_counter:  559
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']


======= labels_counter:  560
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']


======= labels_counter:  561
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']


======= labels_counter:  562
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']


======= labels_counter:  563
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']


======= labels_counter:  564
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']


======= labels_counter:  565
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']


======= labels_counter:  566
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']


======= labels_counter:  567
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']


======= labels_counter:  568
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']


======= labels_counter:  569
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 85.90650799951439
Distance to goal 38.91015291668744
Distance in cm: 194.55076458343717 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 143.13010235415598
angle final goal = 85.90650799951439
0.15000000000000002 -0.2 rel ang = -83.13010235415595
-----------------


======= labels_counter:  570
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 115.90650799951439
Distance to goal 38.91015291668744
Distance in cm: 194.55076458343717 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 143.13010235415598
angle final goal = 115.90650799951439
0.15000000000000002 -0.2 rel ang = -53.13010235415595
-----------------


======= labels_counter:  571
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 145.9065079995144
Distance to goal 38.91015291668744
Distance in cm: 194.55076458343717 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = 143.13010235415598
angle final goal = 145.9065079995144
0.15000000000000002 -0.2 rel ang = -23.13010235415595
-----------------


======= labels_counter:  572
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 175.9065079995144
Distance to goal 38.91015291668744
Distance in cm: 194.55076458343717 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 143.13010235415598
angle final goal = 175.9065079995144
0.15000000000000002 -0.2 rel ang = 6.86989764584402
-----------------


======= labels_counter:  573
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 175.40771810894847
Distance to goal 44.28317965096906
Distance in cm: 221.4158982548453 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 143.13010235415598
angle final goal = 175.40771810894847
0.15000000000000002 -0.2 rel ang = 6.86989764584402
-----------------


======= labels_counter:  574
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 170.2825590889166
Distance to goal 49.040799340956916
Distance in cm: 245.20399670478457 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 168.6900675259798
angle final goal = 170.2825590889166
0.05 -0.25 rel ang = -18.69006752597977
-----------------


======= labels_counter:  575
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -159.7174409110834
Distance to goal 49.040799340956916
Distance in cm: 245.20399670478457 > 50.0
continuous actions for exploring
agent angle = 180.0
angle stg goal = 168.6900675259798
angle final goal = -159.7174409110834
0.05 -0.25 rel ang = 11.3099324740202
-----------------


======= labels_counter:  576
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -30.784146526326424
Distance to goal 54.70831746635972
Distance in cm: 273.5415873317986 > 50.0
continuous actions for exploring
agent angle = 180.0
angle stg goal = 143.13010235415598
angle final goal = -30.784146526326424
0.15000000000000002 -0.2 rel ang = 36.86989764584402
-----------------


======= labels_counter:  577
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -60.784146526326424
Distance to goal 54.70831746635972
Distance in cm: 273.5415873317986 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 143.13010235415598
angle final goal = -60.784146526326424
0.15000000000000002 -0.2 rel ang = 6.86989764584402
-----------------


======= labels_counter:  578
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move milk_frother_cup from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -64.90249561592469
Distance to goal 52.43090691567332
Distance in cm: 262.15453457836657 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 143.13010235415598
angle final goal = -64.90249561592469
0.15000000000000002 -0.2 rel ang = 6.86989764584402
-----------------


======= labels_counter:  579
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']


======= labels_counter:  580
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']


======= labels_counter:  581
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']


======= labels_counter:  582
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']


======= labels_counter:  583
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']


======= labels_counter:  584
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']


======= labels_counter:  585
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']


======= labels_counter:  586
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']


======= labels_counter:  587
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']


======= labels_counter:  588
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']


======= labels_counter:  589
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -135.52408047917612
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 60.000030517578125
angle stg goal = -26.56505117707799
angle final goal = -135.52408047917612
-0.1 0.2 rel ang = 86.56508169465612
-----------------


======= labels_counter:  590
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -165.52408047917612
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = -26.56505117707799
angle final goal = -165.52408047917612
-0.1 0.2 rel ang = 56.565081694656115
-----------------


======= labels_counter:  591
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 164.47591952082388
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 3.0517578125e-05
angle stg goal = -26.56505117707799
angle final goal = 164.47591952082388
-0.1 0.2 rel ang = 26.565081694656115
-----------------


======= labels_counter:  592
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 134.47591952082388
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = -29.999969482421875
angle stg goal = -26.56505117707799
angle final goal = 134.47591952082388
-0.1 0.2 rel ang = -3.434918305343899
-----------------


======= labels_counter:  593
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 144.80560160984334
Distance to goal 22.090722034374522
Distance in cm: 110.45361017187261 > 50.0
continuous actions for exploring
agent angle = -29.999969482421875
angle stg goal = -26.56505117707799
angle final goal = 144.80560160984334
-0.1 0.2 rel ang = -3.434918305343899
-----------------


======= labels_counter:  594
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 244)
  - delta = -1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 147.79743235581233
Distance to goal 26.019223662515376
Distance in cm: 130.0961183125769 > 50.0
continuous actions for exploring
agent angle = -29.999969482421875
angle stg goal = -14.036243467926479
angle final goal = 147.79743235581233
-0.05 0.2 rel ang = -15.963726014495421
-----------------


======= labels_counter:  595
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 244)
  - delta = -1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 177.79741709702327
Distance to goal 26.019223662515376
Distance in cm: 130.0961183125769 > 50.0
continuous actions for exploring
agent angle = 1.52587890625e-05
angle stg goal = -14.036243467926479
angle final goal = 177.79741709702327
-0.05 0.2 rel ang = 14.036258726715541
-----------------


======= labels_counter:  596
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (237, 243)
  - delta = -3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 100.49149227112066
Distance to goal 27.459060435491963
Distance in cm: 137.2953021774598 > 50.0
continuous actions for exploring
agent angle = 1.52587890625e-05
angle stg goal = -45.0
angle final goal = 100.49149227112066
-0.15000000000000002 0.15000000000000002 rel ang = 45.00001525878906
-----------------


======= labels_counter:  597
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (237, 243)
  - delta = -3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 70.4914770123316
Distance to goal 27.459060435491963
Distance in cm: 137.2953021774598 > 50.0
continuous actions for exploring
agent angle = -30.0
angle stg goal = -45.0
angle final goal = 70.4914770123316
-0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  598
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spectacles from chair to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 244)
  - delta = -1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 70.4914770123316
Distance to goal 27.459060435491963
Distance in cm: 137.2953021774598 > 50.0
continuous actions for exploring
agent angle = -30.0
angle stg goal = -14.036243467926479
angle final goal = 70.4914770123316
-0.05 0.2 rel ang = -15.963756532073546
-----------------


======= labels_counter:  599
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']


======= labels_counter:  600
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']


======= labels_counter:  601
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']


======= labels_counter:  602
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']


======= labels_counter:  603
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']


======= labels_counter:  604
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']


======= labels_counter:  605
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']


======= labels_counter:  606
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']


======= labels_counter:  607
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']


======= labels_counter:  608
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']


======= labels_counter:  609
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: True
reduced obs dilation to 2
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -33.012787504183336
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = -26.56505117707799
angle final goal = -33.012787504183336
-0.1 0.2 rel ang = 86.56505117707799
-----------------


======= labels_counter:  610
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -63.012787504183336
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = 30.0
angle stg goal = 168.6900675259798
angle final goal = -63.012787504183336
0.05 -0.25 rel ang = -138.6900675259798
-----------------


======= labels_counter:  611
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -33.012787504183336
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 168.6900675259798
angle final goal = -33.012787504183336
0.05 -0.25 rel ang = -108.6900675259798
-----------------


======= labels_counter:  612
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -3.0127875041833363
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 168.6900675259798
angle final goal = -3.0127875041833363
0.05 -0.25 rel ang = -78.69006752597977
-----------------


======= labels_counter:  613
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 26.987212495816664
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = 168.6900675259798
angle final goal = 26.987212495816664
0.05 -0.25 rel ang = -48.69006752597977
-----------------


======= labels_counter:  614
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 56.987212495816664
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 168.6900675259798
angle final goal = 56.987212495816664
0.05 -0.25 rel ang = -18.69006752597977
-----------------


======= labels_counter:  615
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 86.98727353097291
Distance to goal 19.026297590440446
Distance in cm: 95.13148795220224 > 50.0
continuous actions for exploring
agent angle = -179.99993896484375
angle stg goal = 168.6900675259798
angle final goal = 86.98727353097291
0.05 -0.25 rel ang = 11.30999350917648
-----------------


======= labels_counter:  616
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 101.88871907478426
Distance to goal 19.4164878389476
Distance in cm: 97.082439194738 > 50.0
continuous actions for exploring
agent angle = -179.99993896484375
angle stg goal = 168.6900675259798
angle final goal = 101.88871907478426
0.05 -0.25 rel ang = 11.30999350917648
-----------------


======= labels_counter:  617
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 115.34623697710293
Distance to goal 21.02379604162864
Distance in cm: 105.1189802081432 > 50.0
continuous actions for exploring
agent angle = -179.99993896484375
angle stg goal = 143.13010235415598
angle final goal = 115.34623697710293
0.15000000000000002 -0.2 rel ang = 36.8699586810003
-----------------


======= labels_counter:  618
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move board_game from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 236)
  - delta = -4 -4
Distance (m): 0.282842712474619
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 85.34623697710295
Distance to goal 21.02379604162864
Distance in cm: 105.1189802081432 > 50.0
continuous actions for exploring
agent angle = 150.00006103515625
angle stg goal = -135.0
angle final goal = 85.34623697710295
-0.2 -0.2 rel ang = -74.99993896484375
-----------------


======= labels_counter:  619
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']


======= labels_counter:  620
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']


======= labels_counter:  621
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']


======= labels_counter:  622
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']


======= labels_counter:  623
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']


======= labels_counter:  624
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']


======= labels_counter:  625
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']


======= labels_counter:  626
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']


======= labels_counter:  627
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']


======= labels_counter:  628
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']


======= labels_counter:  629
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 240)
  - delta = 4 0
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -77.04540848888723
Distance to goal 39.6232255123179
Distance in cm: 198.1161275615895 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 90.0
angle final goal = -77.04540848888723
0.2 0.0 rel ang = -30.0
-----------------


======= labels_counter:  630
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 240)
  - delta = 4 0
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -47.04540848888723
Distance to goal 39.6232255123179
Distance in cm: 198.1161275615895 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 90.0
angle final goal = -47.04540848888723
0.2 0.0 rel ang = 0.0
-----------------


======= labels_counter:  631
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 240)
  - delta = 4 0
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -48.36646066342979
Distance to goal 36.124783736376884
Distance in cm: 180.62391868188442 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 90.0
angle final goal = -48.36646066342979
0.2 0.0 rel ang = 0.0
-----------------


======= labels_counter:  632
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -54.86580694308435
Distance to goal 33.015148038438355
Distance in cm: 165.07574019219177 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 116.56505117707799
angle final goal = -54.86580694308435
0.2 -0.1 rel ang = -26.565051177077976
-----------------


======= labels_counter:  633
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -33.434948822922024
Distance to goal 35.77708763999664
Distance in cm: 178.88543819998318 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = 14.036243467926479
angle final goal = -33.434948822922024
0.05 0.2 rel ang = 105.96375653207352
-----------------


======= labels_counter:  634
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -63.434948822922024
Distance to goal 35.77708763999664
Distance in cm: 178.88543819998318 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 14.036243467926479
angle final goal = -63.434948822922024
0.05 0.2 rel ang = 75.96375653207352
-----------------


======= labels_counter:  635
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -93.43494882292202
Distance to goal 35.77708763999664
Distance in cm: 178.88543819998318 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 14.036243467926479
angle final goal = -93.43494882292202
0.05 0.2 rel ang = 45.96375653207352
-----------------


======= labels_counter:  636
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 239)
  - delta = -5 -1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -123.434948822922
Distance to goal 35.77708763999664
Distance in cm: 178.88543819998318 > 50.0
continuous actions for exploring
agent angle = 30.0
angle stg goal = -101.30993247402021
angle final goal = -123.434948822922
-0.25 -0.05 rel ang = 131.30993247402023
-----------------


======= labels_counter:  637
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 239)
  - delta = -5 -1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -153.434948822922
Distance to goal 35.77708763999664
Distance in cm: 178.88543819998318 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = -101.30993247402021
angle final goal = -153.434948822922
-0.25 -0.05 rel ang = 101.30993247402021
-----------------


======= labels_counter:  638
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 4
[ObjectNav] Goal name:  ['Move credit_card from table to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 239)
  - delta = -5 -1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 176.56508169465613
Distance to goal 35.77708763999664
Distance in cm: 178.88543819998318 > 50.0
continuous actions for exploring
agent angle = -29.999969482421875
angle stg goal = -101.30993247402021
angle final goal = 176.56508169465613
-0.25 -0.05 rel ang = 71.30996299159834
-----------------


======= labels_counter:  639
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']


======= labels_counter:  640
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']


======= labels_counter:  641
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']


======= labels_counter:  642
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']


======= labels_counter:  643
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']


======= labels_counter:  644
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']


======= labels_counter:  645
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']


======= labels_counter:  646
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']


======= labels_counter:  647
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']


======= labels_counter:  648
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']


======= labels_counter:  649
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 34.44003482817619
Distance to goal 25.495097567963924
Distance in cm: 127.47548783981962 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = -78.69006752597979
angle final goal = 34.44003482817619
-0.25 0.05 rel ang = 138.69006752597977
-----------------


======= labels_counter:  650
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 4.440034828176188
Distance to goal 25.495097567963924
Distance in cm: 127.47548783981962 > 50.0
continuous actions for exploring
agent angle = 30.0
angle stg goal = -78.69006752597979
angle final goal = 4.440034828176188
-0.25 0.05 rel ang = 108.69006752597979
-----------------


======= labels_counter:  651
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -25.55996517182382
Distance to goal 25.495097567963924
Distance in cm: 127.47548783981962 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = -78.69006752597979
angle final goal = -25.55996517182382
-0.25 0.05 rel ang = 78.69006752597979
-----------------


======= labels_counter:  652
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -55.55996517182382
Distance to goal 25.495097567963924
Distance in cm: 127.47548783981962 > 50.0
continuous actions for exploring
agent angle = -30.0
angle stg goal = -78.69006752597979
angle final goal = -55.55996517182382
-0.25 0.05 rel ang = 48.690067525979785
-----------------


======= labels_counter:  653
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -85.55996517182382
Distance to goal 25.495097567963924
Distance in cm: 127.47548783981962 > 50.0
continuous actions for exploring
agent angle = -60.0
angle stg goal = -78.69006752597979
angle final goal = -85.55996517182382
-0.25 0.05 rel ang = 18.690067525979785
-----------------


======= labels_counter:  654
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -115.55996517182382
Distance to goal 25.495097567963924
Distance in cm: 127.47548783981962 > 50.0
continuous actions for exploring
agent angle = -90.0
angle stg goal = -78.69006752597979
angle final goal = -115.55996517182382
-0.25 0.05 rel ang = -11.30993247402023
-----------------


======= labels_counter:  655
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -124.82448915695679
Distance to goal 28.0178514522438
Distance in cm: 140.089257261219 > 50.0
continuous actions for exploring
agent angle = -90.0
angle stg goal = -78.69006752597979
angle final goal = -124.82448915695679
-0.25 0.05 rel ang = -11.30993247402023
-----------------


======= labels_counter:  656
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -55.304846468766016
Distance to goal 31.622776601683793
Distance in cm: 158.11388300841895 > 50.0
continuous actions for exploring
agent angle = -90.0
angle stg goal = -78.69006752597979
angle final goal = -55.304846468766016
-0.25 0.05 rel ang = -11.30993247402023
-----------------


======= labels_counter:  657
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -63.434948822922024
Distance to goal 29.068883707497267
Distance in cm: 145.34441853748635 > 50.0
continuous actions for exploring
agent angle = -90.0
angle stg goal = -78.69006752597979
angle final goal = -63.434948822922024
-0.25 0.05 rel ang = -11.30993247402023
-----------------


======= labels_counter:  658
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -72.89727103094765
Distance to goal 27.202941017470888
Distance in cm: 136.01470508735443 > 50.0
continuous actions for exploring
agent angle = -90.0
angle stg goal = -53.13010235415598
angle final goal = -72.89727103094765
-0.2 0.15000000000000002 rel ang = -36.86989764584405
-----------------


======= labels_counter:  659
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']


======= labels_counter:  660
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']


======= labels_counter:  661
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']


======= labels_counter:  662
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']


======= labels_counter:  663
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']


======= labels_counter:  664
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']


======= labels_counter:  665
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']


======= labels_counter:  666
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']


======= labels_counter:  667
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']


======= labels_counter:  668
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']


======= labels_counter:  669
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 42.89727103094762
Distance to goal 40.80441152620633
Distance in cm: 204.02205763103166 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 45.0
angle final goal = 42.89727103094762
0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  670
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 47.79953127261922
Distance to goal 37.8549864614954
Distance in cm: 189.274932307477 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 45.0
angle final goal = 47.79953127261922
0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  671
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 53.290163192243064
Distance to goal 34.23448553724738
Distance in cm: 171.17242768623692 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 14.036243467926479
angle final goal = 53.290163192243064
0.05 0.2 rel ang = 45.96375653207352
-----------------


======= labels_counter:  672
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 40.30486172755509
Distance to goal 44.721359549995796
Distance in cm: 223.60679774997897 > 50.0
continuous actions for exploring
agent angle = 30.000015258789062
angle stg goal = 14.036243467926479
angle final goal = 40.30486172755509
0.05 0.2 rel ang = 15.963771790862584
-----------------


======= labels_counter:  673
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 10.304907503922283
Distance to goal 44.721359549995796
Distance in cm: 223.60679774997897 > 50.0
continuous actions for exploring
agent angle = 6.103515625e-05
angle stg goal = 14.036243467926479
angle final goal = 10.304907503922283
0.05 0.2 rel ang = -14.036182432770204
-----------------


======= labels_counter:  674
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 11.592266963025446
Distance to goal 39.81205847478876
Distance in cm: 199.0602923739438 > 50.0
continuous actions for exploring
agent angle = 9.1552734375e-05
angle stg goal = 45.0
angle final goal = 11.592266963025446
0.15000000000000002 0.15000000000000002 rel ang = -44.999908447265625
-----------------


======= labels_counter:  675
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 42.994723603439944
Distance to goal 40.024992192379
Distance in cm: 200.124960961895 > 50.0
continuous actions for exploring
agent angle = 30.000106811523438
angle stg goal = 45.0
angle final goal = 42.994723603439944
0.15000000000000002 0.15000000000000002 rel ang = -14.999893188476562
-----------------


======= labels_counter:  676
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 48.92476648636374
Distance to goal 37.0
Distance in cm: 185.0 > 50.0
continuous actions for exploring
agent angle = 30.0001220703125
angle stg goal = 45.0
angle final goal = 48.92476648636374
0.15000000000000002 0.15000000000000002 rel ang = -14.9998779296875
-----------------


======= labels_counter:  677
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 54.304671336249214
Distance to goal 34.0147027033899
Distance in cm: 170.0735135169495 > 50.0
continuous actions for exploring
agent angle = 30.0001220703125
angle stg goal = 0.0
angle final goal = 54.304671336249214
0.0 0.2 rel ang = 30.0001220703125
-----------------


======= labels_counter:  678
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move plant_container from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 29.357936648260026
Distance to goal 36.71511950137164
Distance in cm: 183.5755975068582 > 50.0
continuous actions for exploring
agent angle = 0.00018310546875
angle stg goal = 143.13010235415598
angle final goal = 29.357936648260026
0.15000000000000002 -0.2 rel ang = -143.12991924868723
-----------------


======= labels_counter:  679
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']


======= labels_counter:  680
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']


======= labels_counter:  681
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']


======= labels_counter:  682
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']


======= labels_counter:  683
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']


======= labels_counter:  684
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']


======= labels_counter:  685
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']


======= labels_counter:  686
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']


======= labels_counter:  687
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']


======= labels_counter:  688
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']


======= labels_counter:  689
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 25.407665536122863
Distance to goal 35.22782990761707
Distance in cm: 176.13914953808535 > 50.0
continuous actions for exploring
agent angle = 59.99995422363281
angle stg goal = 143.13010235415598
angle final goal = 25.407665536122863
0.15000000000000002 -0.2 rel ang = -83.13014813052314
-----------------


======= labels_counter:  690
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 55.407741830068176
Distance to goal 35.22782990761707
Distance in cm: 176.13914953808535 > 50.0
continuous actions for exploring
agent angle = 90.00003051757812
angle stg goal = 143.13010235415598
angle final goal = 55.407741830068176
0.15000000000000002 -0.2 rel ang = -53.13007183657783
-----------------


======= labels_counter:  691
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 85.40774183006818
Distance to goal 35.22782990761707
Distance in cm: 176.13914953808535 > 50.0
continuous actions for exploring
agent angle = 120.00003051757812
angle stg goal = 143.13010235415598
angle final goal = 85.40774183006818
0.15000000000000002 -0.2 rel ang = -23.130071836577827
-----------------


======= labels_counter:  692
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 115.4077723476463
Distance to goal 35.22782990761707
Distance in cm: 176.13914953808535 > 50.0
continuous actions for exploring
agent angle = 150.00006103515625
angle stg goal = 143.13010235415598
angle final goal = 115.4077723476463
0.15000000000000002 -0.2 rel ang = 6.86995868100027
-----------------


======= labels_counter:  693
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 122.10279000420863
Distance to goal 38.47076812334269
Distance in cm: 192.35384061671343 > 50.0
continuous actions for exploring
agent angle = 150.00006103515625
angle stg goal = 116.56505117707799
angle final goal = 122.10279000420863
0.2 -0.1 rel ang = 33.43500985807826
-----------------


======= labels_counter:  694
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 92.10279000420863
Distance to goal 38.47076812334269
Distance in cm: 192.35384061671343 > 50.0
continuous actions for exploring
agent angle = 120.00006103515625
angle stg goal = 116.56505117707799
angle final goal = 92.10279000420863
0.2 -0.1 rel ang = 3.43500985807826
-----------------


======= labels_counter:  695
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 56.56511221223424
Distance to goal 38.01315561749642
Distance in cm: 190.0657780874821 > 50.0
continuous actions for exploring
agent angle = 120.00006103515625
angle stg goal = 116.56505117707799
angle final goal = 56.56511221223424
0.2 -0.1 rel ang = 3.43500985807826
-----------------


======= labels_counter:  696
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 60.96381756722977
Distance to goal 34.9857113690718
Distance in cm: 174.928556845359 > 50.0
continuous actions for exploring
agent angle = 120.00006103515625
angle stg goal = 116.56505117707799
angle final goal = 60.96381756722977
0.2 -0.1 rel ang = 3.43500985807826
-----------------


======= labels_counter:  697
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 67.56865306398373
Distance to goal 32.802438933713454
Distance in cm: 164.01219466856728 > 50.0
continuous actions for exploring
agent angle = 120.00006103515625
angle stg goal = 116.56505117707799
angle final goal = 67.56865306398373
0.2 -0.1 rel ang = 3.43500985807826
-----------------


======= labels_counter:  698
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 18
[ObjectNav] Goal name:  ['Move folder from bench to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 76.27309105521296
Distance to goal 31.827660925679098
Distance in cm: 159.13830462839547 > 50.0
continuous actions for exploring
agent angle = 120.00006103515625
angle stg goal = 116.56505117707799
angle final goal = 76.27309105521296
0.2 -0.1 rel ang = 3.43500985807826
-----------------


======= labels_counter:  699
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  700
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  701
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  702
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  703
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  704
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  705
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  706
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  707
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  708
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  709
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 61.90915243299638
Distance to goal 30.01666203960727
Distance in cm: 150.08331019803634 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = -111.80140948635182
angle final goal = 61.90915243299638
-0.25 -0.1 rel ang = 171.80140948635182
-----------------


======= labels_counter:  710
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 31.9091829505745
Distance to goal 30.01666203960727
Distance in cm: 150.08331019803634 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = -111.80140948635182
angle final goal = 31.9091829505745
-0.25 -0.1 rel ang = 141.80144000392994
-----------------


======= labels_counter:  711
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 1.9091982093635638
Distance to goal 30.01666203960727
Distance in cm: 150.08331019803634 > 50.0
continuous actions for exploring
agent angle = 4.57763671875e-05
angle stg goal = -111.80140948635182
angle final goal = 1.9091982093635638
-0.25 -0.1 rel ang = 111.801455262719
-----------------


======= labels_counter:  712
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -28.09080179063642
Distance to goal 30.01666203960727
Distance in cm: 150.08331019803634 > 50.0
continuous actions for exploring
agent angle = -29.999954223632812
angle stg goal = -111.80140948635182
angle final goal = -28.09080179063642
-0.25 -0.1 rel ang = 81.801455262719
-----------------


======= labels_counter:  713
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -58.09080179063642
Distance to goal 30.01666203960727
Distance in cm: 150.08331019803634 > 50.0
continuous actions for exploring
agent angle = -59.99995422363281
angle stg goal = -111.80140948635182
angle final goal = -58.09080179063642
-0.25 -0.1 rel ang = 51.801455262719
-----------------


======= labels_counter:  714
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -88.09078653184736
Distance to goal 30.01666203960727
Distance in cm: 150.08331019803634 > 50.0
continuous actions for exploring
agent angle = -89.99993896484375
angle stg goal = -111.80140948635182
angle final goal = -88.09078653184736
-0.25 -0.1 rel ang = 21.801470521508065
-----------------


======= labels_counter:  715
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -118.09078653184736
Distance to goal 30.01666203960727
Distance in cm: 150.08331019803634 > 50.0
continuous actions for exploring
agent angle = -119.99993896484375
angle stg goal = -111.80140948635182
angle final goal = -118.09078653184736
-0.25 -0.1 rel ang = -8.198529478491935
-----------------


======= labels_counter:  716
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 239)
  - delta = -5 -1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -126.91116608386844
Distance to goal 33.24154027718932
Distance in cm: 166.20770138594662 > 50.0
continuous actions for exploring
agent angle = -119.99993896484375
angle stg goal = -101.30993247402021
angle final goal = -126.91116608386844
-0.25 -0.05 rel ang = -18.69000649082352
-----------------


======= labels_counter:  717
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -96.91116608386847
Distance to goal 33.24154027718932
Distance in cm: 166.20770138594662 > 50.0
continuous actions for exploring
agent angle = -89.99993896484375
angle stg goal = -111.80140948635182
angle final goal = -96.91116608386847
-0.25 -0.1 rel ang = 21.801470521508065
-----------------


======= labels_counter:  718
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -126.91116608386844
Distance to goal 33.24154027718932
Distance in cm: 166.20770138594662 > 50.0
continuous actions for exploring
agent angle = -119.99993896484375
angle stg goal = -111.80140948635182
angle final goal = -126.91116608386844
-0.25 -0.1 rel ang = -8.198529478491935
-----------------


======= labels_counter:  719
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']


======= labels_counter:  720
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']


======= labels_counter:  721
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']


======= labels_counter:  722
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']


======= labels_counter:  723
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']


======= labels_counter:  724
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']


======= labels_counter:  725
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']


======= labels_counter:  726
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']


======= labels_counter:  727
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']


======= labels_counter:  728
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']


======= labels_counter:  729
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 75.52401944401988
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 59.999908447265625
angle stg goal = 75.96375653207353
angle final goal = 75.52401944401988
0.2 0.05 rel ang = -15.963848084807921
-----------------


======= labels_counter:  730
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 105.52401944401988
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 89.99990844726562
angle stg goal = 75.96375653207353
angle final goal = 105.52401944401988
0.2 0.05 rel ang = 14.036151915192093
-----------------


======= labels_counter:  731
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 119.05451254634278
Distance to goal 20.591260281974
Distance in cm: 102.95630140987001 > 50.0
continuous actions for exploring
agent angle = 89.99990844726562
angle stg goal = 45.0
angle final goal = 119.05451254634278
0.15000000000000002 0.15000000000000002 rel ang = 44.999908447265625
-----------------


======= labels_counter:  732
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 89.05451254634278
Distance to goal 20.591260281974
Distance in cm: 102.95630140987001 > 50.0
continuous actions for exploring
agent angle = 59.999908447265625
angle stg goal = 45.0
angle final goal = 89.05451254634278
0.15000000000000002 0.15000000000000002 rel ang = 14.999908447265625
-----------------


======= labels_counter:  733
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 95.2175166742474
Distance to goal 20.808652046684813
Distance in cm: 104.04326023342406 > 50.0
continuous actions for exploring
agent angle = 59.99992370605469
angle stg goal = 0.0
angle final goal = 95.2175166742474
0.0 0.2 rel ang = 59.99992370605469
-----------------


======= labels_counter:  734
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 65.21753193303647
Distance to goal 20.808652046684813
Distance in cm: 104.04326023342406 > 50.0
continuous actions for exploring
agent angle = 29.99993896484375
angle stg goal = 116.56505117707799
angle final goal = 65.21753193303647
0.2 -0.1 rel ang = -86.56511221223423
-----------------


======= labels_counter:  735
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 95.2175624506146
Distance to goal 20.808652046684813
Distance in cm: 104.04326023342406 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 116.56505117707799
angle final goal = 95.2175624506146
0.2 -0.1 rel ang = -56.5650816946561
-----------------


======= labels_counter:  736
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 125.2175624506146
Distance to goal 20.808652046684813
Distance in cm: 104.04326023342406 > 50.0
continuous actions for exploring
agent angle = 89.99996948242188
angle stg goal = 116.56505117707799
angle final goal = 125.2175624506146
0.2 -0.1 rel ang = -26.5650816946561
-----------------


======= labels_counter:  737
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 155.2175624506146
Distance to goal 20.808652046684813
Distance in cm: 104.04326023342406 > 50.0
continuous actions for exploring
agent angle = 119.99996948242188
angle stg goal = 116.56505117707799
angle final goal = 155.2175624506146
0.2 -0.1 rel ang = 3.434918305343885
-----------------


======= labels_counter:  738
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move scissors from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 239)
  - delta = 4 -1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 160.10084651105598
Distance to goal 24.839484696748443
Distance in cm: 124.19742348374221 > 50.0
continuous actions for exploring
agent angle = 119.99993896484375
angle stg goal = 104.03624346792648
angle final goal = 160.10084651105598
0.2 -0.05 rel ang = 15.963695496917268
-----------------


======= labels_counter:  739
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  740
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  741
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  742
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  743
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  744
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  745
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  746
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  747
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  748
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']


======= labels_counter:  749
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 119.34942359568151
Distance to goal 31.38470965295043
Distance in cm: 156.92354826475216 > 50.0
continuous actions for exploring
agent angle = 60.000091552734375
angle stg goal = 45.0
angle final goal = 119.34942359568151
0.15000000000000002 0.15000000000000002 rel ang = 15.000091552734375
-----------------


======= labels_counter:  750
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 89.34942359568151
Distance to goal 31.38470965295043
Distance in cm: 156.92354826475216 > 50.0
continuous actions for exploring
agent angle = 30.000091552734375
angle stg goal = 45.0
angle final goal = 89.34942359568151
0.15000000000000002 0.15000000000000002 rel ang = -14.999908447265625
-----------------


======= labels_counter:  751
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 88.39258930648548
Distance to goal 30.528675044947494
Distance in cm: 152.64337522473747 > 50.0
continuous actions for exploring
agent angle = 30.000091552734375
angle stg goal = 45.0
angle final goal = 88.39258930648548
0.15000000000000002 0.15000000000000002 rel ang = -14.999908447265625
-----------------


======= labels_counter:  752
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 97.52065715563127
Distance to goal 31.38470965295043
Distance in cm: 156.92354826475216 > 50.0
continuous actions for exploring
agent angle = 30.000091552734375
angle stg goal = 45.0
angle final goal = 97.52065715563127
0.15000000000000002 0.15000000000000002 rel ang = -14.999908447265625
-----------------


======= labels_counter:  753
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 101.56514272981237
Distance to goal 31.622776601683793
Distance in cm: 158.11388300841895 > 50.0
continuous actions for exploring
agent angle = 30.000091552734375
angle stg goal = 45.0
angle final goal = 101.56514272981237
0.15000000000000002 0.15000000000000002 rel ang = -14.999908447265625
-----------------


======= labels_counter:  754
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 22.146778250756157
Distance to goal 29.274562336608895
Distance in cm: 146.37281168304446 > 50.0
continuous actions for exploring
agent angle = 30.000091552734375
angle stg goal = 45.0
angle final goal = 22.146778250756157
0.15000000000000002 0.15000000000000002 rel ang = -14.999908447265625
-----------------


======= labels_counter:  755
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 25.426170292833515
Distance to goal 25.079872407968907
Distance in cm: 125.39936203984453 > 50.0
continuous actions for exploring
agent angle = 30.000091552734375
angle stg goal = 75.96375653207353
angle final goal = 25.426170292833515
0.2 0.05 rel ang = -45.96366497933917
-----------------


======= labels_counter:  756
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 57.79749339096857
Distance to goal 26.019223662515376
Distance in cm: 130.0961183125769 > 50.0
continuous actions for exploring
agent angle = 60.000091552734375
angle stg goal = 75.96375653207353
angle final goal = 57.79749339096857
0.2 0.05 rel ang = -15.963664979339171
-----------------


======= labels_counter:  757
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 87.79749339096857
Distance to goal 26.019223662515376
Distance in cm: 130.0961183125769 > 50.0
continuous actions for exploring
agent angle = 90.00009155273438
angle stg goal = 75.96375653207353
angle final goal = 87.79749339096857
0.2 0.05 rel ang = 14.036335020660843
-----------------


======= labels_counter:  758
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 4
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 98.74625381528958
Distance to goal 26.30589287593181
Distance in cm: 131.52946437965906 > 50.0
continuous actions for exploring
agent angle = 90.00009155273438
angle stg goal = 45.0
angle final goal = 98.74625381528958
0.15000000000000002 0.15000000000000002 rel ang = 45.000091552734375
-----------------


======= labels_counter:  759
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']


======= labels_counter:  760
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']


======= labels_counter:  761
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']


======= labels_counter:  762
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']


======= labels_counter:  763
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']


======= labels_counter:  764
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']


======= labels_counter:  765
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']


======= labels_counter:  766
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']


======= labels_counter:  767
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']


======= labels_counter:  768
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']


======= labels_counter:  769
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 98.15724184615812
Distance to goal 35.608987629529715
Distance in cm: 178.04493814764857 > 50.0
continuous actions for exploring
agent angle = 60.00001525878906
angle stg goal = 45.0
angle final goal = 98.15724184615812
0.15000000000000002 0.15000000000000002 rel ang = 15.000015258789062
-----------------


======= labels_counter:  770
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 68.15725710494718
Distance to goal 35.608987629529715
Distance in cm: 178.04493814764857 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = 45.0
angle final goal = 68.15725710494718
0.15000000000000002 0.15000000000000002 rel ang = -14.999969482421875
-----------------


======= labels_counter:  771
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 75.00003051757812
Distance to goal 33.94112549695428
Distance in cm: 169.70562748477138 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = 45.0
angle final goal = 75.00003051757812
0.15000000000000002 0.15000000000000002 rel ang = -14.999969482421875
-----------------


======= labels_counter:  772
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 81.07248692478584
Distance to goal 33.421549934136806
Distance in cm: 167.10774967068403 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = 45.0
angle final goal = 81.07248692478584
0.15000000000000002 0.15000000000000002 rel ang = -14.999969482421875
-----------------


======= labels_counter:  773
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 73.72700049752142
Distance to goal 31.827660925679098
Distance in cm: 159.13830462839547 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = 45.0
angle final goal = 73.72700049752142
0.15000000000000002 0.15000000000000002 rel ang = -14.999969482421875
-----------------


======= labels_counter:  774
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 75.00003051757812
Distance to goal 29.698484809834994
Distance in cm: 148.49242404917499 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = 45.0
angle final goal = 75.00003051757812
0.15000000000000002 0.15000000000000002 rel ang = -14.999969482421875
-----------------


======= labels_counter:  775
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 77.86243574368987
Distance to goal 28.319604517012593
Distance in cm: 141.59802258506295 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = 75.96375653207353
angle final goal = 77.86243574368987
0.2 0.05 rel ang = -45.96372601449542
-----------------


======= labels_counter:  776
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 107.86243574368987
Distance to goal 28.319604517012593
Distance in cm: 141.59802258506295 > 50.0
continuous actions for exploring
agent angle = 60.000030517578125
angle stg goal = 45.0
angle final goal = 107.86243574368987
0.15000000000000002 0.15000000000000002 rel ang = 15.000030517578125
-----------------


======= labels_counter:  777
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 77.86245100247893
Distance to goal 28.319604517012593
Distance in cm: 141.59802258506295 > 50.0
continuous actions for exploring
agent angle = 30.000045776367188
angle stg goal = 45.0
angle final goal = 77.86245100247893
0.15000000000000002 0.15000000000000002 rel ang = -14.999954223632812
-----------------


======= labels_counter:  778
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move tray from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 240)
  - delta = 4 0
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 75.00004577636719
Distance to goal 26.870057685088806
Distance in cm: 134.35028842544403 > 50.0
continuous actions for exploring
agent angle = 30.000045776367188
angle stg goal = 90.0
angle final goal = 75.00004577636719
0.2 0.0 rel ang = -59.99995422363281
-----------------


======= labels_counter:  779
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']


======= labels_counter:  780
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']


======= labels_counter:  781
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']


======= labels_counter:  782
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']


======= labels_counter:  783
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']


======= labels_counter:  784
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']


======= labels_counter:  785
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']


======= labels_counter:  786
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']


======= labels_counter:  787
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']


======= labels_counter:  788
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']


======= labels_counter:  789
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -136.50436138175502
Distance to goal 28.160255680657446
Distance in cm: 140.80127840328723 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 14.036243467926479
angle final goal = -136.50436138175502
0.05 0.2 rel ang = 45.96375653207352
-----------------


======= labels_counter:  790
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -166.50436138175502
Distance to goal 28.160255680657446
Distance in cm: 140.80127840328723 > 50.0
continuous actions for exploring
agent angle = 30.0
angle stg goal = 14.036243467926479
angle final goal = -166.50436138175502
0.05 0.2 rel ang = 15.963756532073521
-----------------


======= labels_counter:  791
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 163.49563861824498
Distance to goal 28.160255680657446
Distance in cm: 140.80127840328723 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = 14.036243467926479
angle final goal = 163.49563861824498
0.05 0.2 rel ang = -14.036243467926454
-----------------


======= labels_counter:  792
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 160.46334506187162
Distance to goal 32.89376840679705
Distance in cm: 164.46884203398525 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = 14.036243467926479
angle final goal = 160.46334506187162
0.05 0.2 rel ang = -14.036243467926454
-----------------


======= labels_counter:  793
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -55.304846468766016
Distance to goal 31.622776601683793
Distance in cm: 158.11388300841895 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = 14.036243467926479
angle final goal = -55.304846468766016
0.05 0.2 rel ang = -14.036243467926454
-----------------


======= labels_counter:  794
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -63.434948822922024
Distance to goal 29.068883707497267
Distance in cm: 145.34441853748635 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = 14.036243467926479
angle final goal = -63.434948822922024
0.05 0.2 rel ang = -14.036243467926454
-----------------


======= labels_counter:  795
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -72.89727103094765
Distance to goal 27.202941017470888
Distance in cm: 136.01470508735443 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = 14.036243467926479
angle final goal = -72.89727103094765
0.05 0.2 rel ang = -14.036243467926454
-----------------


======= labels_counter:  796
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -83.418055344822
Distance to goal 26.1725046566048
Distance in cm: 130.86252328302402 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = 45.0
angle final goal = -83.418055344822
0.15000000000000002 0.15000000000000002 rel ang = -45.0
-----------------


======= labels_counter:  797
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -53.88449643371462
Distance to goal 28.160255680657446
Distance in cm: 140.80127840328723 > 50.0
continuous actions for exploring
agent angle = 30.0
angle stg goal = 45.0
angle final goal = -53.88449643371462
0.15000000000000002 0.15000000000000002 rel ang = -15.0
-----------------


======= labels_counter:  798
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 9
[ObjectNav] Goal name:  ['Move lunch_box from bench to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -62.20259816176582
Distance to goal 26.019223662515376
Distance in cm: 130.0961183125769 > 50.0
continuous actions for exploring
agent angle = 30.0
angle stg goal = 45.0
angle final goal = -62.20259816176582
0.15000000000000002 0.15000000000000002 rel ang = -15.0
-----------------


======= labels_counter:  799
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']


======= labels_counter:  800
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']


======= labels_counter:  801
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']


======= labels_counter:  802
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']


======= labels_counter:  803
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']


======= labels_counter:  804
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']


======= labels_counter:  805
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']


======= labels_counter:  806
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']


======= labels_counter:  807
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']


======= labels_counter:  808
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']


======= labels_counter:  809
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 160.88552705465872
Distance to goal 26.476404589747453
Distance in cm: 132.38202294873727 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 75.96375653207353
angle final goal = 160.88552705465872
0.2 0.05 rel ang = -15.963756532073546
-----------------


======= labels_counter:  810
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -169.11447294534128
Distance to goal 26.476404589747453
Distance in cm: 132.38202294873727 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = -169.11447294534128
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  811
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -170.83765295427827
Distance to goal 31.400636936215164
Distance in cm: 157.00318468107582 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = -170.83765295427827
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  812
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 46.21887523513129
Distance to goal 33.24154027718932
Distance in cm: 166.20770138594662 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = 46.21887523513129
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  813
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 53.13010235415598
Distance to goal 30.0
Distance in cm: 150.0 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = 53.13010235415598
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  814
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 61.55707137563665
Distance to goal 27.294688127912362
Distance in cm: 136.4734406395618 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = 61.55707137563665
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  815
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 71.56505117707799
Distance to goal 25.298221281347036
Distance in cm: 126.49110640673518 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = 71.56505117707799
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  816
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 82.8749836510982
Distance to goal 24.186773244895647
Distance in cm: 120.93386622447824 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = 82.8749836510982
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  817
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 94.76364169072617
Distance to goal 24.08318915758459
Distance in cm: 120.41594578792296 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 45.0
angle final goal = 94.76364169072617
0.15000000000000002 0.15000000000000002 rel ang = 45.0
-----------------


======= labels_counter:  818
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move credit_card from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 64.76364169072617
Distance to goal 24.08318915758459
Distance in cm: 120.41594578792296 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 45.0
angle final goal = 64.76364169072617
0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  819
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']


======= labels_counter:  820
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']


======= labels_counter:  821
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']


======= labels_counter:  822
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']


======= labels_counter:  823
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']


======= labels_counter:  824
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']


======= labels_counter:  825
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']


======= labels_counter:  826
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']


======= labels_counter:  827
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']


======= labels_counter:  828
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']


======= labels_counter:  829
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 132.25537415131026
Distance to goal 26.248809496813376
Distance in cm: 131.24404748406687 > 50.0
continuous actions for exploring
agent angle = 60.00004577636719
angle stg goal = 45.0
angle final goal = 132.25537415131026
0.15000000000000002 0.15000000000000002 rel ang = 15.000045776367188
-----------------


======= labels_counter:  830
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 102.25538941009931
Distance to goal 26.248809496813376
Distance in cm: 131.24404748406687 > 50.0
continuous actions for exploring
agent angle = 30.00006103515625
angle stg goal = 45.0
angle final goal = 102.25538941009931
0.15000000000000002 0.15000000000000002 rel ang = -14.99993896484375
-----------------


======= labels_counter:  831
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 111.57309201367558
Distance to goal 27.294688127912362
Distance in cm: 136.4734406395618 > 50.0
continuous actions for exploring
agent angle = 30.00006103515625
angle stg goal = 45.0
angle final goal = 111.57309201367558
0.15000000000000002 0.15000000000000002 rel ang = -14.99993896484375
-----------------


======= labels_counter:  832
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 112.14674773317803
Distance to goal 29.274562336608895
Distance in cm: 146.37281168304446 > 50.0
continuous actions for exploring
agent angle = 30.00006103515625
angle stg goal = 45.0
angle final goal = 112.14674773317803
0.15000000000000002 0.15000000000000002 rel ang = -14.99993896484375
-----------------


======= labels_counter:  833
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 112.40541766656482
Distance to goal 30.265491900843113
Distance in cm: 151.32745950421557 > 50.0
continuous actions for exploring
agent angle = 30.00006103515625
angle stg goal = 45.0
angle final goal = 112.40541766656482
0.15000000000000002 0.15000000000000002 rel ang = -14.99993896484375
-----------------


======= labels_counter:  834
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 121.73576562408464
Distance to goal 33.015148038438355
Distance in cm: 165.07574019219177 > 50.0
continuous actions for exploring
agent angle = 30.00006103515625
angle stg goal = 45.0
angle final goal = 121.73576562408464
0.15000000000000002 0.15000000000000002 rel ang = -14.99993896484375
-----------------


======= labels_counter:  835
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 51.447797362261596
Distance to goal 30.083217912982647
Distance in cm: 150.41608956491325 > 50.0
continuous actions for exploring
agent angle = 30.00006103515625
angle stg goal = 45.0
angle final goal = 51.447797362261596
0.15000000000000002 0.15000000000000002 rel ang = -14.99993896484375
-----------------


======= labels_counter:  836
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 60.25649819868551
Distance to goal 27.784887978899608
Distance in cm: 138.92443989449805 > 50.0
continuous actions for exploring
agent angle = 30.00006103515625
angle stg goal = 45.0
angle final goal = 60.25649819868551
0.15000000000000002 0.15000000000000002 rel ang = -14.99993896484375
-----------------


======= labels_counter:  837
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 70.10096858136849
Distance to goal 24.839484696748443
Distance in cm: 124.19742348374221 > 50.0
continuous actions for exploring
agent angle = 30.00006103515625
angle stg goal = 14.036243467926479
angle final goal = 70.10096858136849
0.05 0.2 rel ang = 15.963817567229771
-----------------


======= labels_counter:  838
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move cellphone from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 46.39725732124169
Distance to goal 29.0
Distance in cm: 145.0 > 50.0
continuous actions for exploring
agent angle = 7.62939453125e-05
angle stg goal = 45.0
angle final goal = 46.39725732124169
0.15000000000000002 0.15000000000000002 rel ang = -44.99992370605469
-----------------


======= labels_counter:  839
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  840
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  841
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  842
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  843
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  844
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  845
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  846
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  847
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  848
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']


======= labels_counter:  849
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: True
reduced obs dilation to 2
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 75.52420254948863
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 60.000091552734375
angle stg goal = -111.80140948635182
angle final goal = 75.52420254948863
-0.25 -0.1 rel ang = 171.8015010390862
-----------------


======= labels_counter:  850
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 45.524202549488635
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 30.000091552734375
angle stg goal = -111.80140948635182
angle final goal = 45.524202549488635
-0.25 -0.1 rel ang = 141.8015010390862
-----------------


======= labels_counter:  851
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 15.524202549488633
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 9.1552734375e-05
angle stg goal = -111.80140948635182
angle final goal = 15.524202549488633
-0.25 -0.1 rel ang = 111.80150103908619
-----------------


======= labels_counter:  852
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -14.47579745051138
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = -29.999908447265625
angle stg goal = -111.80140948635182
angle final goal = -14.47579745051138
-0.25 -0.1 rel ang = 81.80150103908619
-----------------


======= labels_counter:  853
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -44.47579745051138
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = -59.999908447265625
angle stg goal = -111.80140948635182
angle final goal = -44.47579745051138
-0.25 -0.1 rel ang = 51.80150103908619
-----------------


======= labels_counter:  854
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -74.47579745051138
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = -89.99990844726562
angle stg goal = -111.80140948635182
angle final goal = -74.47579745051138
-0.25 -0.1 rel ang = 21.80150103908619
-----------------


======= labels_counter:  855
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -104.47579745051138
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = -119.99990844726562
angle stg goal = -111.80140948635182
angle final goal = -104.47579745051138
-0.25 -0.1 rel ang = -8.19849896091381
-----------------


======= labels_counter:  856
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -117.27359745335934
Distance to goal 21.02379604162864
Distance in cm: 105.1189802081432 > 50.0
continuous actions for exploring
agent angle = -119.99990844726562
angle stg goal = -53.13010235415598
angle final goal = -117.27359745335934
-0.2 0.15000000000000002 rel ang = -66.86980609310967
-----------------


======= labels_counter:  857
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -87.27359745335934
Distance to goal 21.02379604162864
Distance in cm: 105.1189802081432 > 50.0
continuous actions for exploring
agent angle = -89.99990844726562
angle stg goal = -53.13010235415598
angle final goal = -87.27359745335934
-0.2 0.15000000000000002 rel ang = -36.86980609310967
-----------------


======= labels_counter:  858
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move ramekin from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -57.27359745335934
Distance to goal 21.02379604162864
Distance in cm: 105.1189802081432 > 50.0
continuous actions for exploring
agent angle = -59.999908447265625
angle stg goal = -53.13010235415598
angle final goal = -57.27359745335934
-0.2 0.15000000000000002 rel ang = -6.869806093109673
-----------------


======= labels_counter:  859
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']


======= labels_counter:  860
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']


======= labels_counter:  861
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']


======= labels_counter:  862
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']


======= labels_counter:  863
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']


======= labels_counter:  864
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']


======= labels_counter:  865
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']


======= labels_counter:  866
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']


======= labels_counter:  867
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']


======= labels_counter:  868
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']


======= labels_counter:  869
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: True
reduced obs dilation to 2
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -135.52408047917612
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 60.000030517578125
angle stg goal = -111.80140948635182
angle final goal = -135.52408047917612
-0.25 -0.1 rel ang = 171.80144000392994
-----------------


======= labels_counter:  870
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -165.52408047917612
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 30.000030517578125
angle stg goal = -53.13010235415598
angle final goal = -165.52408047917612
-0.2 0.15000000000000002 rel ang = 83.1301328717341
-----------------


======= labels_counter:  871
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 164.47591952082388
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 3.0517578125e-05
angle stg goal = -53.13010235415598
angle final goal = 164.47591952082388
-0.2 0.15000000000000002 rel ang = 53.130132871734105
-----------------


======= labels_counter:  872
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 134.47593477961294
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = -29.999954223632812
angle stg goal = -53.13010235415598
angle final goal = 134.47593477961294
-0.2 0.15000000000000002 rel ang = 23.130148130523168
-----------------


======= labels_counter:  873
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 104.47591952082388
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = -59.999969482421875
angle stg goal = -53.13010235415598
angle final goal = 104.47591952082388
-0.2 0.15000000000000002 rel ang = -6.869867128265923
-----------------


======= labels_counter:  874
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 101.56508169465613
Distance to goal 18.973665961010276
Distance in cm: 94.86832980505139 > 50.0
continuous actions for exploring
agent angle = -59.999969482421875
angle stg goal = -53.13010235415598
angle final goal = 101.56508169465613
-0.2 0.15000000000000002 rel ang = -6.869867128265923
-----------------


======= labels_counter:  875
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 101.56508169465613
Distance to goal 18.973665961010276
Distance in cm: 94.86832980505139 > 50.0
continuous actions for exploring
agent angle = -59.999969482421875
angle stg goal = -26.56505117707799
angle final goal = 101.56508169465613
-0.1 0.2 rel ang = -33.4349183053439
-----------------


======= labels_counter:  876
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 131.56508169465613
Distance to goal 18.973665961010276
Distance in cm: 94.86832980505139 > 50.0
continuous actions for exploring
agent angle = -29.999969482421875
angle stg goal = -26.56505117707799
angle final goal = 131.56508169465613
-0.1 0.2 rel ang = -3.434918305343899
-----------------


======= labels_counter:  877
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 103.02509650669614
Distance to goal 20.518284528683193
Distance in cm: 102.59142264341597 > 50.0
continuous actions for exploring
agent angle = -29.999969482421875
angle stg goal = -53.13010235415598
angle final goal = 103.02509650669614
-0.2 0.15000000000000002 rel ang = 23.130132871734105
-----------------


======= labels_counter:  878
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move candy_bar from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 73.02509650669614
Distance to goal 20.518284528683193
Distance in cm: 102.59142264341597 > 50.0
continuous actions for exploring
agent angle = -59.999969482421875
angle stg goal = 14.036243467926479
angle final goal = 73.02509650669614
0.05 0.2 rel ang = -74.03621295034839
-----------------


======= labels_counter:  879
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']


======= labels_counter:  880
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']


======= labels_counter:  881
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']


======= labels_counter:  882
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']


======= labels_counter:  883
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']


======= labels_counter:  884
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']


======= labels_counter:  885
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']


======= labels_counter:  886
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']


======= labels_counter:  887
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']


======= labels_counter:  888
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']


======= labels_counter:  889
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -17.124998440387515
Distance to goal 35.90264614203248
Distance in cm: 179.51323071016242 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = -26.56505117707799
angle final goal = -17.124998440387515
-0.1 0.2 rel ang = 86.56505117707799
-----------------


======= labels_counter:  890
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -47.12501369917658
Distance to goal 35.90264614203248
Distance in cm: 179.51323071016242 > 50.0
continuous actions for exploring
agent angle = 29.999984741210938
angle stg goal = -26.56505117707799
angle final goal = -47.12501369917658
-0.1 0.2 rel ang = 56.56503591828893
-----------------


======= labels_counter:  891
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -77.12501369917658
Distance to goal 35.90264614203248
Distance in cm: 179.51323071016242 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = -26.56505117707799
angle final goal = -77.12501369917658
-0.1 0.2 rel ang = 26.565035918288928
-----------------


======= labels_counter:  892
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -107.12501369917658
Distance to goal 35.90264614203248
Distance in cm: 179.51323071016242 > 50.0
continuous actions for exploring
agent angle = -30.000015258789062
angle stg goal = -26.56505117707799
angle final goal = -107.12501369917658
-0.1 0.2 rel ang = -3.4349640817110867
-----------------


======= labels_counter:  893
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -50.5560604783725
Distance to goal 34.17601498127012
Distance in cm: 170.88007490635061 > 50.0
continuous actions for exploring
agent angle = -30.000015258789062
angle stg goal = -26.56505117707799
angle final goal = -50.5560604783725
-0.1 0.2 rel ang = -3.4349640817110867
-----------------


======= labels_counter:  894
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -56.56506643586704
Distance to goal 31.304951684997057
Distance in cm: 156.5247584249853 > 50.0
continuous actions for exploring
agent angle = -30.000015258789062
angle stg goal = -26.56505117707799
angle final goal = -56.56506643586704
-0.1 0.2 rel ang = -3.4349640817110867
-----------------


======= labels_counter:  895
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -65.31122869842227
Distance to goal 29.410882339705484
Distance in cm: 147.05441169852742 > 50.0
continuous actions for exploring
agent angle = -30.000015258789062
angle stg goal = 14.036243467926479
angle final goal = -65.31122869842227
0.05 0.2 rel ang = -44.03625872671557
-----------------


======= labels_counter:  896
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -45.00001525878906
Distance to goal 38.18376618407357
Distance in cm: 190.91883092036784 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = 14.036243467926479
angle final goal = -45.00001525878906
0.05 0.2 rel ang = -14.036258726715516
-----------------


======= labels_counter:  897
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -48.50354690357352
Distance to goal 34.713109915419565
Distance in cm: 173.56554957709784 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = 14.036243467926479
angle final goal = -48.50354690357352
0.05 0.2 rel ang = -14.036258726715516
-----------------


======= labels_counter:  898
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move file_sorter from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -55.30486172755508
Distance to goal 31.622776601683793
Distance in cm: 158.11388300841895 > 50.0
continuous actions for exploring
agent angle = -1.52587890625e-05
angle stg goal = 45.0
angle final goal = -55.30486172755508
0.15000000000000002 0.15000000000000002 rel ang = -45.00001525878906
-----------------


======= labels_counter:  899
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']


======= labels_counter:  900
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']


======= labels_counter:  901
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']


======= labels_counter:  902
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']


======= labels_counter:  903
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']


======= labels_counter:  904
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']


======= labels_counter:  905
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']


======= labels_counter:  906
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']


======= labels_counter:  907
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']


======= labels_counter:  908
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']


======= labels_counter:  909
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -135.52411099675425
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 14.036243467926479
angle final goal = -135.52411099675425
0.05 0.2 rel ang = 45.96375653207352
-----------------


======= labels_counter:  910
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -165.5241262555433
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 29.999984741210938
angle stg goal = 14.036243467926479
angle final goal = -165.5241262555433
0.05 0.2 rel ang = 15.963741273284459
-----------------


======= labels_counter:  911
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 164.4758279680895
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = -6.103515625e-05
angle stg goal = 14.036243467926479
angle final goal = 164.4758279680895
0.05 0.2 rel ang = -14.036304503082704
-----------------


======= labels_counter:  912
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 167.73516523695136
Distance to goal 23.53720459187964
Distance in cm: 117.6860229593982 > 50.0
continuous actions for exploring
agent angle = -6.103515625e-05
angle stg goal = 14.036243467926479
angle final goal = 167.73516523695136
0.05 0.2 rel ang = -14.036304503082704
-----------------


======= labels_counter:  913
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 169.87526730944595
Distance to goal 28.442925306655784
Distance in cm: 142.21462653327893 > 50.0
continuous actions for exploring
agent angle = -6.103515625e-05
angle stg goal = 14.036243467926479
angle final goal = 169.87526730944595
0.05 0.2 rel ang = -14.036304503082704
-----------------


======= labels_counter:  914
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 171.38429078067963
Distance to goal 33.37663853655727
Distance in cm: 166.88319268278636 > 50.0
continuous actions for exploring
agent angle = -6.103515625e-05
angle stg goal = 45.0
angle final goal = 171.38429078067963
0.15000000000000002 0.15000000000000002 rel ang = -45.00006103515625
-----------------


======= labels_counter:  915
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -158.61572447810943
Distance to goal 33.37663853655727
Distance in cm: 166.88319268278636 > 50.0
continuous actions for exploring
agent angle = 29.999923706054688
angle stg goal = 45.0
angle final goal = -158.61572447810943
0.15000000000000002 0.15000000000000002 rel ang = -15.000076293945312
-----------------


======= labels_counter:  916
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -128.61572447810943
Distance to goal 33.37663853655727
Distance in cm: 166.88319268278636 > 50.0
continuous actions for exploring
agent angle = 59.99992370605469
angle stg goal = 45.0
angle final goal = -128.61572447810943
0.15000000000000002 0.15000000000000002 rel ang = 14.999923706054688
-----------------


======= labels_counter:  917
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -55.76940391828401
Distance to goal 32.202484376209235
Distance in cm: 161.01242188104618 > 50.0
continuous actions for exploring
agent angle = 59.99992370605469
angle stg goal = 14.036243467926479
angle final goal = -55.76940391828401
0.05 0.2 rel ang = 45.963680238128205
-----------------


======= labels_counter:  918
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move spicemill from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -85.76940391828401
Distance to goal 32.202484376209235
Distance in cm: 161.01242188104618 > 50.0
continuous actions for exploring
agent angle = 29.999923706054688
angle stg goal = 14.036243467926479
angle final goal = -85.76940391828401
0.05 0.2 rel ang = 15.963680238128209
-----------------


======= labels_counter:  919
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']


======= labels_counter:  920
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']


======= labels_counter:  921
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']


======= labels_counter:  922
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']


======= labels_counter:  923
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']


======= labels_counter:  924
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']


======= labels_counter:  925
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']


======= labels_counter:  926
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']


======= labels_counter:  927
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']


======= labels_counter:  928
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']


======= labels_counter:  929
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 63.27045740560544
Distance to goal 35.05709628591621
Distance in cm: 175.28548142958104 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 45.0
angle final goal = 63.27045740560544
0.15000000000000002 0.15000000000000002 rel ang = 14.999969482421875
-----------------


======= labels_counter:  930
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 70.3048159511879
Distance to goal 33.54101966249684
Distance in cm: 167.7050983124842 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 45.0
angle final goal = 70.3048159511879
0.15000000000000002 0.15000000000000002 rel ang = 14.999969482421875
-----------------


======= labels_counter:  931
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 70.3048159511879
Distance to goal 33.54101966249684
Distance in cm: 167.7050983124842 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 14.036243467926479
angle final goal = 70.3048159511879
0.05 0.2 rel ang = 45.96372601449539
-----------------


======= labels_counter:  932
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 42.87497104203435
Distance to goal 35.90264614203248
Distance in cm: 179.51323071016242 > 50.0
continuous actions for exploring
agent angle = 29.999969482421875
angle stg goal = -78.69006752597979
angle final goal = 42.87497104203435
-0.25 0.05 rel ang = 108.69003700840166
-----------------


======= labels_counter:  933
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 12.874971042034351
Distance to goal 35.90264614203248
Distance in cm: 179.51323071016242 > 50.0
continuous actions for exploring
agent angle = -3.0517578125e-05
angle stg goal = -78.69006752597979
angle final goal = 12.874971042034351
-0.25 0.05 rel ang = 78.69003700840166
-----------------


======= labels_counter:  934
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -17.12502895796564
Distance to goal 35.90264614203248
Distance in cm: 179.51323071016242 > 50.0
continuous actions for exploring
agent angle = -30.000030517578125
angle stg goal = -78.69006752597979
angle final goal = -17.12502895796564
-0.25 0.05 rel ang = 48.69003700840166
-----------------


======= labels_counter:  935
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -47.12502895796564
Distance to goal 35.90264614203248
Distance in cm: 179.51323071016242 > 50.0
continuous actions for exploring
agent angle = -60.000030517578125
angle stg goal = -78.69006752597979
angle final goal = -47.12502895796564
-0.25 0.05 rel ang = 18.69003700840166
-----------------


======= labels_counter:  936
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -77.12502895796564
Distance to goal 35.90264614203248
Distance in cm: 179.51323071016242 > 50.0
continuous actions for exploring
agent angle = -90.00003051757812
angle stg goal = -78.69006752597979
angle final goal = -77.12502895796564
-0.25 0.05 rel ang = -11.309962991598354
-----------------


======= labels_counter:  937
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -85.10093806379035
Distance to goal 35.12833614050059
Distance in cm: 175.64168070250298 > 50.0
continuous actions for exploring
agent angle = -90.00003051757812
angle stg goal = -53.13010235415598
angle final goal = -85.10093806379035
-0.2 0.15000000000000002 rel ang = -36.86992816342217
-----------------


======= labels_counter:  938
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move c-clamp from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -55.10093806379035
Distance to goal 35.12833614050059
Distance in cm: 175.64168070250298 > 50.0
continuous actions for exploring
agent angle = -60.000030517578125
angle stg goal = -53.13010235415598
angle final goal = -55.10093806379035
-0.2 0.15000000000000002 rel ang = -6.869928163422173
-----------------


======= labels_counter:  939
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']


======= labels_counter:  940
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']


======= labels_counter:  941
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']


======= labels_counter:  942
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']


======= labels_counter:  943
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']


======= labels_counter:  944
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']


======= labels_counter:  945
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']


======= labels_counter:  946
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']


======= labels_counter:  947
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']


======= labels_counter:  948
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']


======= labels_counter:  949
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -128.7461622625552
Distance to goal 26.30589287593181
Distance in cm: 131.52946437965906 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 75.96375653207353
angle final goal = -128.7461622625552
0.2 0.05 rel ang = -15.963756532073546
-----------------


======= labels_counter:  950
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -98.74616226255523
Distance to goal 26.30589287593181
Distance in cm: 131.52946437965906 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = -98.74616226255523
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  951
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -92.12109639666141
Distance to goal 27.018512172212592
Distance in cm: 135.09256086106296 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 45.0
angle final goal = -92.12109639666141
0.15000000000000002 0.15000000000000002 rel ang = 45.0
-----------------


======= labels_counter:  952
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -122.12109639666144
Distance to goal 27.018512172212592
Distance in cm: 135.09256086106296 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 45.0
angle final goal = -122.12109639666144
0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  953
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -121.97493401088198
Distance to goal 29.017236257093817
Distance in cm: 145.08618128546908 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 45.0
angle final goal = -121.97493401088198
0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  954
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -123.57633437499734
Distance to goal 32.0624390837628
Distance in cm: 160.31219541881399 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 45.0
angle final goal = -123.57633437499734
0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  955
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -66.46923439005184
Distance to goal 28.600699292150182
Distance in cm: 143.0034964607509 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 75.96375653207353
angle final goal = -66.46923439005184
0.2 0.05 rel ang = -15.963756532073546
-----------------


======= labels_counter:  956
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -46.273030020056694
Distance to goal 31.827660925679098
Distance in cm: 159.13830462839547 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 75.96375653207353
angle final goal = -46.273030020056694
0.2 0.05 rel ang = 14.036243467926468
-----------------


======= labels_counter:  957
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 242)
  - delta = 3 2
Distance (m): 0.18027756377319945
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -46.273030020056694
Distance to goal 31.827660925679098
Distance in cm: 159.13830462839547 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = 56.309932474020215
angle final goal = -46.273030020056694
0.15000000000000002 0.1 rel ang = 33.690067525979785
-----------------


======= labels_counter:  958
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 6
[ObjectNav] Goal name:  ['Move gaming_console from chest_of_drawers to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 242)
  - delta = 3 2
Distance (m): 0.18027756377319945
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -76.2730300200567
Distance to goal 31.827660925679098
Distance in cm: 159.13830462839547 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 56.309932474020215
angle final goal = -76.2730300200567
0.15000000000000002 0.1 rel ang = 3.690067525979785
-----------------


======= labels_counter:  959
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']


======= labels_counter:  960
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']


======= labels_counter:  961
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']


======= labels_counter:  962
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']


======= labels_counter:  963
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']


======= labels_counter:  964
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']


======= labels_counter:  965
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']


======= labels_counter:  966
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']


======= labels_counter:  967
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']


======= labels_counter:  968
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']


======= labels_counter:  969
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -121.73562829498306
Distance to goal 33.015148038438355
Distance in cm: 165.07574019219177 > 50.0
continuous actions for exploring
agent angle = 60.00007629394531
angle stg goal = 14.036243467926479
angle final goal = -121.73562829498306
0.05 0.2 rel ang = 45.96383282601883
-----------------


======= labels_counter:  970
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -151.73562829498306
Distance to goal 33.015148038438355
Distance in cm: 165.07574019219177 > 50.0
continuous actions for exploring
agent angle = 30.000076293945312
angle stg goal = -78.69006752597979
angle final goal = -151.73562829498306
-0.25 0.05 rel ang = 108.6901438199251
-----------------


======= labels_counter:  971
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 178.26437170501694
Distance to goal 33.015148038438355
Distance in cm: 165.07574019219177 > 50.0
continuous actions for exploring
agent angle = 7.62939453125e-05
angle stg goal = -78.69006752597979
angle final goal = 178.26437170501694
-0.25 0.05 rel ang = 78.6901438199251
-----------------


======= labels_counter:  972
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 148.26437170501694
Distance to goal 33.015148038438355
Distance in cm: 165.07574019219177 > 50.0
continuous actions for exploring
agent angle = -29.999923706054688
angle stg goal = -78.69006752597979
angle final goal = 148.26437170501694
-0.25 0.05 rel ang = 48.6901438199251
-----------------


======= labels_counter:  973
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 118.26432592864975
Distance to goal 33.015148038438355
Distance in cm: 165.07574019219177 > 50.0
continuous actions for exploring
agent angle = -59.999969482421875
angle stg goal = -78.69006752597979
angle final goal = 118.26432592864975
-0.25 0.05 rel ang = 18.69009804355791
-----------------


======= labels_counter:  974
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 88.26435644622788
Distance to goal 33.015148038438355
Distance in cm: 165.07574019219177 > 50.0
continuous actions for exploring
agent angle = -89.99993896484375
angle stg goal = -78.69006752597979
angle final goal = 88.26435644622788
-0.25 0.05 rel ang = -11.30987143886398
-----------------


======= labels_counter:  975
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 88.264386963806
Distance to goal 33.015148038438355
Distance in cm: 165.07574019219177 > 50.0
continuous actions for exploring
agent angle = -89.99990844726562
angle stg goal = -78.69006752597979
angle final goal = 88.264386963806
-0.25 0.05 rel ang = -11.309840921285854
-----------------


======= labels_counter:  976
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 88.26441748138413
Distance to goal 33.015148038438355
Distance in cm: 165.07574019219177 > 50.0
continuous actions for exploring
agent angle = -89.9998779296875
angle stg goal = -78.69006752597979
angle final goal = 88.26441748138413
-0.25 0.05 rel ang = -11.30981040370773
-----------------


======= labels_counter:  977
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 95.19455097804729
Distance to goal 33.13608305156178
Distance in cm: 165.68041525780893 > 50.0
continuous actions for exploring
agent angle = -89.9998779296875
angle stg goal = -53.13010235415598
angle final goal = 95.19455097804729
-0.2 0.15000000000000002 rel ang = -36.86977557553155
-----------------


======= labels_counter:  978
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 9
[ObjectNav] Goal name:  ['Move ladle from toilet to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 125.19458149562541
Distance to goal 33.13608305156178
Distance in cm: 165.68041525780893 > 50.0
continuous actions for exploring
agent angle = -59.999847412109375
angle stg goal = -78.69006752597979
angle final goal = 125.19458149562541
-0.25 0.05 rel ang = 18.69022011387041
-----------------


======= labels_counter:  979
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']


======= labels_counter:  980
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']


======= labels_counter:  981
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']


======= labels_counter:  982
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']


======= labels_counter:  983
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']


======= labels_counter:  984
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']


======= labels_counter:  985
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']


======= labels_counter:  986
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']


======= labels_counter:  987
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']


======= labels_counter:  988
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']


======= labels_counter:  989
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 121.92757409930329
Distance to goal 34.0
Distance in cm: 170.0 > 50.0
continuous actions for exploring
agent angle = 60.00006103515625
angle stg goal = 168.6900675259798
angle final goal = 121.92757409930329
0.05 -0.25 rel ang = -108.69000649082355
-----------------


======= labels_counter:  990
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 151.92754358172516
Distance to goal 34.0
Distance in cm: 170.0 > 50.0
continuous actions for exploring
agent angle = 90.00003051757812
angle stg goal = 168.6900675259798
angle final goal = 151.92754358172516
0.05 -0.25 rel ang = -78.69003700840165
-----------------


======= labels_counter:  991
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -178.07248693585296
Distance to goal 34.0
Distance in cm: 170.0 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = 168.6900675259798
angle final goal = -178.07248693585296
0.05 -0.25 rel ang = -48.69006752597977
-----------------


======= labels_counter:  992
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -148.07248693585296
Distance to goal 34.0
Distance in cm: 170.0 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 168.6900675259798
angle final goal = -148.07248693585296
0.05 -0.25 rel ang = -18.69006752597977
-----------------


======= labels_counter:  993
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -118.07248693585296
Distance to goal 34.0
Distance in cm: 170.0 > 50.0
continuous actions for exploring
agent angle = 180.0
angle stg goal = 168.6900675259798
angle final goal = -118.07248693585296
0.05 -0.25 rel ang = 11.3099324740202
-----------------


======= labels_counter:  994
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -99.72757855140162
Distance to goal 35.510561809129406
Distance in cm: 177.55280904564702 > 50.0
continuous actions for exploring
agent angle = 180.0
angle stg goal = 143.13010235415598
angle final goal = -99.72757855140162
0.15000000000000002 -0.2 rel ang = 36.86989764584402
-----------------


======= labels_counter:  995
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -129.72757855140162
Distance to goal 35.510561809129406
Distance in cm: 177.55280904564702 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 143.13010235415598
angle final goal = -129.72757855140162
0.15000000000000002 -0.2 rel ang = 6.86989764584402
-----------------


======= labels_counter:  996
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -128.9726266148964
Distance to goal 38.47076812334269
Distance in cm: 192.35384061671343 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 143.13010235415598
angle final goal = -128.9726266148964
0.15000000000000002 -0.2 rel ang = 6.86989764584402
-----------------


======= labels_counter:  997
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -68.88449643371462
Distance to goal 39.824615503479755
Distance in cm: 199.12307751739877 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = 168.6900675259798
angle final goal = -68.88449643371462
0.05 -0.25 rel ang = -18.69006752597977
-----------------


======= labels_counter:  998
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 4
[ObjectNav] Goal name:  ['Move cake_pan from chair to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -41.98721249581661
Distance to goal 40.36087214122113
Distance in cm: 201.80436070610565 > 50.0
continuous actions for exploring
agent angle = 180.0
angle stg goal = 168.6900675259798
angle final goal = -41.98721249581661
0.05 -0.25 rel ang = 11.3099324740202
-----------------


======= labels_counter:  999
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']


======= labels_counter:  1000
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']


======= labels_counter:  1001
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']


======= labels_counter:  1002
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']


======= labels_counter:  1003
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']


======= labels_counter:  1004
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']


======= labels_counter:  1005
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']


======= labels_counter:  1006
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']


======= labels_counter:  1007
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']


======= labels_counter:  1008
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']


======= labels_counter:  1009
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 235)
  - delta = 0 -5
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -21.869943422211236
Distance to goal 35.35533905932738
Distance in cm: 176.7766952966369 > 50.0
continuous actions for exploring
agent angle = 59.99995422363281
angle stg goal = 180.0
angle final goal = -21.869943422211236
0.0 -0.25 rel ang = -120.00004577636719
-----------------


======= labels_counter:  1010
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 235)
  - delta = 0 -5
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 8.130041318999716
Distance to goal 35.35533905932738
Distance in cm: 176.7766952966369 > 50.0
continuous actions for exploring
agent angle = 89.99993896484375
angle stg goal = 180.0
angle final goal = 8.130041318999716
0.0 -0.25 rel ang = -90.00006103515625
-----------------


======= labels_counter:  1011
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 235)
  - delta = 0 -5
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 38.130041318999716
Distance to goal 35.35533905932738
Distance in cm: 176.7766952966369 > 50.0
continuous actions for exploring
agent angle = 119.99993896484375
angle stg goal = 180.0
angle final goal = 38.130041318999716
0.0 -0.25 rel ang = -60.00006103515625
-----------------


======= labels_counter:  1012
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 235)
  - delta = 0 -5
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 68.13004131899972
Distance to goal 35.35533905932738
Distance in cm: 176.7766952966369 > 50.0
continuous actions for exploring
agent angle = 149.99993896484375
angle stg goal = 180.0
angle final goal = 68.13004131899972
0.0 -0.25 rel ang = -30.00006103515625
-----------------


======= labels_counter:  1013
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 235)
  - delta = 0 -5
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 98.13004131899972
Distance to goal 35.35533905932738
Distance in cm: 176.7766952966369 > 50.0
continuous actions for exploring
agent angle = 179.99993896484375
angle stg goal = 180.0
angle final goal = 98.13004131899972
0.0 -0.25 rel ang = -6.103515625e-05
-----------------


======= labels_counter:  1014
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 70.01683244294377
Distance to goal 35.11409973215888
Distance in cm: 175.57049866079439 > 50.0
continuous actions for exploring
agent angle = 179.99993896484375
angle stg goal = 168.6900675259798
angle final goal = 70.01683244294377
0.05 -0.25 rel ang = 11.30987143886395
-----------------


======= labels_counter:  1015
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 78.02380652064039
Distance to goal 33.734255586866
Distance in cm: 168.67127793433 > 50.0
continuous actions for exploring
agent angle = 179.99993896484375
angle stg goal = 143.13010235415598
angle final goal = 78.02380652064039
0.15000000000000002 -0.2 rel ang = 36.86983661068777
-----------------


======= labels_counter:  1016
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 236)
  - delta = 3 -4
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 48.02380652064039
Distance to goal 33.734255586866
Distance in cm: 168.67127793433 > 50.0
continuous actions for exploring
agent angle = 149.99993896484375
angle stg goal = 143.13010235415598
angle final goal = 48.02380652064039
0.15000000000000002 -0.2 rel ang = 6.86983661068777
-----------------


======= labels_counter:  1017
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 56.30855297839247
Distance to goal 31.064449134018133
Distance in cm: 155.32224567009067 > 50.0
continuous actions for exploring
agent angle = 149.99993896484375
angle stg goal = 116.56505117707799
angle final goal = 56.30855297839247
0.2 -0.1 rel ang = 33.43488778776576
-----------------


======= labels_counter:  1018
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move bowl from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 45.9453348657666
Distance to goal 36.40054944640259
Distance in cm: 182.00274723201295 > 50.0
continuous actions for exploring
agent angle = 119.99993896484375
angle stg goal = 75.96375653207353
angle final goal = 45.9453348657666
0.2 0.05 rel ang = 44.03618243277022
-----------------


======= labels_counter:  1019
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']


======= labels_counter:  1020
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']


======= labels_counter:  1021
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']


======= labels_counter:  1022
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']


======= labels_counter:  1023
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']


======= labels_counter:  1024
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']


======= labels_counter:  1025
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']


======= labels_counter:  1026
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']


======= labels_counter:  1027
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']


======= labels_counter:  1028
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']


======= labels_counter:  1029
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -7.166376339660587
Distance to goal 20.615528128088304
Distance in cm: 103.07764064044152 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = -78.69006752597979
angle final goal = -7.166376339660587
-0.25 0.05 rel ang = 138.69003700840165
-----------------


======= labels_counter:  1030
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -37.16637633966059
Distance to goal 20.615528128088304
Distance in cm: 103.07764064044152 > 50.0
continuous actions for exploring
agent angle = 29.999969482421875
angle stg goal = -78.69006752597979
angle final goal = -37.16637633966059
-0.25 0.05 rel ang = 108.69003700840166
-----------------


======= labels_counter:  1031
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -67.16637633966059
Distance to goal 20.615528128088304
Distance in cm: 103.07764064044152 > 50.0
continuous actions for exploring
agent angle = -3.0517578125e-05
angle stg goal = -78.69006752597979
angle final goal = -67.16637633966059
-0.25 0.05 rel ang = 78.69003700840166
-----------------


======= labels_counter:  1032
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -97.16637633966059
Distance to goal 20.615528128088304
Distance in cm: 103.07764064044152 > 50.0
continuous actions for exploring
agent angle = -30.000030517578125
angle stg goal = -78.69006752597979
angle final goal = -97.16637633966059
-0.25 0.05 rel ang = 48.69003700840166
-----------------


======= labels_counter:  1033
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -127.16637633966059
Distance to goal 20.615528128088304
Distance in cm: 103.07764064044152 > 50.0
continuous actions for exploring
agent angle = -60.000030517578125
angle stg goal = -78.69006752597979
angle final goal = -127.16637633966059
-0.25 0.05 rel ang = 18.69003700840166
-----------------


======= labels_counter:  1034
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -157.1663763396606
Distance to goal 20.615528128088304
Distance in cm: 103.07764064044152 > 50.0
continuous actions for exploring
agent angle = -90.00003051757812
angle stg goal = -78.69006752597979
angle final goal = -157.1663763396606
-0.25 0.05 rel ang = -11.309962991598354
-----------------


======= labels_counter:  1035
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 241)
  - delta = -5 1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -85.23638882685196
Distance to goal 24.08318915758459
Distance in cm: 120.41594578792296 > 50.0
continuous actions for exploring
agent angle = -90.00003051757812
angle stg goal = -78.69006752597979
angle final goal = -85.23638882685196
-0.25 0.05 rel ang = -11.309962991598354
-----------------


======= labels_counter:  1036
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -92.38597454796695
Distance to goal 24.020824298928627
Distance in cm: 120.10412149464314 > 50.0
continuous actions for exploring
agent angle = -90.00003051757812
angle stg goal = -53.13010235415598
angle final goal = -92.38597454796695
-0.2 0.15000000000000002 rel ang = -36.86992816342217
-----------------


======= labels_counter:  1037
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -62.38597454796695
Distance to goal 24.020824298928627
Distance in cm: 120.10412149464314 > 50.0
continuous actions for exploring
agent angle = -60.000030517578125
angle stg goal = -53.13010235415598
angle final goal = -62.38597454796695
-0.2 0.15000000000000002 rel ang = -6.869928163422173
-----------------


======= labels_counter:  1038
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 6
[ObjectNav] Goal name:  ['Move stuffed_toy from table to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -75.25514922063587
Distance to goal 22.80350850198276
Distance in cm: 114.0175425099138 > 50.0
continuous actions for exploring
agent angle = -60.000030517578125
angle stg goal = -26.56505117707799
angle final goal = -75.25514922063587
-0.1 0.2 rel ang = -33.43497934050015
-----------------


======= labels_counter:  1039
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']


======= labels_counter:  1040
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']


======= labels_counter:  1041
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']


======= labels_counter:  1042
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']


======= labels_counter:  1043
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']


======= labels_counter:  1044
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']


======= labels_counter:  1045
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']


======= labels_counter:  1046
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']


======= labels_counter:  1047
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']


======= labels_counter:  1048
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']


======= labels_counter:  1049
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -135.52411099675425
Distance to goal 18.681541692269406
Distance in cm: 93.40770846134703 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 45.0
angle final goal = -135.52411099675425
0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  1050
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -133.3924977537511
Distance to goal 21.587033144922902
Distance in cm: 107.9351657246145 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 45.0
angle final goal = -133.3924977537511
0.15000000000000002 0.15000000000000002 rel ang = 15.0
-----------------


======= labels_counter:  1051
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -140.55604521958347
Distance to goal 25.632011235952593
Distance in cm: 128.16005617976296 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = 14.036243467926479
angle final goal = -140.55604521958347
0.05 0.2 rel ang = 45.96375653207352
-----------------


======= labels_counter:  1052
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -170.55604521958347
Distance to goal 25.632011235952593
Distance in cm: 128.16005617976296 > 50.0
continuous actions for exploring
agent angle = 30.0
angle stg goal = -26.56505117707799
angle final goal = -170.55604521958347
-0.1 0.2 rel ang = 56.56505117707799
-----------------


======= labels_counter:  1053
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 244)
  - delta = -1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 159.44395478041653
Distance to goal 25.632011235952593
Distance in cm: 128.16005617976296 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = -14.036243467926479
angle final goal = 159.44395478041653
-0.05 0.2 rel ang = 14.036243467926479
-----------------


======= labels_counter:  1054
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 244)
  - delta = -1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 162.75854060106005
Distance to goal 30.364452901377952
Distance in cm: 151.82226450688975 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = -14.036243467926479
angle final goal = 162.75854060106005
-0.05 0.2 rel ang = 14.036243467926479
-----------------


======= labels_counter:  1055
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 244)
  - delta = -1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 165.17352002964432
Distance to goal 35.17101079013795
Distance in cm: 175.85505395068975 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = -14.036243467926479
angle final goal = 165.17352002964432
-0.05 0.2 rel ang = 14.036243467926479
-----------------


======= labels_counter:  1056
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 244)
  - delta = -1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 167.0053832080835
Distance to goal 40.024992192379
Distance in cm: 200.124960961895 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = -14.036243467926479
angle final goal = 167.0053832080835
-0.05 0.2 rel ang = 14.036243467926479
-----------------


======= labels_counter:  1057
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 244)
  - delta = -1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 163.17859010995917
Distance to goal 44.9221548904324
Distance in cm: 224.61077445216202 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = -14.036243467926479
angle final goal = 163.17859010995917
-0.05 0.2 rel ang = 14.036243467926479
-----------------


======= labels_counter:  1058
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 7
[ObjectNav] Goal name:  ['Move spicemill from bench to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 244)
  - delta = -1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -44.06080905426444
Distance to goal 43.139309220245984
Distance in cm: 215.69654610122993 > 50.0
continuous actions for exploring
agent angle = 0.0
angle stg goal = -14.036243467926479
angle final goal = -44.06080905426444
-0.05 0.2 rel ang = 14.036243467926479
-----------------


======= labels_counter:  1059
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']


======= labels_counter:  1060
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']


======= labels_counter:  1061
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']


======= labels_counter:  1062
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']


======= labels_counter:  1063
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']


======= labels_counter:  1064
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']


======= labels_counter:  1065
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']


======= labels_counter:  1066
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']


======= labels_counter:  1067
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']


======= labels_counter:  1068
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']


======= labels_counter:  1069
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 74.93138666055943
Distance to goal 31.04834939252005
Distance in cm: 155.24174696260025 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = -158.19859051364818
angle final goal = 74.93138666055943
-0.1 -0.25 rel ang = -141.80144000392994
-----------------


======= labels_counter:  1070
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 104.93138666055943
Distance to goal 31.04834939252005
Distance in cm: 155.24174696260025 > 50.0
continuous actions for exploring
agent angle = 89.99996948242188
angle stg goal = -158.19859051364818
angle final goal = 104.93138666055943
-0.1 -0.25 rel ang = -111.80144000392994
-----------------


======= labels_counter:  1071
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 134.93138666055944
Distance to goal 31.04834939252005
Distance in cm: 155.24174696260025 > 50.0
continuous actions for exploring
agent angle = 119.99996948242188
angle stg goal = -158.19859051364818
angle final goal = 134.93138666055944
-0.1 -0.25 rel ang = -81.80144000392994
-----------------


======= labels_counter:  1072
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 164.93135614298131
Distance to goal 31.04834939252005
Distance in cm: 155.24174696260025 > 50.0
continuous actions for exploring
agent angle = 149.99993896484375
angle stg goal = -158.19859051364818
angle final goal = 164.93135614298131
-0.1 -0.25 rel ang = -51.801470521508065
-----------------


======= labels_counter:  1073
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -165.06864385701869
Distance to goal 31.04834939252005
Distance in cm: 155.24174696260025 > 50.0
continuous actions for exploring
agent angle = 179.99993896484375
angle stg goal = -158.19859051364818
angle final goal = -165.06864385701869
-0.1 -0.25 rel ang = -21.801470521508065
-----------------


======= labels_counter:  1074
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -135.06864385701869
Distance to goal 31.04834939252005
Distance in cm: 155.24174696260025 > 50.0
continuous actions for exploring
agent angle = -150.00006103515625
angle stg goal = -158.19859051364818
angle final goal = -135.06864385701869
-0.1 -0.25 rel ang = 8.198529478491935
-----------------


======= labels_counter:  1075
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -66.70989784291316
Distance to goal 34.23448553724738
Distance in cm: 171.17242768623692 > 50.0
continuous actions for exploring
agent angle = -150.00006103515625
angle stg goal = -158.19859051364818
angle final goal = -66.70989784291316
-0.1 -0.25 rel ang = 8.198529478491935
-----------------


======= labels_counter:  1076
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -74.0363045030827
Distance to goal 32.984845004941285
Distance in cm: 164.92422502470643 > 50.0
continuous actions for exploring
agent angle = -150.00006103515625
angle stg goal = -158.19859051364818
angle final goal = -74.0363045030827
-0.1 -0.25 rel ang = 8.198529478491935
-----------------


======= labels_counter:  1077
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 235)
  - delta = -1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -74.0363045030827
Distance to goal 32.984845004941285
Distance in cm: 164.92422502470643 > 50.0
continuous actions for exploring
agent angle = -150.00006103515625
angle stg goal = -168.6900675259798
angle final goal = -74.0363045030827
-0.05 -0.25 rel ang = 18.69000649082355
-----------------


======= labels_counter:  1078
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 18
[ObjectNav] Goal name:  ['Move hand_towel from counter to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (239, 235)
  - delta = -1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -104.0363045030827
Distance to goal 32.984845004941285
Distance in cm: 164.92422502470643 > 50.0
continuous actions for exploring
agent angle = 179.99993896484375
angle stg goal = -168.6900675259798
angle final goal = -104.0363045030827
-0.05 -0.25 rel ang = -11.30999350917648
-----------------


======= labels_counter:  1079
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']


======= labels_counter:  1080
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']


======= labels_counter:  1081
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']


======= labels_counter:  1082
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']


======= labels_counter:  1083
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']


======= labels_counter:  1084
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']


======= labels_counter:  1085
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']


======= labels_counter:  1086
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']


======= labels_counter:  1087
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']


======= labels_counter:  1088
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']


======= labels_counter:  1089
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -8.198590513648185
Distance to goal 37.69615364994153
Distance in cm: 188.48076824970764 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = -158.19859051364818
angle final goal = -8.198590513648185
-0.1 -0.25 rel ang = -141.80140948635182
-----------------


======= labels_counter:  1090
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 21.801409486351815
Distance to goal 37.69615364994153
Distance in cm: 188.48076824970764 > 50.0
continuous actions for exploring
agent angle = 90.0
angle stg goal = -158.19859051364818
angle final goal = 21.801409486351815
-0.1 -0.25 rel ang = -111.80140948635182
-----------------


======= labels_counter:  1091
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 51.801409486351815
Distance to goal 37.69615364994153
Distance in cm: 188.48076824970764 > 50.0
continuous actions for exploring
agent angle = 120.0
angle stg goal = -158.19859051364818
angle final goal = 51.801409486351815
-0.1 -0.25 rel ang = -81.80140948635182
-----------------


======= labels_counter:  1092
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 81.80140948635182
Distance to goal 37.69615364994153
Distance in cm: 188.48076824970764 > 50.0
continuous actions for exploring
agent angle = 150.0
angle stg goal = -158.19859051364818
angle final goal = 81.80140948635182
-0.1 -0.25 rel ang = -51.801409486351815
-----------------


======= labels_counter:  1093
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 111.80140948635182
Distance to goal 37.69615364994153
Distance in cm: 188.48076824970764 > 50.0
continuous actions for exploring
agent angle = 180.0
angle stg goal = -158.19859051364818
angle final goal = 111.80140948635182
-0.1 -0.25 rel ang = -21.801409486351815
-----------------


======= labels_counter:  1094
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 141.80140948635182
Distance to goal 37.69615364994153
Distance in cm: 188.48076824970764 > 50.0
continuous actions for exploring
agent angle = -150.0
angle stg goal = -158.19859051364818
angle final goal = 141.80140948635182
-0.1 -0.25 rel ang = 8.198590513648185
-----------------


======= labels_counter:  1095
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 146.56505117707798
Distance to goal 42.485291572496
Distance in cm: 212.42645786248002 > 50.0
continuous actions for exploring
agent angle = -150.0
angle stg goal = -158.19859051364818
angle final goal = 146.56505117707798
-0.1 -0.25 rel ang = 8.198590513648185
-----------------


======= labels_counter:  1096
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -15.0
Distance to goal 41.012193308819754
Distance in cm: 205.06096654409876 > 50.0
continuous actions for exploring
agent angle = -150.0
angle stg goal = -158.19859051364818
angle final goal = -15.0
-0.1 -0.25 rel ang = 8.198590513648185
-----------------


======= labels_counter:  1097
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -16.123302714075407
Distance to goal 36.069377593742864
Distance in cm: 180.34688796871433 > 50.0
continuous actions for exploring
agent angle = -150.0
angle stg goal = -158.19859051364818
angle final goal = -16.123302714075407
-0.1 -0.25 rel ang = 8.198590513648185
-----------------


======= labels_counter:  1098
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 18
[ObjectNav] Goal name:  ['Move dumbbell from chair to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -17.602562202499826
Distance to goal 31.144823004794873
Distance in cm: 155.72411502397438 > 50.0
continuous actions for exploring
agent angle = -150.0
angle stg goal = -158.19859051364818
angle final goal = -17.602562202499826
-0.1 -0.25 rel ang = 8.198590513648185
-----------------


======= labels_counter:  1099
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']


======= labels_counter:  1100
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']


======= labels_counter:  1101
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']


======= labels_counter:  1102
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']


======= labels_counter:  1103
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']


======= labels_counter:  1104
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']


======= labels_counter:  1105
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']


======= labels_counter:  1106
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']


======= labels_counter:  1107
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']


======= labels_counter:  1108
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']


======= labels_counter:  1109
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -31.591140271194604
Distance to goal 36.013886210738214
Distance in cm: 180.06943105369106 > 50.0
continuous actions for exploring
agent angle = 60.0
angle stg goal = -111.80140948635182
angle final goal = -31.591140271194604
-0.25 -0.1 rel ang = 171.80140948635182
-----------------


======= labels_counter:  1110
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -61.591140271194604
Distance to goal 36.013886210738214
Distance in cm: 180.06943105369106 > 50.0
continuous actions for exploring
agent angle = 30.0
angle stg goal = -111.80140948635182
angle final goal = -61.591140271194604
-0.25 -0.1 rel ang = 141.80140948635182
-----------------


======= labels_counter:  1111
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -91.59117078877273
Distance to goal 36.013886210738214
Distance in cm: 180.06943105369106 > 50.0
continuous actions for exploring
agent angle = -3.0517578125e-05
angle stg goal = -111.80140948635182
angle final goal = -91.59117078877273
-0.25 -0.1 rel ang = 111.80137896877369
-----------------


======= labels_counter:  1112
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -121.59115552998367
Distance to goal 36.013886210738214
Distance in cm: 180.06943105369106 > 50.0
continuous actions for exploring
agent angle = -30.000015258789062
angle stg goal = -111.80140948635182
angle final goal = -121.59115552998367
-0.25 -0.1 rel ang = 81.80139422756275
-----------------


======= labels_counter:  1113
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -151.59115552998367
Distance to goal 36.013886210738214
Distance in cm: 180.06943105369106 > 50.0
continuous actions for exploring
agent angle = -60.00001525878906
angle stg goal = -111.80140948635182
angle final goal = -151.59115552998367
-0.25 -0.1 rel ang = 51.80139422756275
-----------------


======= labels_counter:  1114
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 178.4088597288054
Distance to goal 36.013886210738214
Distance in cm: 180.06943105369106 > 50.0
continuous actions for exploring
agent angle = -90.0
angle stg goal = -111.80140948635182
angle final goal = 178.4088597288054
-0.25 -0.1 rel ang = 21.801409486351815
-----------------


======= labels_counter:  1115
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 148.4088597288054
Distance to goal 36.013886210738214
Distance in cm: 180.06943105369106 > 50.0
continuous actions for exploring
agent angle = -120.0
angle stg goal = -111.80140948635182
angle final goal = 148.4088597288054
-0.25 -0.1 rel ang = -8.198590513648185
-----------------


======= labels_counter:  1116
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 238)
  - delta = -5 -2
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 148.60281897270363
Distance to goal 41.012193308819754
Distance in cm: 205.06096654409876 > 50.0
continuous actions for exploring
agent angle = -120.0
angle stg goal = -111.80140948635182
angle final goal = 148.60281897270363
-0.25 -0.1 rel ang = -8.198590513648185
-----------------


======= labels_counter:  1117
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 235)
  - delta = -2 -5
Distance (m): 0.2692582403567252
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 38.96248897457818
Distance to goal 41.78516483155236
Distance in cm: 208.92582415776178 > 50.0
continuous actions for exploring
agent angle = -120.0
angle stg goal = -158.19859051364818
angle final goal = 38.96248897457818
-0.1 -0.25 rel ang = 38.198590513648185
-----------------


======= labels_counter:  1118
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 4
[ObjectNav] Goal name:  ['Move pitcher from counter to bench']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 8.962488974578179
Distance to goal 41.78516483155236
Distance in cm: 208.92582415776178 > 50.0
continuous actions for exploring
agent angle = -150.0
angle stg goal = 14.036243467926479
angle final goal = 8.962488974578179
0.05 0.2 rel ang = -164.03624346792648
-----------------


======= labels_counter:  1119
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']


======= labels_counter:  1120
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']


======= labels_counter:  1121
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']


======= labels_counter:  1122
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']


======= labels_counter:  1123
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']


======= labels_counter:  1124
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']


======= labels_counter:  1125
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']


======= labels_counter:  1126
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']


======= labels_counter:  1127
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']


======= labels_counter:  1128
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']


======= labels_counter:  1129
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -50.556075737161564
Distance to goal 34.17601498127012
Distance in cm: 170.88007490635061 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 14.036243467926479
angle final goal = -50.556075737161564
0.05 0.2 rel ang = 45.96372601449539
-----------------


======= labels_counter:  1130
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -80.55607573716156
Distance to goal 34.17601498127012
Distance in cm: 170.88007490635061 > 50.0
continuous actions for exploring
agent angle = 29.999969482421875
angle stg goal = -53.13010235415598
angle final goal = -80.55607573716156
-0.2 0.15000000000000002 rel ang = 83.13007183657786
-----------------


======= labels_counter:  1131
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -110.55607573716159
Distance to goal 34.17601498127012
Distance in cm: 170.88007490635061 > 50.0
continuous actions for exploring
agent angle = -3.0517578125e-05
angle stg goal = -53.13010235415598
angle final goal = -110.55607573716159
-0.2 0.15000000000000002 rel ang = 53.130071836577855
-----------------


======= labels_counter:  1132
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -140.5560757371616
Distance to goal 34.17601498127012
Distance in cm: 170.88007490635061 > 50.0
continuous actions for exploring
agent angle = -30.000030517578125
angle stg goal = -53.13010235415598
angle final goal = -140.5560757371616
-0.2 0.15000000000000002 rel ang = 23.130071836577855
-----------------


======= labels_counter:  1133
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -170.5560757371616
Distance to goal 34.17601498127012
Distance in cm: 170.88007490635061 > 50.0
continuous actions for exploring
agent angle = -60.000030517578125
angle stg goal = -53.13010235415598
angle final goal = -170.5560757371616
-0.2 0.15000000000000002 rel ang = -6.869928163422173
-----------------


======= labels_counter:  1134
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 53.8059130008796
Distance to goal 37.16180835212409
Distance in cm: 185.80904176062046 > 50.0
continuous actions for exploring
agent angle = -60.000030517578125
angle stg goal = -26.56505117707799
angle final goal = 53.8059130008796
-0.1 0.2 rel ang = -33.43497934050015
-----------------


======= labels_counter:  1135
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 83.80589774209054
Distance to goal 37.16180835212409
Distance in cm: 185.80904176062046 > 50.0
continuous actions for exploring
agent angle = -30.000045776367188
angle stg goal = -26.56505117707799
angle final goal = 83.80589774209054
-0.1 0.2 rel ang = -3.4349945992892117
-----------------


======= labels_counter:  1136
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 90.69967677444723
Distance to goal 37.21558813185679
Distance in cm: 186.07794065928397 > 50.0
continuous actions for exploring
agent angle = -30.000045776367188
angle stg goal = -26.56505117707799
angle final goal = 90.69967677444723
-0.1 0.2 rel ang = -3.4349945992892117
-----------------


======= labels_counter:  1137
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 99.61064246365942
Distance to goal 37.64306044943742
Distance in cm: 188.2153022471871 > 50.0
continuous actions for exploring
agent angle = -30.000045776367188
angle stg goal = -53.13010235415598
angle final goal = 99.61064246365942
-0.2 0.15000000000000002 rel ang = 23.130056577788793
-----------------


======= labels_counter:  1138
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 7
[ObjectNav] Goal name:  ['Move watch from chair to chest_of_drawers']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 69.61065772244848
Distance to goal 37.64306044943742
Distance in cm: 188.2153022471871 > 50.0
continuous actions for exploring
agent angle = -60.000030517578125
angle stg goal = -53.13010235415598
angle final goal = 69.61065772244848
-0.2 0.15000000000000002 rel ang = -6.869928163422173
-----------------


======= labels_counter:  1139
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']


======= labels_counter:  1140
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']


======= labels_counter:  1141
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']


======= labels_counter:  1142
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']


======= labels_counter:  1143
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']


======= labels_counter:  1144
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']


======= labels_counter:  1145
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']


======= labels_counter:  1146
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']


======= labels_counter:  1147
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']


======= labels_counter:  1148
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']


======= labels_counter:  1149
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 110.52747911649993
Distance to goal 22.02271554554524
Distance in cm: 110.1135777277262 > 50.0
continuous actions for exploring
agent angle = 59.99993896484375
angle stg goal = 45.0
angle final goal = 110.52747911649993
0.15000000000000002 0.15000000000000002 rel ang = 14.99993896484375
-----------------


======= labels_counter:  1150
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 101.4236045898464
Distance to goal 22.67156809750927
Distance in cm: 113.35784048754634 > 50.0
continuous actions for exploring
agent angle = 59.99993896484375
angle stg goal = 45.0
angle final goal = 101.4236045898464
0.15000000000000002 0.15000000000000002 rel ang = 14.99993896484375
-----------------


======= labels_counter:  1151
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 93.69000649082354
Distance to goal 21.633307652783937
Distance in cm: 108.16653826391969 > 50.0
continuous actions for exploring
agent angle = 59.99993896484375
angle stg goal = 45.0
angle final goal = 93.69000649082354
0.15000000000000002 0.15000000000000002 rel ang = 14.99993896484375
-----------------


======= labels_counter:  1152
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 104.99993896484375
Distance to goal 22.627416997969522
Distance in cm: 113.13708498984761 > 50.0
continuous actions for exploring
agent angle = 59.99993896484375
angle stg goal = 14.036243467926479
angle final goal = 104.99993896484375
0.05 0.2 rel ang = 45.96369549691727
-----------------


======= labels_counter:  1153
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 74.99993896484375
Distance to goal 22.627416997969522
Distance in cm: 113.13708498984761 > 50.0
continuous actions for exploring
agent angle = 29.99993896484375
angle stg goal = 168.6900675259798
angle final goal = 74.99993896484375
0.05 -0.25 rel ang = -138.69012856113605
-----------------


======= labels_counter:  1154
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 104.99993896484375
Distance to goal 22.627416997969522
Distance in cm: 113.13708498984761 > 50.0
continuous actions for exploring
agent angle = 59.99993896484375
angle stg goal = 168.6900675259798
angle final goal = 104.99993896484375
0.05 -0.25 rel ang = -108.69012856113605
-----------------


======= labels_counter:  1155
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 134.99993896484375
Distance to goal 22.627416997969522
Distance in cm: 113.13708498984761 > 50.0
continuous actions for exploring
agent angle = 89.99993896484375
angle stg goal = 168.6900675259798
angle final goal = 134.99993896484375
0.05 -0.25 rel ang = -78.69012856113602
-----------------


======= labels_counter:  1156
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 164.99993896484375
Distance to goal 22.627416997969522
Distance in cm: 113.13708498984761 > 50.0
continuous actions for exploring
agent angle = 119.99993896484375
angle stg goal = 168.6900675259798
angle final goal = 164.99993896484375
0.05 -0.25 rel ang = -48.69012856113602
-----------------


======= labels_counter:  1157
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -165.00006103515625
Distance to goal 22.627416997969522
Distance in cm: 113.13708498984761 > 50.0
continuous actions for exploring
agent angle = 149.99993896484375
angle stg goal = 168.6900675259798
angle final goal = -165.00006103515625
0.05 -0.25 rel ang = -18.69012856113602
-----------------


======= labels_counter:  1158
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 18
end_recep goal = 19
[ObjectNav] Goal name:  ['Move soap_dish from table to toilet']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 235)
  - delta = 1 -5
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -135.00006103515625
Distance to goal 22.627416997969522
Distance in cm: 113.13708498984761 > 50.0
continuous actions for exploring
agent angle = 179.99993896484375
angle stg goal = 168.6900675259798
angle final goal = -135.00006103515625
0.05 -0.25 rel ang = 11.30987143886395
-----------------


======= labels_counter:  1159
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']


======= labels_counter:  1160
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']


======= labels_counter:  1161
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']


======= labels_counter:  1162
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']


======= labels_counter:  1163
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']


======= labels_counter:  1164
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']


======= labels_counter:  1165
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']


======= labels_counter:  1166
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']


======= labels_counter:  1167
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']


======= labels_counter:  1168
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']


======= labels_counter:  1169
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -49.179038543388856
Distance to goal 24.351591323771842
Distance in cm: 121.75795661885921 > 50.0
continuous actions for exploring
agent angle = 59.999969482421875
angle stg goal = 45.0
angle final goal = -49.179038543388856
0.15000000000000002 0.15000000000000002 rel ang = 14.999969482421875
-----------------


======= labels_counter:  1170
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -49.17899276702167
Distance to goal 24.351591323771842
Distance in cm: 121.75795661885921 > 50.0
continuous actions for exploring
agent angle = 60.00001525878906
angle stg goal = 14.036243467926479
angle final goal = -49.17899276702167
0.05 0.2 rel ang = 45.96377179086258
-----------------


======= labels_counter:  1171
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -79.17899276702167
Distance to goal 24.351591323771842
Distance in cm: 121.75795661885921 > 50.0
continuous actions for exploring
agent angle = 30.000015258789062
angle stg goal = -53.13010235415598
angle final goal = -79.17899276702167
-0.2 0.15000000000000002 rel ang = 83.13011761294504
-----------------


======= labels_counter:  1172
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -109.17899276702167
Distance to goal 24.351591323771842
Distance in cm: 121.75795661885921 > 50.0
continuous actions for exploring
agent angle = 1.52587890625e-05
angle stg goal = -53.13010235415598
angle final goal = -109.17899276702167
-0.2 0.15000000000000002 rel ang = 53.13011761294504
-----------------


======= labels_counter:  1173
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -139.17899276702167
Distance to goal 24.351591323771842
Distance in cm: 121.75795661885921 > 50.0
continuous actions for exploring
agent angle = -29.999984741210938
angle stg goal = -53.13010235415598
angle final goal = -139.17899276702167
-0.2 0.15000000000000002 rel ang = 23.130117612945043
-----------------


======= labels_counter:  1174
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (236, 243)
  - delta = -4 3
Distance (m): 0.25
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -169.17899276702167
Distance to goal 24.351591323771842
Distance in cm: 121.75795661885921 > 50.0
continuous actions for exploring
agent angle = -59.99998474121094
angle stg goal = -53.13010235415598
angle final goal = -169.17899276702167
-0.2 0.15000000000000002 rel ang = -6.869882387054986
-----------------


======= labels_counter:  1175
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -169.17899276702167
Distance to goal 24.351591323771842
Distance in cm: 121.75795661885921 > 50.0
continuous actions for exploring
agent angle = -59.99998474121094
angle stg goal = -26.56505117707799
angle final goal = -169.17899276702167
-0.1 0.2 rel ang = -33.43493356413296
-----------------


======= labels_counter:  1176
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -139.17899276702167
Distance to goal 24.351591323771842
Distance in cm: 121.75795661885921 > 50.0
continuous actions for exploring
agent angle = -29.999984741210938
angle stg goal = -26.56505117707799
angle final goal = -139.17899276702167
-0.1 0.2 rel ang = -3.4349335641329617
-----------------


======= labels_counter:  1177
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 239)
  - delta = -5 -1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -139.17899276702167
Distance to goal 24.351591323771842
Distance in cm: 121.75795661885921 > 50.0
continuous actions for exploring
agent angle = -29.999984741210938
angle stg goal = -101.30993247402021
angle final goal = -139.17899276702167
-0.25 -0.05 rel ang = 71.30994773280928
-----------------


======= labels_counter:  1178
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 9
end_recep goal = 6
[ObjectNav] Goal name:  ['Move spicemill from counter to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (235, 239)
  - delta = -5 -1
Distance (m): 0.25495097567963926
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -169.17899276702167
Distance to goal 24.351591323771842
Distance in cm: 121.75795661885921 > 50.0
continuous actions for exploring
agent angle = -59.99998474121094
angle stg goal = -101.30993247402021
angle final goal = -169.17899276702167
-0.25 -0.05 rel ang = 41.30994773280928
-----------------


======= labels_counter:  1179
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']


======= labels_counter:  1180
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']


======= labels_counter:  1181
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']


======= labels_counter:  1182
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']


======= labels_counter:  1183
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']


======= labels_counter:  1184
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']


======= labels_counter:  1185
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']


======= labels_counter:  1186
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']


======= labels_counter:  1187
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']


======= labels_counter:  1188
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']


======= labels_counter:  1189
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -63.38857461126776
Distance to goal 52.69724850502159
Distance in cm: 263.48624252510797 > 50.0
continuous actions for exploring
agent angle = 59.99993896484375
angle stg goal = 45.0
angle final goal = -63.38857461126776
0.15000000000000002 0.15000000000000002 rel ang = 14.99993896484375
-----------------


======= labels_counter:  1190
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -67.7757453411109
Distance to goal 50.60632371551998
Distance in cm: 253.0316185775999 > 50.0
continuous actions for exploring
agent angle = 59.99993896484375
angle stg goal = 45.0
angle final goal = -67.7757453411109
0.15000000000000002 0.15000000000000002 rel ang = 14.99993896484375
-----------------


======= labels_counter:  1191
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -73.36348399353949
Distance to goal 49.51767361255979
Distance in cm: 247.58836806279896 > 50.0
continuous actions for exploring
agent angle = 59.99993896484375
angle stg goal = 45.0
angle final goal = -73.36348399353949
0.15000000000000002 0.15000000000000002 rel ang = 14.99993896484375
-----------------


======= labels_counter:  1192
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -76.68474535305256
Distance to goal 48.104053883222775
Distance in cm: 240.52026941611388 > 50.0
continuous actions for exploring
agent angle = 59.99993896484375
angle stg goal = 14.036243467926479
angle final goal = -76.68474535305256
0.05 0.2 rel ang = 45.96369549691727
-----------------


======= labels_counter:  1193
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -106.68476061184163
Distance to goal 48.104053883222775
Distance in cm: 240.52026941611388 > 50.0
continuous actions for exploring
agent angle = 29.999923706054688
angle stg goal = 45.0
angle final goal = -106.68476061184163
0.15000000000000002 0.15000000000000002 rel ang = -15.000076293945312
-----------------


======= labels_counter:  1194
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -76.68476061184163
Distance to goal 48.104053883222775
Distance in cm: 240.52026941611388 > 50.0
continuous actions for exploring
agent angle = 59.99992370605469
angle stg goal = 45.0
angle final goal = -76.68476061184163
0.15000000000000002 0.15000000000000002 rel ang = 14.999923706054688
-----------------


======= labels_counter:  1195
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -50.09530748585013
Distance to goal 43.657759905886145
Distance in cm: 218.28879952943072 > 50.0
continuous actions for exploring
agent angle = 59.99992370605469
angle stg goal = 14.036243467926479
angle final goal = -50.09530748585013
0.05 0.2 rel ang = 45.963680238128205
-----------------


======= labels_counter:  1196
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -80.09530748585013
Distance to goal 43.657759905886145
Distance in cm: 218.28879952943072 > 50.0
continuous actions for exploring
agent angle = 29.999923706054688
angle stg goal = 14.036243467926479
angle final goal = -80.09530748585013
0.05 0.2 rel ang = 15.963680238128209
-----------------


======= labels_counter:  1197
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -110.09530748585013
Distance to goal 43.657759905886145
Distance in cm: 218.28879952943072 > 50.0
continuous actions for exploring
agent angle = -7.62939453125e-05
angle stg goal = 75.96375653207353
angle final goal = -110.09530748585013
0.2 0.05 rel ang = -75.96383282601886
-----------------


======= labels_counter:  1198
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 6
[ObjectNav] Goal name:  ['Move plant_container from toilet to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -80.09530748585013
Distance to goal 43.657759905886145
Distance in cm: 218.28879952943072 > 50.0
continuous actions for exploring
agent angle = 29.999923706054688
angle stg goal = 75.96375653207353
angle final goal = -80.09530748585013
0.2 0.05 rel ang = -45.96383282601886
-----------------


======= labels_counter:  1199
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']


======= labels_counter:  1200
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']


======= labels_counter:  1201
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']


======= labels_counter:  1202
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']


======= labels_counter:  1203
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']


======= labels_counter:  1204
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']


======= labels_counter:  1205
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']


======= labels_counter:  1206
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']


======= labels_counter:  1207
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']


======= labels_counter:  1208
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']


======= labels_counter:  1209
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 114.46238324318188
Distance to goal 43.01162633521314
Distance in cm: 215.05813167606567 > 50.0
continuous actions for exploring
agent angle = 60.00006103515625
angle stg goal = -26.56505117707799
angle final goal = 114.46238324318188
-0.1 0.2 rel ang = 86.56511221223424
-----------------


======= labels_counter:  1210
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 84.46238324318188
Distance to goal 43.01162633521314
Distance in cm: 215.05813167606567 > 50.0
continuous actions for exploring
agent angle = 30.00006103515625
angle stg goal = -26.56505117707799
angle final goal = 84.46238324318188
-0.1 0.2 rel ang = 56.56511221223424
-----------------


======= labels_counter:  1211
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 54.46238324318187
Distance to goal 43.01162633521314
Distance in cm: 215.05813167606567 > 50.0
continuous actions for exploring
agent angle = 6.103515625e-05
angle stg goal = -26.56505117707799
angle final goal = 54.46238324318187
-0.1 0.2 rel ang = 26.56511221223424
-----------------


======= labels_counter:  1212
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 24.462429019549056
Distance to goal 43.01162633521314
Distance in cm: 215.05813167606567 > 50.0
continuous actions for exploring
agent angle = -29.999893188476562
angle stg goal = -26.56505117707799
angle final goal = 24.462429019549056
-0.1 0.2 rel ang = -3.4348420113985867
-----------------


======= labels_counter:  1213
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 26.72521882668852
Distance to goal 38.27531841800928
Distance in cm: 191.3765920900464 > 50.0
continuous actions for exploring
agent angle = -29.999893188476562
angle stg goal = -26.56505117707799
angle final goal = 26.72521882668852
-0.1 0.2 rel ang = -3.4348420113985867
-----------------


======= labels_counter:  1214
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 30.642353268732165
Distance to goal 36.71511950137164
Distance in cm: 183.5755975068582 > 50.0
continuous actions for exploring
agent angle = -29.999893188476562
angle stg goal = -26.56505117707799
angle final goal = 30.642353268732165
-0.1 0.2 rel ang = -3.4348420113985867
-----------------


======= labels_counter:  1215
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (238, 244)
  - delta = -2 4
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 34.98321333342342
Distance to goal 33.1058907144937
Distance in cm: 165.52945357246847 > 50.0
continuous actions for exploring
agent angle = -29.999893188476562
angle stg goal = -26.56505117707799
angle final goal = 34.98321333342342
-0.1 0.2 rel ang = -3.4348420113985867
-----------------


======= labels_counter:  1216
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 42.75864741258346
Distance to goal 30.364452901377952
Distance in cm: 151.82226450688975 > 50.0
continuous actions for exploring
agent angle = -29.999893188476562
angle stg goal = 14.036243467926479
angle final goal = 42.75864741258346
0.05 0.2 rel ang = -44.03613665640307
-----------------


======= labels_counter:  1217
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 72.75864741258346
Distance to goal 30.364452901377952
Distance in cm: 151.82226450688975 > 50.0
continuous actions for exploring
agent angle = 0.0001068115234375
angle stg goal = 45.0
angle final goal = 72.75864741258346
0.15000000000000002 0.15000000000000002 rel ang = -44.99989318847656
-----------------


======= labels_counter:  1218
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 7
end_recep goal = 18
[ObjectNav] Goal name:  ['Move multiport_hub from chest_of_drawers to table']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (241, 244)
  - delta = 1 4
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 102.75864741258346
Distance to goal 30.364452901377952
Distance in cm: 151.82226450688975 > 50.0
continuous actions for exploring
agent angle = 30.000106811523438
angle stg goal = 14.036243467926479
angle final goal = 102.75864741258346
0.05 0.2 rel ang = 15.963863343596959
-----------------


======= labels_counter:  1219
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']


======= labels_counter:  1220
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']


======= labels_counter:  1221
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']


======= labels_counter:  1222
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']


======= labels_counter:  1223
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']


======= labels_counter:  1224
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']


======= labels_counter:  1225
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']


======= labels_counter:  1226
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']


======= labels_counter:  1227
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']


======= labels_counter:  1228
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']


======= labels_counter:  1229
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -127.76504394811283
Distance to goal 22.20360331117452
Distance in cm: 111.01801655587259 > 50.0
continuous actions for exploring
agent angle = 60.0001220703125
angle stg goal = 75.96375653207353
angle final goal = -127.76504394811283
0.2 0.05 rel ang = -15.963634461761046
-----------------


======= labels_counter:  1230
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -97.76504394811286
Distance to goal 22.20360331117452
Distance in cm: 111.01801655587259 > 50.0
continuous actions for exploring
agent angle = 90.0001220703125
angle stg goal = 75.96375653207353
angle final goal = -97.76504394811286
0.2 0.05 rel ang = 14.036365538238968
-----------------


======= labels_counter:  1231
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -109.98298445158747
Distance to goal 23.40939982143925
Distance in cm: 117.04699910719626 > 50.0
continuous actions for exploring
agent angle = 90.0001220703125
angle stg goal = 45.0
angle final goal = -109.98298445158747
0.15000000000000002 0.15000000000000002 rel ang = 45.0001220703125
-----------------


======= labels_counter:  1232
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -139.98298445158747
Distance to goal 23.40939982143925
Distance in cm: 117.04699910719626 > 50.0
continuous actions for exploring
agent angle = 60.0001220703125
angle stg goal = 75.96375653207353
angle final goal = -139.98298445158747
0.2 0.05 rel ang = -15.963634461761046
-----------------


======= labels_counter:  1233
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -109.98298445158747
Distance to goal 23.40939982143925
Distance in cm: 117.04699910719626 > 50.0
continuous actions for exploring
agent angle = 90.0001220703125
angle stg goal = 75.96375653207353
angle final goal = -109.98298445158747
0.2 0.05 rel ang = 14.036365538238968
-----------------


======= labels_counter:  1234
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -115.55984310151129
Distance to goal 25.495097567963924
Distance in cm: 127.47548783981962 > 50.0
continuous actions for exploring
agent angle = 90.0001220703125
angle stg goal = 45.0
angle final goal = -115.55984310151129
0.15000000000000002 0.15000000000000002 rel ang = 45.0001220703125
-----------------


======= labels_counter:  1235
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -145.5598431015113
Distance to goal 25.495097567963924
Distance in cm: 127.47548783981962 > 50.0
continuous actions for exploring
agent angle = 60.0001220703125
angle stg goal = 45.0
angle final goal = -145.5598431015113
0.15000000000000002 0.15000000000000002 rel ang = 15.0001220703125
-----------------


======= labels_counter:  1236
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (243, 243)
  - delta = 3 3
Distance (m): 0.21213203435596423
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -175.5598431015113
Distance to goal 25.495097567963924
Distance in cm: 127.47548783981962 > 50.0
continuous actions for exploring
agent angle = 30.0001220703125
angle stg goal = 45.0
angle final goal = -175.5598431015113
0.15000000000000002 0.15000000000000002 rel ang = -14.9998779296875
-----------------


======= labels_counter:  1237
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 32.38606610070131
Distance to goal 24.020824298928627
Distance in cm: 120.10412149464314 > 50.0
continuous actions for exploring
agent angle = 30.0001220703125
angle stg goal = 75.96375653207353
angle final goal = 32.38606610070131
0.2 0.05 rel ang = -45.963634461761046
-----------------


======= labels_counter:  1238
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 6
end_recep goal = 9
[ObjectNav] Goal name:  ['Move mouse_pad from chair to counter']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 241)
  - delta = 4 1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 62.38606610070131
Distance to goal 24.020824298928627
Distance in cm: 120.10412149464314 > 50.0
continuous actions for exploring
agent angle = 60.0001220703125
angle stg goal = 75.96375653207353
angle final goal = 62.38606610070131
0.2 0.05 rel ang = -15.963634461761046
-----------------


======= labels_counter:  1239
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']


======= labels_counter:  1240
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']


======= labels_counter:  1241
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']


======= labels_counter:  1242
Executing skill EXPLORE at timestep 3
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']


======= labels_counter:  1243
Executing skill EXPLORE at timestep 4
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']


======= labels_counter:  1244
Executing skill EXPLORE at timestep 5
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']


======= labels_counter:  1245
Executing skill EXPLORE at timestep 6
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']


======= labels_counter:  1246
Executing skill EXPLORE at timestep 7
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']


======= labels_counter:  1247
Executing skill EXPLORE at timestep 8
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']


======= labels_counter:  1248
Executing skill EXPLORE at timestep 9
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']


======= labels_counter:  1249
Executing skill EXPLORE at timestep 10
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (240, 244)
  - delta = 0 4
Distance (m): 0.2
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -155.09567945792455
Distance to goal 45.221676218380054
Distance in cm: 226.10838109190027 > 50.0
continuous actions for exploring
agent angle = 60.00013732910156
angle stg goal = 0.0
angle final goal = -155.09567945792455
0.0 0.2 rel ang = 60.00013732910156
-----------------


======= labels_counter:  1250
Executing skill EXPLORE at timestep 11
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 174.90432054207545
Distance to goal 45.221676218380054
Distance in cm: 226.10838109190027 > 50.0
continuous actions for exploring
agent angle = 30.000137329101562
angle stg goal = 116.56505117707799
angle final goal = 174.90432054207545
0.2 -0.1 rel ang = -86.56491384797641
-----------------


======= labels_counter:  1251
Executing skill EXPLORE at timestep 12
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -155.09567945792455
Distance to goal 45.221676218380054
Distance in cm: 226.10838109190027 > 50.0
continuous actions for exploring
agent angle = 60.00013732910156
angle stg goal = 116.56505117707799
angle final goal = -155.09567945792455
0.2 -0.1 rel ang = -56.56491384797641
-----------------


======= labels_counter:  1252
Executing skill EXPLORE at timestep 13
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -125.09569471671361
Distance to goal 45.221676218380054
Distance in cm: 226.10838109190027 > 50.0
continuous actions for exploring
agent angle = 90.0001220703125
angle stg goal = 116.56505117707799
angle final goal = -125.09569471671361
0.2 -0.1 rel ang = -26.564929106765476
-----------------


======= labels_counter:  1253
Executing skill EXPLORE at timestep 14
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 238)
  - delta = 4 -2
Distance (m): 0.223606797749979
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -95.09569471671364
Distance to goal 45.221676218380054
Distance in cm: 226.10838109190027 > 50.0
continuous actions for exploring
agent angle = 120.0001220703125
angle stg goal = 116.56505117707799
angle final goal = -95.09569471671364
0.2 -0.1 rel ang = 3.43507089323451
-----------------


======= labels_counter:  1254
Executing skill EXPLORE at timestep 15
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 239)
  - delta = 4 -1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -101.42354355469013
Distance to goal 45.34313619501854
Distance in cm: 226.71568097509268 > 50.0
continuous actions for exploring
agent angle = 120.0001220703125
angle stg goal = 104.03624346792648
angle final goal = -101.42354355469013
0.2 -0.05 rel ang = 15.963878602386018
-----------------


======= labels_counter:  1255
Executing skill EXPLORE at timestep 16
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 239)
  - delta = 4 -1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -131.42354355469013
Distance to goal 45.34313619501854
Distance in cm: 226.71568097509268 > 50.0
continuous actions for exploring
agent angle = 90.0001220703125
angle stg goal = 104.03624346792648
angle final goal = -131.42354355469013
0.2 -0.05 rel ang = -14.03612139761401
-----------------


======= labels_counter:  1256
Executing skill EXPLORE at timestep 17
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 239)
  - delta = 4 -1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: -122.38055563625673
Distance to goal 48.54894437575342
Distance in cm: 242.7447218787671 > 50.0
continuous actions for exploring
agent angle = 90.0001220703125
angle stg goal = 104.03624346792648
angle final goal = -122.38055563625673
0.2 -0.05 rel ang = -14.03612139761401
-----------------


======= labels_counter:  1257
Executing skill EXPLORE at timestep 18
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 239)
  - delta = 4 -1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 57.72447775573487
Distance to goal 44.94441010848846
Distance in cm: 224.7220505424423 > 50.0
continuous actions for exploring
agent angle = 90.0001220703125
angle stg goal = 104.03624346792648
angle final goal = 57.72447775573487
0.2 -0.05 rel ang = -14.03612139761401
-----------------


======= labels_counter:  1258
Executing skill EXPLORE at timestep 19
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 4
end_recep goal = 6
[ObjectNav] Goal name:  ['Move sushi_mat from bench to chair']

--- Planning ---
Found goal: 0
Goal points provided: True
Current pose: [240 240]
Short term goal: (244, 239)
  - delta = 4 -1
Distance (m): 0.20615528128088303
Replan: False
-----------------
Found reachable goal: 0
Stop: False
Angle to goal: 63.43507089323451
Distance to goal 42.485291572496
Distance in cm: 212.42645786248002 > 50.0
continuous actions for exploring
agent angle = 90.0001220703125
angle stg goal = 104.03624346792648
angle final goal = 63.43507089323451
0.2 -0.05 rel ang = -14.03612139761401
-----------------


======= labels_counter:  1259
Executing skill EXPLORE at timestep 20
Max agent step reached, forcing the agent to quit and wrapping up...
Initializing episode...
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 18
[ObjectNav] Goal name:  ['Move tomato from toilet to table']


======= labels_counter:  1260
Executing skill EXPLORE at timestep 1
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 18
[ObjectNav] Goal name:  ['Move tomato from toilet to table']


======= labels_counter:  1261
Executing skill EXPLORE at timestep 2
[OVMM AGENT] step heuristic nav policy
object goal = 1
start_recep goal = 19
end_recep goal = 18
[ObjectNav] Goal name:  ['Move tomato from toilet to table']


======= labels_counter:  1262
Executing skill EXPLORE at timestep 3
